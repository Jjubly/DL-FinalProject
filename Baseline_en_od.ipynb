{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Baseline_en_od.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMHCjCO6PzcFTzULmikwlUH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L8oK1k3C8IyV","colab_type":"code","outputId":"d3a26f3c-9bb7-475d-b5cb-103a87dd9420","executionInfo":{"status":"ok","timestamp":1587529693845,"user_tz":240,"elapsed":2853,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8BM71zNk9C1-","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","  \n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import torch\n","import torch.nn as nn \n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from io import open\n","from collections import Counter\n","from functools import partial\n","import unicodedata\n","import re\n","from torch.autograd import Variable\n","from gensim.models import KeyedVectors\n","from gensim.models.wrappers import FastText\n","import random\n","import time\n","from datetime import datetime\n","import pickle as pkl\n","import string\n","import os\n","from os import listdir \n","from ast import literal_eval\n","from nltk.tokenize import WordPunctTokenizer \n","\n","\n","import numpy as np \n","import pandas as pd \n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import random\n","import math \n","\n","\n","\n","\n","\n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","import sacrebleu\n","import random\n","import time\n","from datetime import datetime\n","import pickle as pkl\n","import string\n","import os\n","from os import listdir \n","from ast import literal_eval\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.style\n","import matplotlib as mpl\n","from collections import OrderedDict\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jev6MwG3KM6d","colab_type":"code","outputId":"450755c8-cf25-4076-94cc-7906fc5d1e86","executionInfo":{"status":"ok","timestamp":1587523808122,"user_tz":240,"elapsed":8556,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#!pip install sacrebleu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/27/e9c95f45fc11f9093000d234564823aab762f517458f1aa1ad01ba51d5f2/sacrebleu-1.4.7-py3-none-any.whl (59kB)\n","\r\u001b[K     |█████▌                          | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40kB 26.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Collecting mecab-python3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n","\u001b[K     |████████████████████████████████| 17.1MB 187kB/s \n","\u001b[?25hInstalling collected packages: portalocker, mecab-python3, sacrebleu\n","Successfully installed mecab-python3-0.996.5 portalocker-1.7.0 sacrebleu-1.4.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zJHiRKo3cNwh","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'od'\n","\n","SRC_MAX_SENTENCE_LEN = 10\n","TARG_MAX_SENTENCE_LEN = 10\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000 # odia only has 6246 tokens. so will change this later\n","\n","BATCH_SIZE = 64"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZIceAKsv8NM","colab_type":"text"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"wVZdXJTg4_Jm","colab_type":"text"},"source":["### Split and save raw data into train.src.tok, train.targ.tok, val.src.tok, val.targ.tok, test.src.tok, test.targ.tok"]},{"cell_type":"code","metadata":{"id":"52PTi2UR3yYl","colab_type":"code","colab":{}},"source":["#### Create full data for (English, Pashto): combining 4 files each (not needed if you have the dataset in your directory)\n","\n","# en_ps_EN = ['bible.en-ps.clean.en', 'KDE4.en-ps.en', 'ted-wmt20.en-ps.en', 'Ubuntu.en-ps.en']\n","# en_ps_PS = ['bible.en-ps.clean.ps', 'KDE4.en-ps.ps', 'ted-wmt20.en-ps.ps', 'Ubuntu.en-ps.ps']\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/en.tok', 'w') as outfile:\n","#     for file_name in en_ps_EN:\n","#         with open(\"/content/drive/My Drive/ds1012/MT/data/en-ps/{}\".format(file_name)) as infile:\n","#             outfile.write(infile.read())\n","#         outfile.write('\\n')\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/ps.tok', 'w') as outfile:\n","#     for file_name in en_ps_PS:\n","#         with open(\"/content/drive/My Drive/ds1012/MT/data/en-ps/{}\".format(file_name)) as infile:\n","#             outfile.write(infile.read())\n","#         outfile.write('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFLDa2sR3DUW","colab_type":"code","colab":{}},"source":["#### Create train, dev, test for (English, Pashto)\n","\n","# random.seed(1234)\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/en.tok') as infile:\n","#     data = infile.readlines()\n","# train_idx = int(len(data)*0.7)\n","# dev_idx = int(len(data)*0.85)\n","# random.shuffle(data)\n","# train = data[:train_idx]\n","# dev = data[train_idx:dev_idx]\n","# test = data[dev_idx:]\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(train))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/dev.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(dev))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/test.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(test))\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/ps.tok') as infile:\n","#     data = infile.readlines()\n","\n","# random.shuffle(data)\n","# train = data[:train_idx]\n","# dev = data[train_idx:dev_idx]\n","# test = data[dev_idx:]\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(train))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/dev.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(dev))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/test.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzyxoc3874r0","colab_type":"code","outputId":"d2e1837f-c558-41aa-807b-fe9be7a05ac8","executionInfo":{"status":"ok","timestamp":1587245294555,"user_tz":240,"elapsed":332,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# show examples for ps\n","with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.ps.tok') as f:\n","    data = f.read().split('\\n')\n","data[:10]\n","# Note: data are not clean where both en and ps has sentence like '%d:%02d:%02d'"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['مخبره',\n"," 'دا د اِسمٰعيل زامن وُو ، چې په دې ترتيب سره پېدا شوى وُو : نبايوت ، قيدار ، ادبيئل ، مِبسام ،',\n"," 'د کډي د کتابتونونو لپاره په مختاړي کې وژباړل شو',\n"," 'د قوم د راغونډولو د خبر د پاره به دواړه بيګلې غږولے شى . خو دا آواز به لنډ نۀ وى .',\n"," 'په پرليکه اکر کې پېلول',\n"," '. دا خوښبکس وتوانوﺉ چې د ليکبڼه ډول امستنې بدلې کړﺉ@ info: tooltip',\n"," 'عيسىٰ دَ هغوئ سره دَ غرۀ نه راکُوز شو اَؤ په هوار ميدان کښے ودريدو . په دغه ځائے کښے دَ هغۀ ګڼ مُريدان اَؤ ډير خلق چه ټول دَ يهُوديه اَؤ بيتُ المُقدس دَ صور اَؤ دَ صيدا دَ سمندرى غاړے نه راټول شوى وُو اَؤ دَ هغۀ آؤريدو ته راغلى وُو اَؤ چه دوئ دَ خپلو رنځُونو نه شفا ومُومى .',\n"," 'ننوت لېلې_',\n"," 'خو کله چه هغوئ دَ عيسىٰ خوا ته راغلل نو هغه ئے وليدو چه مړ دے ، نو هغوئ دَ هغۀ پښے ماتے نۀ کړلے .',\n"," '%d:%02d:%02d5:02:%Id%dshort time format']"]},"metadata":{"tags":[]},"execution_count":155}]},{"cell_type":"code","metadata":{"id":"TF-rm5DGGtZK","colab_type":"code","colab":{}},"source":["#### Create train, dev, test for (English, Odia)\n","\n","# for i in ['train', 'dev', 'test']:\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.final'.format(i)) as infile:\n","#         lines = infile.readlines()\n","#     en_od_EN = []\n","#     en_od_OD = []\n","#     for line in lines:\n","#         en_od_EN.append(line.split('\\t')[1])\n","#         en_od_OD.append(line.split('\\t')[2])\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.en.tok'.format(i), 'w') as outfile:\n","#         outfile.write(\"\\n\".join(en_od_EN))\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.od.tok'.format(i), 'w') as outfile:\n","#         outfile.write(\"\".join(en_od_OD))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cAQpuj4Imsz","colab_type":"code","outputId":"9df3d009-4bb3-494b-9aeb-b40f3d8b0734","executionInfo":{"status":"ok","timestamp":1587525324750,"user_tz":240,"elapsed":1830,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#### Show examples for od\n","with open('/content/drive/My Drive/ds1012/MT/data/en-od/train.od.tok') as f:\n","    data = f.read().split('\\n')\n","data[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ଆରମ୍ଭରେ ପରମେଶ୍ବର ଆକାଶ ଓ ପୃଥିବୀକୁ ସୃଷ୍ଟି କଲେ।',\n"," 'ପୃଥିବୀ ସେତବେେଳେ ସଂପୂରନ୍ଭାବେ ଶୂନ୍ଯ ଓ କିଛି ନଥିଲା। ଜଳଭାଗ ଉପରେ ଅନ୍ଧକାର ଘାଡ଼ଇେେ ରଖିଥିଲା ଏବଂ ପରମେଶ୍ବରଙ୍କର ଆତ୍ମା ଜଳଭାଗ ଉପରେ ବ୍ଯାପ୍ତ ଥିଲା।',\n"," 'ପରମେଶ୍ବର ଆଲୋକକୁ ଦେଖିଲେ ଏବଂ ସେ ଜାଣିଲେ, ତାହା ଉତ୍ତମ, ଏହାପ ରେ ପରମେଶ୍ବର ଆଲୋକକୁ ଅନ୍ଧକାରରୁ ଅଲଗା କଲେ।',\n"," 'ପରମେଶ୍ବର ସହେି ଆଲୋକର ନାମ ଦେଲେ \" ଦିନ\" ଏବଂ ଅନ୍ଧକାରର ନାମ ଦେଲେ \"ରାତି।\"',\n"," 'ଏହାପରେ ପରମେଶ୍ବର କହିଲେ, \"ଜଳ ମଧିଅରେ ବୃହତ ଗମ୍ବୁଜ ଜାତ ହାଇେ ଜଳକୁ ଦୁଇଭାଗ କରୁ!\"',\n"," 'ଏହିପରି ପରମେଶ୍ବର ତାରଣେ ନିର୍ମାଣ କଲେ ଏବଂ ତାଣେ ଉପର ଜଳଠାରୁ ତାରଣେ ତଳ ଜଳକୁ ଅଲଗା କଲେ। ତହିଁରେ ସହେିପରି ହେଲା।',\n"," 'ପରମେଶ୍ବର ସହେି ତାରଣେ ନାମ ଦେଲେ \"ଆକାଶ\" ତା\\'ପରେ ସଠାେ ରେ ପ୍ରଭାତ ଏବଂ ସଠାେରେ ସୁର୍ୟ୍ଯାସ୍ତ ହେଲା। ଏବଂ ଏହା ଦି୍ବତୀଯ ଦିନ ଥିଲା।',\n"," 'ଏହାପରେ ପରମେଶ୍ବର କହିଲେ, \"ଆକାଶମଣ୍ଡଳ ଅଧଃସ୍ଥ ସମଗ୍ର ଜଳ ଏକ ସ୍ଥାନ ରେ ସଂଗୃହିତ ହେଉ। ୟଦ୍ବାରା ଭୂମି ଶୁଖିଲା ଦଖାୟିବେ।\" ଏବଂ ଏହିପରି ହେଲା।',\n"," 'ପରମେଶ୍ବର ଶୁଖିଲା ଭୂମିର ନାମ \"ପୃଥିବୀ\" ଦେଲେ। ଏବଂ ଜଳସମୁହ ଭାଗର ନାମ ଦେଲେ, \"ସମୁଦ୍ର।\" ଏହା ପରମେଶ୍ବରଙ୍କ ଦୃଷ୍ଟିରେ ଅତି ଉତ୍ତମ ଦିଶିଥିଲା।',\n"," 'ପରମେଶ୍ବର କହିଲେ, \"ପୃଥିବୀ ତୃଣ ଓ ସଜୀବ ଶାକ, ଜୀବ ସମ୍ବଳିତ ନିଜ ନିଜ ଜାତି ଅନୁୟାଯୀ ଫଳ ଉତ୍ପନ୍ନ କରୁ,\" ଏହିପରି ହେଲା।']"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"markdown","metadata":{"id":"IoUv2m-7wGVd","colab_type":"text"},"source":["### Generate Vocab and Tokenize"]},{"cell_type":"code","metadata":{"id":"z8hlbmXHyF5b","colab_type":"code","colab":{}},"source":["RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","\n","def get_filepath(split, src_lang, targ_lang, lang_type): \n","    \"\"\" Locates data filepath given data split type (train/dev/test), translation pairs (src_lang -> targ_lang), \n","        and the language type (source or target) \n","        e.g. to load train.en.tok for en-ps pair, use get_filepath(split='train', src_lang='en', targ_lang='ps', lang_type='source')\n","    \"\"\"\n","    folder_name = \"/content/drive/My Drive/ds1012/MT/data/{}-{}/\".format(src_lang, targ_lang)\n","    if lang_type == 'source': \n","        file_name = \"{}.{}.tok\".format(split, src_lang)\n","    elif lang_type == 'target': \n","        file_name = \"{}.{}.tok\".format(split, targ_lang)\n","    return folder_name + file_name\n","\n","\n","def build_vocab(token_lists, max_vocab_size): \n","    \"\"\" Takes lists of tokens (representing sentences of words), max_vocab_size and returns: \n","        - id2token: list of tokens, where id2token[i] returns token that corresponds to i-th token \n","        - token2id: dictionary where keys represent tokens and corresponding values represent their indices\n","        Note that the vocab will comprise N=max_vocab_size-len(RESERVED_TOKENS) most frequently occuring tokens\n","    \"\"\"\n","    num_vocab = max_vocab_size - len(RESERVED_TOKENS)\n","    all_tokens = [token for sublist in token_lists for token in sublist]\n","    token_counter = Counter(all_tokens)\n","    vocab, count = zip(*token_counter.most_common(num_vocab))\n","    id2token = sorted(RESERVED_TOKENS, key=RESERVED_TOKENS.get) + list(vocab)\n","    token2id = dict(zip(id2token, range(max_vocab_size)))\n","    \n","    # check how many unique tokens + pct of corpus are represented in our vocab \n","    tokens_in_vocab_pct_corpus = 100 * sum([token_counter[token] for token in vocab]) / len(all_tokens)\n","    print(\"A vocabulary of {} is generated from a set of {} unique tokens, representing {:.1f}% of entire corpus\".format(\n","        len(vocab), len(token_counter), tokens_in_vocab_pct_corpus))\n","    \n","    return token2id, id2token \n","\n","\n","\n","def generate_vocab(src_lang, targ_lang, src_vocab_size, targ_vocab_size):\n","    \"\"\" \n","        Takes source and target language names and vocab sizes, outputs a nested dictionary vocab \n","        containing token2id and id2token for both source and target languages. \n","        Note the first level of keys is lang_name (e.g. 'en'), and that of nested dictionary are token2id and id2token.\n","    \"\"\"\n","    vocab = {} \n","    for lang, vocab_size in zip([src_lang, targ_lang], [src_vocab_size, targ_vocab_size]): \n","        \n","        # load train data \n","        train_data_fp = get_filepath(split='train', src_lang=src_lang, targ_lang=targ_lang, \n","                                     lang_type='source' if lang == 'en' else 'target')\n","        # tokenize train data\n","        tk = WordPunctTokenizer() \n","        with open(train_data_fp) as f:\n","            train_tokens = [tk.tokenize(line) for line in f.readlines()]\n","\n","        # generate token2id and id2token \n","        token2id, id2token = build_vocab(train_tokens, vocab_size) \n","        \n","        # store token2id, id2token as a dict in nested dict lang \n","        vocab[lang] = {'token2id': token2id, 'id2token': id2token}\n","        \n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrYvZioLPL6O","colab_type":"code","colab":{}},"source":["### it takes a long time to generate vocabulary, so save to pickle for reimport in future \n","\n","## en-ps pair\n","# SRC_LANG = 'en'\n","# TARG_LANG = 'ps'\n","# SRC_VOCAB_SIZE = 10000 \n","# TARG_VOCAB_SIZE = 10000 \n","# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n","# vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","# pkl.dump(vocab, open(vocab_filename, \"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj9r73yNXLYi","colab_type":"code","colab":{}},"source":["# # en-ps pair\n","# SRC_LANG = 'en'\n","# TARG_LANG = 'od'\n","# SRC_VOCAB_SIZE = 10000 \n","# TARG_VOCAB_SIZE = 10000 \n","# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n","# vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","# pkl.dump(vocab, open(vocab_filename, \"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5O5Cvi57WFy_","colab_type":"code","colab":{}},"source":["# reload from pickle for en-ps\n","SRC_LANG = 'en'\n","TARG_LANG = 'od'\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000\n","\n","vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","vocab = pkl.load(open(vocab_filename, \"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaLv-3KPWFdU","colab_type":"code","colab":{}},"source":["# usage \n","## vocab['en']['id2token']\n","## vocab['od']['token2id']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZNb6UqV-cLx7","colab_type":"text"},"source":["### Generate Data using Vocab"]},{"cell_type":"code","metadata":{"id":"G66g-ayLXxWu","colab_type":"code","colab":{}},"source":["def get_filepaths(src_lang, targ_lang): \n","    \"\"\" Takes language names ('ps', 'en') to be translated from and to (in_lang and out_lang respectively) as inputs, \n","        returns a nested dictionary containing the filepaths for input/output data for train/dev/test sets  \n","        e.g. fps['train']['source']['filepath']\n","    \"\"\"\n","    fps = {} \n","    \n","    # store language names \n","    fps['languages'] = {} \n","    fps['languages']['source'] = src_lang\n","    fps['languages']['target'] = targ_lang \n","    \n","    # store filepaths \n","    for split in ['train', 'dev', 'test']: \n","        fps[split] = {} \n","        for lang_type in ['source', 'target']: \n","            fps[split][lang_type] = {} \n","            fps[split][lang_type]['filepath'] = get_filepath(split, src_lang, targ_lang, lang_type)\n","            \n","    return fps\n","\n","\n","def text2tokens(raw_text_fp, lang_type): \n","    \"\"\" Takes filepath of raw text and outputs a list of lists, each representing a sentence of words (tokens) \n","        Note that it appends to target sentences <SOS> at the start, and <EOS> at the end, but only <EOS> at the end for source sentences\n","    \"\"\"\n","    with open(raw_text_fp) as f:\n","        tk = WordPunctTokenizer()\n","        tokens_data = [tk.tokenize(line) for line in f.readlines()]\n","        if lang_type == 'source': \n","            tokens_data = [datum + ['<EOS>'] for datum in tokens_data]\n","        elif lang_type == 'target': \n","            tokens_data = [['<SOS>'] + datum + ['<EOS>'] for datum in tokens_data]\n","    return tokens_data \n","\n","\n","def tokens2indices(tokens_data, token2id): \n","    \"\"\" Takes tokenized data and token2id dictionary and returns indexed data \"\"\"\n","    indices_data = [] \n","    for datum in tokens_data: \n","        indices_datum = [token2id[token] if token in token2id else RESERVED_TOKENS['<UNK>'] for token in datum ]\n","        indices_data.append(indices_datum)    \n","    return indices_data\n","\n","\n","def process_data(src_lang, targ_lang, src_max_sentence_len, targ_max_sentence_len, vocab, sample_limit=None, filter_long=True): \n","    \"\"\" \n","        - Main function that takes source and target language names, vocab dict generated, \n","        and an optional sample_limit representing the number of sentences to subset if necessary (for evaluation).\n","        we filter out long senstences whose length goes above src(targ)_max_sentence_len if filter_long\n","        - Returns data as a nested dictionary containing the indices and tokens of train/dev/test data \n","        for both source and target languages. \n","        - Note the hierachy of data dict is: data[split][lang_type]['tokens' or 'indices'], \n","        e.g. to access indices of source training data, use data['train']['source']['indices'] or data['train']['source']['tokens']\n","    \"\"\" \n","    \n","    # get filepaths \n","    data = get_filepaths(src_lang, targ_lang)\n","    \n","    # loop through each file, read in text, convert to tokens, then to indices \n","    for split in ['train', 'dev', 'test']: \n","        for lang_type in ['source', 'target']: \n","            # read in tokens \n","            data[split][lang_type]['tokens'] = text2tokens(data[split][lang_type]['filepath'], lang_type)\n","    \n","    # for training data, keep only pairs with both source and target sentences within max_sent_len \n","    if filter_long: \n","        original_train_size = len(data['train']['source']['tokens'])\n","        source_lengths = np.array([len(l) for l in data['train']['source']['tokens']])\n","        target_lengths = np.array([len(l) for l in data['train']['target']['tokens']])\n","        keep_mask = (source_lengths <= src_max_sentence_len) & (target_lengths <= targ_max_sentence_len)\n","        data['train']['source']['tokens'] = list(np.array(data['train']['source']['tokens'])[keep_mask])\n","        data['train']['target']['tokens'] = list(np.array(data['train']['target']['tokens'])[keep_mask])\n","        new_train_size = len(data['train']['source']['tokens']) \n","        print(\"{} data points are removed from training data after filtering out long sentences: {} remain.\".format(\n","            new_train_size - original_train_size, new_train_size))\n","    # further limit number of samples if applicable \n","    if sample_limit is not None: \n","        for split in ['train', 'dev', 'test']: \n","            for lang_type in ['source', 'target']: \n","                data[split][lang_type]['tokens'] = data[split][lang_type]['tokens'][:sample_limit]\n","\n","    # convert tokens to indices \n","    for split in ['train', 'dev', 'test']: \n","        for lang_type in ['source', 'target']: \n","            data[split][lang_type]['indices'] = tokens2indices(tokens_data=data[split][lang_type]['tokens'],  \n","                token2id = vocab[data['languages'][lang_type]]['token2id'])\n","\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zE2ptrCoXxQC","colab_type":"code","colab":{}},"source":["# Load data for en-od\n","data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False)\n","data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) \n","data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PooErl-qXw7w","colab_type":"text"},"source":["### Create Dataloaders"]},{"cell_type":"code","metadata":{"id":"F9cQLOCkWFU5","colab_type":"code","colab":{}},"source":["class TranslationDataset(Dataset): \n","    \"\"\" \n","    Class that represents a train/validation/test/dataset that's readable for Pytorch. \n","    Note that this class inherits torch.utils.data.Dataset\n","    return \n","    \"\"\"\n","    def __init__(self, src_indices, targ_indices, src_max_sentence_len, targ_max_sentence_len):\n","        \"\"\" \n","        Initialize dataset by passing in a list of input indices and a list of output indices with defined maximum length for each sentence\n","        \"\"\"\n","        self.src_indices = src_indices\n","        self.targ_indices = targ_indices\n","        self.src_max_sentence_len = src_max_sentence_len\n","        self.targ_max_sentence_len = targ_max_sentence_len\n","        assert (len(self.src_indices) == len(self.targ_indices))\n","        \n","    def __len__(self): \n","        return len(self.src_indices)\n","    \n","    def __getitem__(self, key): \n","        \"\"\" \n","        Triggered when dataset[i] is called, outputs lists of input and output indices, as well as their \n","        respective lengths\n","        \"\"\"\n","        src_idx = self.src_indices[key][:self.src_max_sentence_len]\n","        src_len = len(src_idx)\n","        targ_idx = self.targ_indices[key][:self.targ_max_sentence_len]\n","        targ_len = len(targ_idx)\n","        return [src_idx, targ_idx, src_len, targ_len]\n","    \n","\n","def collate_func(src_max_sentence_len, targ_max_sentence_len, batch): \n","    \"\"\" Customized function for DataLoader that dynamically pads the batch so that all data have the same length\"\"\"\n","    \n","    src_idxs = [] \n","    targ_idxs = [] \n","    src_lens = [] \n","    targ_lens = [] \n","    \n","    for datum in batch: \n","        # append original lengths of sequences \n","        src_lens.append(datum[2]) \n","        targ_lens.append(datum[3])\n","        \n","        # pad sequences before appending \n","        src_idx_padded = np.pad(array=np.array(datum[0]), pad_width = ((0, src_max_sentence_len - datum[2])), \n","                                mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n","        targ_idx_padded = np.pad(array=np.array(datum[1]), pad_width = ((0, targ_max_sentence_len - datum[3])),\n","                                 mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n","        src_idxs.append(src_idx_padded)\n","        targ_idxs.append(targ_idx_padded)\n","    \n","    return [torch.from_numpy(np.array(src_idxs)), torch.from_numpy(np.array(targ_idxs)), \n","            torch.LongTensor(src_lens), torch.LongTensor(targ_lens)]\n","\n","\n","def create_dataloaders(processed_data, src_max_sentence_len, targ_max_sentence_len, batch_size): \n","    \"\"\" Takes processed_data as dictionary output from process_data func, maximum sentence lengths, \n","        outputs a nested dictionary called 'loaders' that holds train, dev, and test loaders, \n","        e.g. loaders['dev'] holds the data loader for dev/validation set \n","    \"\"\"\n","    loaders = {} \n","    for split in ['train', 'dev', 'test']: \n","        dataset = TranslationDataset(processed_data[split]['source']['indices'], processed_data[split]['target']['indices'], \n","                                     src_max_sentence_len, targ_max_sentence_len)\n","        loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n","                                    collate_fn=partial(collate_func, src_max_sentence_len, targ_max_sentence_len))\n","    return loaders"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19-Ds_oWqH3K","colab_type":"code","colab":{}},"source":["# create dataloaders \n","## in the form \n","loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNDeUl6ipWNk","colab_type":"code","colab":{}},"source":["# examine dataloader (dont' run if you use the loders later)\n","# for src_idx, targ_idx, src_len, targ_len in loaders_full['train']:\n","#     print('source index:',src_idx,'\\ntarget index:', targ_idx, '\\nsource length', src_len, '\\ntarget length', targ_len)\n","#     break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7VbjRqUu7s7","colab_type":"text"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"vhd2ztkhu7bH","colab_type":"text"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"o0fZbmIPu7H7","colab_type":"code","colab":{}},"source":["# RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class EncoderRNN(nn.Module):\n","    \"\"\" RNN encoder\"\"\" \n","\n","    def __init__(self, rnn_cell_type, src_vocab_size, enc_hidden_dim, num_layers, enc_dropout, src_max_sentence_len):\n","        super(EncoderRNN, self).__init__()\n","        self.src_vocab_size = src_vocab_size\n","        self.enc_embed_dim = 300\n","        self.enc_hidden_dim = enc_hidden_dim \n","        self.enc_dropout = enc_dropout \n","        self.src_max_sentence_len = src_max_sentence_len\n","        self.num_layers = num_layers\n","        self.embedding = nn.Embedding(src_vocab_size, self.enc_embed_dim)\n","        self.rnn_cell_type = rnn_cell_type \n","        if self.rnn_cell_type == 'gru': \n","            self.rnn = nn.GRU(input_size=self.enc_embed_dim, hidden_size=self.enc_hidden_dim, num_layers=self.num_layers, \n","                dropout = enc_dropout, batch_first=True, bidirectional=True) \n","        elif self.rnn_cell_type == 'lstm': \n","            self.rnn = nn.LSTM(input_size=self.enc_embed_dim, hidden_size=self.enc_hidden_dim, num_layers=self.num_layers, \n","                dropout = enc_dropout, batch_first=True, bidirectional=True)\n","\n","    def forward(self, enc_input, enc_input_lens):\n","        # save computation by packing paded sequence\n","        batch_size = enc_input.size()[0] # the number of sentences in 1 batch\n","        _, idx_sort = torch.sort(enc_input_lens, dim=0, descending=True)\n","        _, idx_unsort = torch.sort(idx_sort, dim=0)\n","        enc_input, enc_input_lens = enc_input.index_select(0, idx_sort), enc_input_lens.index_select(0, idx_sort) # 0 dimension to reselect\n","        embedded = self.embedding(enc_input) # [batch_size, seq len(the length of each sentence), emb dim(the embedding for each word in a sentence)] e.g [64,10,300]\n","        embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, enc_input_lens, batch_first=True)\n","        # implement rnn\n","        hidden = self.initHidden(batch_size) \n","        if self.rnn_cell_type == 'gru': \n","            output, hidden = self.rnn(embedded, hidden)\n","        elif self.rnn_cell_type == 'lstm': \n","            memory = self.initHidden(batch_size)\n","            output, (hidden, memory) = self.rnn(embedded, (hidden, memory)) \n","        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, \n","                                                            total_length=self.src_max_sentence_len,\n","                                                            padding_value=RESERVED_TOKENS['<PAD>'])\n","        # output: (batch, seq_len, num_directions * hidden_size)\n","        # get the output and hidden in the original unsorted order\n","        output = output.index_select(0, idx_unsort)\n","        hidden = hidden.index_select(1, idx_unsort)\n","        output = torch.cat([output[:, :, :self.enc_hidden_dim], output[:, :, self.enc_hidden_dim:]], dim=2)\n","        hidden = hidden.view(self.num_layers, 2, batch_size, self.enc_hidden_dim) # # h_n.view(num_layers, num_directions, batch, hidden_size)\n","        hidden = torch.cat([hidden[:, 0, :, :].view(self.num_layers, 1, batch_size, self.enc_hidden_dim).squeeze(dim=1), \n","            hidden[:, 1, :, :].view(self.num_layers, 1, batch_size, self.enc_hidden_dim).squeeze(dim=1)], dim=2) \n","        hidden = hidden.view(self.num_layers, batch_size, 2 * self.enc_hidden_dim)\n","\n","        return output, hidden\n","\n","    def initHidden(self, batch_size):\n","        return torch.zeros(2*self.num_layers, batch_size, self.enc_hidden_dim).to(device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xIJdgWplu6--","colab_type":"text"},"source":["### Decoder"]},{"cell_type":"code","metadata":{"id":"F06VQX-Ku62S","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module): \n","\n","\t\"\"\" Vanilla decoder without attention, but final layer from encoder is repeatedly passed as input to each time step. \n","\t\tHandles output from EncoderRNN, which concats bidirectional output. \n","\t\"\"\" \n","\n","\tdef __init__(self, dec_hidden_dim, enc_hidden_dim, num_layers, targ_vocab_size, targ_max_sentence_len):\n","\t\tsuper(DecoderRNN, self).__init__()\n","\t\tself.dec_embed_dim = 300\n","\t\tself.dec_hidden_dim = dec_hidden_dim \n","\t\tself.enc_hidden_dim = enc_hidden_dim\n","\t\tself.targ_vocab_size = targ_vocab_size\n","\t\tself.targ_max_sentence_len = targ_max_sentence_len\n","\t\tself.num_layers = num_layers\n","\t\tself.embedding = nn.Embedding(targ_vocab_size, self.dec_embed_dim)\n","\t\tself.gru = nn.GRU(self.dec_embed_dim + 2 * self.enc_hidden_dim, self.dec_hidden_dim, num_layers=self.num_layers) \n","\t\tself.out = nn.Linear(dec_hidden_dim, self.targ_vocab_size) \n","\t\tself.softmax = nn.LogSoftmax(dim=1) \n","\n","\tdef forward(self, dec_input, dec_hidden, enc_outputs): \n","\t\tdec_input = dec_input \n","\t\tdec_hidden = dec_hidden \n","\t\tenc_outputs = enc_outputs \n","\t\tbatch_size = dec_input.size()[0]\n","\t\tembedded = self.embedding(dec_input).view(1, batch_size, -1)\t\n","#\t\tcontext = enc_outputs[:, -1, :].unsqueeze(dim=1).transpose(0, 1) \n","\t\tcontext = torch.cat([enc_outputs[:, -1, :self.enc_hidden_dim], \n","\t\t\t\t\t\t\t enc_outputs[:, 0, self.enc_hidden_dim:]], dim=1).unsqueeze(0)\n","\t\tconcat = torch.cat([embedded, context], 2) \n","\t\toutput, hidden = self.gru(concat, dec_hidden)\n","\t\toutput = self.softmax(self.out(output[0]))  \n","\t\treturn output, hidden\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eKcvBFUau6tj","colab_type":"text"},"source":["### Bidirectional Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"OW5q5aTQu6dY","colab_type":"code","colab":{}},"source":["class EncoderDecoder(nn.Module): \n","\n","\t\"\"\" Encoder-Decoder without attention \"\"\"\n","\n","\tdef __init__(self, encoder, decoder, decoder_token2id): \n","\t\tsuper(EncoderDecoder, self).__init__() \n","\t\tself.encoder = encoder \n","\t\tself.decoder = decoder \n","\t\tself.targ_vocab_size = self.decoder.targ_vocab_size\n","\t\tself.src_max_sentence_len = self.encoder.src_max_sentence_len \n","\t\tself.targ_max_sentence_len = self.decoder.targ_max_sentence_len \n","\n","\tdef forward(self, src_idx, targ_idx, src_lens, targ_lens, teacher_forcing_ratio): \n","\t\t\n","\t\tbatch_size = src_idx.size()[0]\n","\t\tenc_outputs, enc_hidden = self.encoder(src_idx, src_lens)\n","\t\tdec_hidden = enc_hidden \n","\t\tdec_outputs = Variable(torch.zeros(self.targ_max_sentence_len, batch_size, self.targ_vocab_size))\n","\t\thypotheses = Variable(torch.zeros(self.targ_max_sentence_len, batch_size))\n","\t\tdec_output = targ_idx[:, 0] \n","\n","\t\tfor di in range(1, self.targ_max_sentence_len): \n","\t\t\tdec_output, dec_hidden = self.decoder(dec_output, dec_hidden, enc_outputs)\n","\t\t\tdec_outputs[di] = dec_output \n","\t\t\tteacher_labels = targ_idx[:, di-1] \n","\t\t\tgreedy_labels = dec_output.data.max(1)[1]\n","\t\t\tdec_output = teacher_labels if random.random() < teacher_forcing_ratio else greedy_labels \n","\t\t\thypotheses[di] = greedy_labels\n","\n","\t\tattn_placeholder = Variable(torch.zeros(batch_size, self.targ_max_sentence_len, self.src_max_sentence_len))\n","\n","\t\treturn dec_outputs, hypotheses.transpose(0,1), attn_placeholder \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2-GF1kWu6WI","colab_type":"text"},"source":["## Train and Evaluate"]},{"cell_type":"code","metadata":{"id":"aTU2Y4HBu6P0","colab_type":"code","colab":{}},"source":["#RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","RESULTS_LOG = '/content/drive/My Drive/ds1012/MT/experiment_results/{}_{}_experiment_results_log.pkl'.format(SRC_LANG, TARG_LANG)\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def filter_reserved_tokens(sentence_as_list): \n","    \"\"\" Takes a list of tokens representing a sentence, removes everything after <EOS>, \n","    as well as remove reserved tokens <SOS>, <EOS>, <PAD>. Outputs filtered sentence as a string. \"\"\" \n","\n","    # drops everything after <EOS> \n","    try: \n","        output = sentence_as_list[:sentence_as_list.index('<EOS>')]\n","    except: \n","        output = sentence_as_list\n","\n","    # drops <SOS>, <EOS>, <PAD>  \n","    output = ' '.join([idx for idx in output if idx not in ['<SOS>', '<EOS>', '<PAD>']]) \n","\n","    return output \n","\n","\n","def tensor2corpus(tensor, id2token):  \n","    \"\"\" Takes a tensor representing a batch of sentences (size: batch_size * max_sentence_length), and returns \n","        its token equivalent (as list of tokens) \"\"\" \n","    list_of_lists = tensor.cpu().numpy().astype(int).tolist()\n","    #print(np.max(list_of_lists))\n","    to_token = lambda l: [id2token[idx] for idx in l]\n","    corpus = [to_token(l) for l in list_of_lists] \n"," \n","    return corpus\n","\n","\n","def reconstruct_corpus(token_list): \n","    \"\"\" Takes a list of tokens, filter out reserved tokens, and returns a list of sentence strings \"\"\" \n","\n","    sentences = [filter_reserved_tokens(sublist) for sublist in token_list]\n","\n","    return sentences  \n","\n","\n","def calc_corpus_bleu(ref_list, hyp_list): \n","    \"\"\" Takes a list of reference sentences and a list of hypothesis sentences, flattens them, and outputs their corpus bleu \"\"\"\n","\n","    # convert ref_list and hyp_list into strings \n","    hyp_stream = reconstruct_corpus(hyp_list)\n","    ref_streams = [reconstruct_corpus(ref_list)]\n","    \n","    # compute bleu score \n","    bleu_score = sacrebleu.corpus_bleu(hyp_stream, ref_streams).score  \n","\n","    return bleu_score \n","\n","\n","def evaluate(model, loader, src_id2token, targ_id2token, teacher_forcing_ratio=1): \n","    \"\"\" Evaluates a model given a loader, id2token dicts, and teacher_forcing_ratio. \n","        Outputs avg loss, avg bleu, as well as indices and tokens representing source, reference, and model translations. \n","    \"\"\"\n","    \n","    with torch.no_grad():\n","\n","        model.eval() \n","        total_loss = 0 \n","\n","        # initialize empty list to hold all source, reference and model translations \n","        reference_corpus = []\n","        hypothesis_corpus = [] \n","        source_corpus = [] \n","        attn_weights_corpus = []\n","        \n","        for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(loader): \n","\n","            # for each batch, compute loss and accumulate to total \n","            batch_size = src_idxs.size()[0]        \n","            src_idxs, targ_idxs, src_lens, targ_lens = src_idxs.to(device), targ_idxs.to(device), src_lens.to(device), targ_lens.to(device)\n","            outputs, hypotheses, attn_weights = model(src_idxs, targ_idxs, src_lens, targ_lens, \n","                teacher_forcing_ratio=teacher_forcing_ratio)\n","            outputs = outputs[1:].transpose(0, 1)\n","            targets = targ_idxs[:,1:]\n","            attn_weights = attn_weights[:,1:]\n","            outputs_for_nll = outputs.contiguous().view(-1, model.decoder.targ_vocab_size).to(device)\n","            targets_for_nll = targets.contiguous().view(-1).to(device)\n","            loss = F.nll_loss(outputs_for_nll, targets_for_nll, ignore_index=RESERVED_TOKENS['<PAD>'])        \n","            total_loss += loss.item()  \n","\n","            # append to lists holding corpus \n","            hypothesis_corpus.append(hypotheses)\n","            reference_corpus.append(targets)\n","            source_corpus.append(src_idxs)\n","            attn_weights_corpus.append(attn_weights)\n","\n","    # concat list of index tensors into corpus tensors (as indices), then convert to list of sentence (as tokens)\n","    hyp_idxs = torch.cat(hypothesis_corpus, dim=0) \n","    ref_idxs = torch.cat(reference_corpus, dim=0)\n","    source_idxs = torch.cat(source_corpus, dim=0)\n","    attn = torch.cat(attn_weights_corpus, dim=0)\n","\n","    hyp_tokens = tensor2corpus(hyp_idxs, targ_id2token)\n","    ref_tokens = tensor2corpus(ref_idxs, targ_id2token)\n","    source_tokens = tensor2corpus(source_idxs, src_id2token)\n","\n","    # compute evaluation metrics \n","    avg_loss = total_loss / len(loader)\n","    avg_bleu = calc_corpus_bleu(ref_tokens, hyp_tokens)\n","    \n","    return avg_loss, avg_bleu, hyp_idxs, ref_idxs, source_idxs, hyp_tokens, ref_tokens, source_tokens, attn   \n","\n","\n","def train_and_eval(model, loaders_full, loaders_minibatch, loaders_minitrain, params, vocab, \n","    lazy_eval=True, print_intermediate=1000000, save_checkpoint=True, save_to_log=True, inspect_samples=None, print_attn=False): \n","    \n","    \"\"\" Main function to train and evaluate model: takes a model, loaders, and a bunch of parameters and \n","        returns trained model along with a results dict storing epoch, train/val loss, and train/val bleu scores. \n","        Note that: \n","        - lazy_train = train and validate only on a single mini batch (for quick prototyping) \n","        - lazy_eval = skip evaluation on train set altogether (not even the 1K proxy) \n","        - print_intermediate = reports loss and bleu scores every 'print_intermediate' minibatches or end of each epoch \n","        - save_checkpoint = saves model's state dict into a .pth.tar file named after model_name \n","        - save_to_log = saves results to log \n","        - inspect_samples = specify number of samples to print out every 1K batches \n","    \"\"\"\n","    \n","    start_time = time.time() \n","\n","    # extract local variables from params \n","    learning_rate = params['learning_rate'] \n","    targ_id2token = vocab[params['targ_lang']]['id2token']\n","    src_id2token = vocab[params['src_lang']]['id2token']\n","    num_epochs = params['num_epochs']\n","    teacher_forcing_ratio = params['teacher_forcing_ratio']\n","    clip_grad_max_norm = params['clip_grad_max_norm']\n","    experiment_name = params['experiment_name']\n","    model_name = params['model_name']\n","    lazy_train = params['lazy_train']\n","    attention_type = params['attention_type']\n","    print(targ_id2token)\n","    # designate data loaders used to train and calculate losses \n","    if lazy_train: \n","        train_loader_ = loaders_minibatch['train'] # used to train \n","        dev_loader_ = loaders_minibatch['dev'] # used to calculate dev loss \n","        train_loader_proxy = loaders_minibatch['train'] # used to calculate train loss \n","    else: \n","        train_loader_ = loaders_full['train']\n","        dev_loader_ = loaders_full['dev'] \n","        # evaluating on full training set prohibitively expensive, so use a 1K batch instead as proxy \n","        train_loader_proxy = loaders_minitrain['train'] \n","\n","    # initialize optimizer and criterion \n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss(ignore_index=RESERVED_TOKENS['<PAD>'])\n","    results = [] \n","    \n","    # loop through train data in batches and train \n","    for epoch in range(num_epochs): \n","        train_loss = 0 \n","        for batch, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader_):\n","            DEBUG_START = time.time() \n","            src_idxs, targ_idxs, src_lens, targ_lens = src_idxs.to(device), targ_idxs.to(device), src_lens.to(device), targ_lens.to(device)\n","            model.train()\n","            optimizer.zero_grad()\n","            final_outputs, hypotheses, attn_weights = model(src_idxs, targ_idxs, src_lens, targ_lens, teacher_forcing_ratio=teacher_forcing_ratio) \n","            # attn_weights = attn_weights[:,1:]\n","            final_outputs = final_outputs[1:].transpose(0, 1)\n","            targets = targ_idxs[:,1:]\n","            outputs_for_nll = final_outputs.contiguous().view(-1, model.decoder.targ_vocab_size).to(device)\n","            targets_for_nll = targets.contiguous().view(-1).to(device)\n","            loss = criterion(outputs_for_nll, targets_for_nll)\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_max_norm)\n","            optimizer.step()\n","            \n","            # evaluate and report loss and bleu scores every 'print_intermediate' minibatches or end of each epoch\n","            if batch % print_intermediate == 0 or ((epoch==num_epochs-1) & (batch==len(train_loader_)-1)):\n","\n","                result = {} \n","                result['epoch'] = epoch + batch / len(train_loader_) \n","\n","                # calculate metrics on validation set \n","                result['val_loss'], result['val_bleu'], val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens, val_attn = \\\n","                    evaluate(model, dev_loader_, src_id2token, targ_id2token, teacher_forcing_ratio=teacher_forcing_ratio)         \n","\n","                # calculate metrics on train set (or proxy thereof) only if lazy_eval not set to True \n","                if not lazy_eval: \n","                    result['train_loss'], result['train_bleu'], train_hyp_idxs, train_ref_idxs, train_source_idxs, train_hyp_tokens, train_ref_tokens, train_source_tokens, train_attn = \\\n","                            evaluate(model, train_loader_proxy, src_id2token, targ_id2token, teacher_forcing_ratio=teacher_forcing_ratio) \n","                else: \n","                    result['train_loss'], result['train_bleu'] = 0, 0  \n","\n","                results.append(result)\n","\n","                print('Epoch: {:.2f}, Train Loss: {:.2f}, Val Loss: {:.2f}, Train BLEU: {:.2f}, Val BLEU: {:.2f}, Minutes Elapsed: {:.2f}'\\\n","                      .format(result['epoch'], result['train_loss'], result['val_loss'], \n","                              result['train_bleu'], result['val_bleu'], (time.time() - start_time) / 60 ))\n","                    \n","                if inspect_samples is not None: \n","                    # sample predictions from training set, if available \n","                    if not lazy_eval: \n","                        print(\"Sampling from training predictions...\")\n","                        sample_predictions(train_hyp_idxs, train_ref_idxs, train_source_idxs, train_hyp_tokens, train_ref_tokens, \n","                            train_source_tokens, targ_id2token, train_attn, print_attn=print_attn, num_samples=inspect_samples)\n","                    # sample predictions from validation set \n","                    print(\"Sampling from val predictions...\")\n","                    sample_predictions(val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens, \n","                        targ_id2token, val_attn, print_attn=print_attn, num_samples=inspect_samples)\n","                    \n","                if save_checkpoint: \n","                    if result['val_bleu'] == pd.DataFrame.from_dict(results)['val_bleu'].max(): \n","                        checkpoint_fp = '/content/drive/My Drive/ds1012/MT/model_checkpoints/{}.pth.tar'.format(model_name)\n","                        check_dir_exists(filename=checkpoint_fp)\n","                        torch.save(model.state_dict(), checkpoint_fp)\n"," \n","    runtime = (time.time() - start_time) / 60 \n","    dt_created = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    total_params, trainable_params = count_parameters(model)               \n","\n","    if save_to_log: \n","        append_to_log(params, results, runtime, experiment_name, model_name, dt_created, total_params, trainable_params)\n","\n","    print(\"Model training completed in {} minutes with {:.2f} best validation loss and {:.2f} best validation BLEU.\".format(\n","        int(runtime), pd.DataFrame.from_dict(results)['val_loss'].min(), \n","        pd.DataFrame.from_dict(results)['val_bleu'].max()))\n","\n","    return model, results  \n","\n","def sample_predictions(hyp_idxs, ref_idxs, source_idxs, hyp_tokens, ref_tokens, source_tokens, id2token, \n","    attn, print_attn, num_samples=1, ): \n","\n","    \"\"\" Sample a few source sentences, reference and model translations to review \"\"\" \n","\n","    for i in range(num_samples): \n","        rand = random.randint(0, len(hyp_idxs)-1) \n","        source = ' '.join(source_tokens[rand])\n","        print(\"Source: {}\".format(source))\n","        reference_translation = ' '.join(ref_tokens[rand]) \n","        print(\"Reference: {}\".format(reference_translation))\n","        model_translation = ' '.join(hyp_tokens[rand])\n","        print(\"Model: {}\".format(model_translation))\n","        if print_attn: \n","            print(\"Attention Weights: {}\".format(attn[rand]))\n","        print()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq-dDt3lc9Wi","colab_type":"code","colab":{}},"source":["def check_dir_exists(filename): \n","    \"\"\" Takes filename string and check whether its implied directory exists, otherwise creates it \"\"\" \n","\n","    if not os.path.exists(os.path.dirname(filename)):\n","        os.makedirs(os.path.dirname(filename))\n","    else: \n","        pass \n","        \n","\n","def append_to_log(hyperparams, results, runtime, experiment_name, model_name, dt_created, total_params, trainable_params, filename=RESULTS_LOG): \n","    \"\"\" Appends results and details of a single experiment to a log file \"\"\"\n","    \n","    # check directory exists, else creates it \n","    check_dir_exists(filename)\n","        \n","    # store experiment details in a dictionary \n","    new_result = {'experiment_name': experiment_name, 'model_name': model_name, 'hyperparams': hyperparams, \n","        'results': results, 'runtime': runtime, 'dt_created': dt_created, \n","        'total_params': total_params, 'trainable_params': trainable_params}\n","    \n","    # if log already exists, append to log \n","    try: \n","        results_log = pkl.load(open(filename, \"rb\"))\n","        results_log.append(new_result)\n","\n","    # if log doesn't exists, initialize first result as the log \n","    except (OSError, IOError) as e:\n","        results_log = [new_result]\n","    \n","    # save to pickle \n","    pkl.dump(results_log, open(filename, \"wb\")) \n","\n","\n","def load_experiment_log(experiment_name=None, model_name=None, filename=RESULTS_LOG): \n","    \"\"\" Loads experiment log, with option to filter for a specific experiment_name \"\"\"\n","    \n","    results_log = pkl.load(open(filename, \"rb\"))\n","    \n","    if experiment_name is not None: \n","        results_log = [r for r in results_log if r['experiment_name'] == experiment_name]\n","\n","    if model_name is not None: \n","        results_log = [r for r in results_log if r['model_name'] == model_name]\n","\n","    # sort by dt_created \n","    results_log = sorted(results_log, key=lambda k: k['dt_created'], reverse=True)\n","        \n","    return results_log\n","\n","\n","def summarize_results(results_log): \n","    \"\"\" Summarizes results_log (list) into a dataframe, splitting hyperparameters string into columns, and reducing \n","        the val_acc dict into the best validation accuracy obtained amongst all the epochs logged \"\"\"\n","    results_df = pd.DataFrame.from_dict(results_log)\n","    results_df = pd.concat([results_df, results_df['hyperparams'].apply(pd.Series)], axis=1)\n","    results_df = results_df.loc[:, ~results_df.columns.duplicated()] # unfortunately saved model_name and experiment_name twice \n","    results_df['best_val_loss'] = results_df['results'].apply(lambda d: pd.DataFrame.from_dict(d)['val_loss'].min())\n","    results_df['best_val_bleu'] = results_df['results'].apply(lambda d: pd.DataFrame.from_dict(d)['val_bleu'].max())\n","    return results_df.sort_values(by='dt_created', ascending=False) \n","\n","\n","def count_parameters(model): \n","    \"\"\" Returns total and trainable parameters of a given model \"\"\" \n","    all_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return all_params, trainable_params"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hv61C_BjRe37","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'od'\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000\n","# model architecture params \n","NETWORK_TYPE = 'rnn'\n","RNN_CELL_TYPE = 'gru'\n","NUM_LAYERS = 2 \n","ENC_HIDDEN_DIM = 512\n","DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n","TEACHER_FORCING_RATIO = 1\n","CLIP_GRAD_MAX_NORM = 1\n","ENC_DROPOUT = 0 \n","DEC_DROPOUT = 0  \n","ATTENTION_TYPE = 'without'\n","\n","# training params  \n","NUM_EPOCHS = 10 \n","LR = 0.00015 \n","OPTIMIZER = 'Adam'\n","LAZY_TRAIN = False\n","\n","# name the model and experiment \n","if NETWORK_TYPE == 'rnn': \n","    EXPERIMENT_NAME = '{}-{}-rnn-{}-attn'.format(SRC_LANG, TARG_LANG, ATTENTION_TYPE)\n","elif NETWORK_TYPE == 'cnn': \n","    EXPERIMENT_NAME = '{}-cnn'.format(SRC_LANG)\n","MODEL_NAME = '{}-{}'.format(EXPERIMENT_NAME, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1nv-1_ZgsDZ","colab_type":"code","colab":{}},"source":["# store as dict to save to results later \n","params = {'experiment_name': EXPERIMENT_NAME,'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n","          'rnn_cell_type': RNN_CELL_TYPE, 'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, \n","          'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, 'src_vocab_size': SRC_VOCAB_SIZE, \n","          'targ_vocab_size': 6246, 'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, \n","          'dec_hidden_dim': DEC_HIDDEN_DIM, 'teacher_forcing_ratio': TEACHER_FORCING_RATIO, \n","          'clip_grad_max_norm': CLIP_GRAD_MAX_NORM, 'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n","          'attention_type': ATTENTION_TYPE, 'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, \n","          'learning_rate': LR, 'optimizer': OPTIMIZER, 'lazy_train': LAZY_TRAIN}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drHV_zknIXxk","colab_type":"code","outputId":"5f9053fb-5120-48a8-b3c8-0ac0949a5516","executionInfo":{"status":"ok","timestamp":1587529914447,"user_tz":240,"elapsed":1385,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(vocab['od']['id2token'])"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6246"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"9X5tqYQmjp_8","colab_type":"code","colab":{}},"source":["encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, src_vocab_size = SRC_VOCAB_SIZE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n","                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT)\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kq4PLDErkTGz","colab_type":"code","outputId":"461ddaf1-a250-459b-a3d8-09fe013b8d40","executionInfo":{"status":"ok","timestamp":1587530535016,"user_tz":240,"elapsed":608459,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model, results = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=True, save_to_log=True, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['<SOS>', '<EOS>', '<PAD>', '<UNK>', '୍', 'ା', 'ି', 'େ', 'ୁ', 'ତ', 'ର', 'କ', 'ନ', 'ବ', 'ମ', 'ପ', 'ଲ', 'ସ', 'ହ', 'ଯ', 'କର', 'ଦ', 'ଶ', 'ୀ', 'ୋ', 'ଥ', 'ନଙ', 'ୟ', 'ଭ', 'େ।', 'ସମ', 'ଣ', 'ଓ', 'େେ', 'ଗ', 'ଙ', 'ଷ', 'ଟ', 'ଇ', 'ଜ', 'ପର', '।', 'ୂ', 'ଁ', 'େ,', 'େି', 'ସହ', ',', 'ଏହ', 'ଖ', 'ଭମ', 'ଧ', 'ରଭ', 'କହ', 'ବର', 'ଛ', 'ୃ', 'ି।', 'ଚ', 'ସଦ', 'ଆମ', '\"', 'ଂ', 'ୋ', 'କଲ', 'ାେ', 'ଡ', 'ୁଁ', 'ଳ', 'କମ', 'ପରମ', 'ା।', 'ମନ', 'ଏ', 'ଅନ', 'ହବ', 'ମଧ', 'ିଁ।', 'ଏବ', 'ଭର', 'ଉ', 'ରକ', \"ା'\", 'ି,', 'େୁ', 'ଠ', 'ସମସ', 'ତବ', 'ସବ', 'ଆସ', 'ରଣ', 'ଇଶ', '଼ି', 'ବରଙ', 'ରତ', 'ଅ', 'ଅଛ', 'ଦବ', 'ିଁ', 'ରହ', 'ଏକ', 'ଭକ', 'ଜଣ', 'କକ', \"'\", 'ଯଦ', 'ଉତ', 'ା,', 'ବନ', 'ଆଉ', 'ଇବ', 'ଞ', 'ତର', 'ଛନ', 'ସନ', 'ଅର', 'ତମ', 'ଯମ', 'କଥ', 'ଇଲ', 'ସର', 'ଶର', 'ତକ', 'ଗଲ', 'ଅଧ', 'ପକ', 'ୈ', 'ଆପଣ', 'କରନ', 'ଦଇ', 'ଯନ', 'ଯକ', 'ୌ', 'ରମ', 'ମର', 'ଉଦ', 'ବସ', 'ଉଚ', 'ଉପର', 'ରର', 'ଶକ', 'ୁ।', 'ଫ', 'ଲର', 'ରସ', 'ଘ', 'ଆ', 'ୁ,', 'ଣସ', 'ଆଣ', 'ଜକ', '।\"', 'ଯର', 'େୀ', 'ରଖ', 'ରବ', 'କଠ', 'ଗର', '଼ା', 'ସଠ', 'ପବ', 'ଜନ', 'ହତ', 'ମହ', 'ନର', 'ଅବ', 'ୟମ', 'ସମୟର', 'ପତ', 'ନବ', 'ବକ', 'ଆଜ', '?', 'ତହ', 'କଙ', 'ପଡ', 'ବହ', 'ଭବ', '଼', 'ନଗର', 'ବଳ', 'ଅଟ', 'ଅଛନ', 'ଏପର', 'ଅତ', 'କଟର', 'ଫର', 'ି।\"', 'ୟକକ', 'ଧର', 'ଭଲ', 'ଗଣ', 'ମକ', 'କଟକ', 'ନଇ', 'ଜର', 'ହସ', 'ଆଶ', 'ପଠ', 'ଢ', 'ଥନ', 'େେ।', 'ଇଥ', 'ଉପ', 'ଦକ', 'ଦର', 'କହନ', 'ସତ', 'ୟକ', 'ଷୟ', 'ଦଖ', 'ଉଛ', 'ପନ', 'ଟମ', 'ଟଦ', 'ପଶ', 'ଆତ', 'ଆକ', 'ଅନକ', 'ଖକ', 'ଳନ', 'ିଁ,', 'ଭଳ', 'ଉଥ', 'ବତ', 'ଘଟ', 'ଲମ', 'େ।\"', 'ମଷ', 'ଟଙ', 'ରଦ', 'ଷଯ', 'ଅଶ', 'ଧନ', 'ବପ', 'ନକ', 'ଟତ', 'ୌ', 'ଝ', '୍।', 'ତନ', 'ସକ', 'ହର', 'କବଳ', 'ଷମ', 'ଉଠ', 'କନ', 'କଟ', 'ଦନ', 'ଦଲ', 'ଅଗ', 'ଆର', 'ଲବ', 'ପଚ', 'ହନ', 'ବଦ', 'ଯତ', 'ଦଣ', 'ଚର', 'ଯବସ', 'ଶଷ', 'ପଦ', 'ନଥ', 'ଉଲ', 'କବ', 'ଶତ', 'ଖର', 'ଭୟ', 'ଅସ', '୍,', 'ଆଦ', 'ଦୟ', 'ଫଳ', 'ସମୟ', 'ଉଦଙ', 'ମଙ', 'ଃ', 'ଯବ', 'ଲକ', 'ଅଭ', 'ିଁ।\"', 'ସଙ', 'ଯବହ', 'ପଲ', 'ଶଲ', 'ୁଃ', 'ଜଳ', 'ହକ', 'ଶସ', 'ଆହ', 'ଇଛ', 'ଏଥ', 'ଯଙ', 'ରନ', 'ରବର', 'ଆୟ', 'ଅପ', 'ଥର', 'ମଣ', 'ଇଚ', 'ୟଜ', 'ରଥମ', 'ତଙ', 'ାଂ', 'ରହଣ', 'ଆଗ', 'ପଥର', 'ରଶ', 'ନମ', ':', 'ଆନନ', 'ନତ', 'ବଧ', 'ଏକତ', 'ଥକ', 'ନଦ', 'ୈେ', 'ଅନନ', 'ାଁ', 'ଟକ', 'ଆନ', 'ିଂ', 'ଚତ', 'ରଯ', 'ଅବଶ', 'ଅମ', 'ଖଣ', 'ଗଳ', 'ରଚ', 'ଞବଦ', 'ରଧ', 'ଟର', 'ତଳ', 'ଟଣ', 'ୀ,', '!', 'ସଗ', 'ମତ', 'ବଞ', 'ଉପସ', 'ଆଡ', 'େଁ।', 'ଇପ', 'ଏଣ', 'ମସ', 'ଇଗ', 'ପଣ', 'ଷର', 'ତଥ', 'ଧକ', 'ଷଣ', 'ଉଣ', '?\"', 'ଶବ', '୍\\u200c', 'ବଡ', 'ଶନ', 'ଗମ', 'ଯଲ', 'ୋ।', 'ଉପଦ', 'ପଳ', 'ୟର', 'ଜକମ', 'ଖଡ', 'ଇମ', 'ଆରମ', 'େି।', 'ଏଠ', 'ଆପଣଙ', 'ରମଣ', 'ନଷ', 'ଗକ', 'ଁ।', 'କବର', 'ଚକ', 'ଉଲଙ', 'କଣ', 'ଅଟନ', 'ଉପହ', 'ି?', 'ଣର', 'ରଙ', '-', 'ମବ', 'ୟଙ', 'ଏତ', 'ଣନ', 'ସମର', 'ପଟ', 'ଉଛନ', 'ତଦ', 'ଏଲ', 'ା।\"', 'ତକର', 'ଗତ', 'େଁ', 'ଆଘ', 'ଆଲ', 'ଷତ', 'ସମଗ', 'ସରଣ', 'ଷଫ', \"।'\", 'ୂେ', 'ଜତ', ';', 'ଇଟ', 'ତରକ', 'ୁ।\"', 'ଦଯ', 'ପଥ', 'ଘର', 'ଗଦ', 'ଇଯ', 'ଁ,', 'ଲମର', 'ବଢ', 'ଲଖ', 'ସହର', 'ଯଥ', 'ନଗରର', 'ସପ', 'ଷକ', 'ଇଫ', 'ଦଶ', 'ଅହ', 'ଦଳ', 'ଚଯ', 'ଏସବ', 'ଅତଏବ', 'ମଗ', 'ୀ।', 'ନଇଗ', 'ଯସ', 'ବଶକ', 'ବଜ', 'ସକଳ', 'ପରମପ', 'ଭଉଣ', 'କତ', 'ଲଜ', 'ୟନ', 'ଶରର', 'ଯପ', 'ଇଛନ', 'ଅପର', 'ରଗ', 'ଜଗ', 'ନଗଣ', 'ଗନ', 'ଳକ', 'ଲଗ', 'ତତ', 'ମଲ', 'ଟଡ', 'ଡଳ', 'ମଦ', 'ଣଙ', 'ଅଙ', 'ଟହ', 'ଶପଥ', 'ବରଣ', 'ଚଳ', 'ଇଦ', 'ଇୟ', 'ଗମନ', 'ଆଚ', 'ଅଦ', 'ୁେ', 'ପଗ', 'ଥଳ', 'ଦଗ', 'ପରସ', 'ଜମ', 'ମରଣ', 'ଉପତ', '000', 'ମନଙ', 'ଆସନ', 'ଟଲ', 'ଶଧର', 'ଯଭ', 'ଶମ', 'ଲନ', 'ଲମକ', 'ରହର', 'ଜଣକ', 'ହମ', 'ଚସ', 'କଟକକ', 'ବଦଳ', 'ଭୟଙ', 'ଏକଥ', 'ଟଖ', 'ଗଣଙ', 'େଁ,', 'ଏମ', 'ଣତ', 'ି?\"', 'ଲଙ', 'ଅଣ', 'ଟନ', 'ଅକ', '଼େ', 'ଅଳ', 'ଏଷ', 'ମଶ', 'ଉପରକ', 'କଷ', 'ଚନ', 'ଭଙ', 'ଇସ', 'େେ,', 'ଅଞ', \"ି।'\", '(', 'ଆଖ', 'ଭଠ', 'ଘଟଣ', 'ଆଗଲ', 'ରଗଣ', 'ଯହ', 'ୗ', 'କଳ', 'ଳର', 'ୋ,', 'ପହଞ', 'ଟସ', '୍-', 'ଦରକ', 'ରଇ', 'ସଭ', 'ଉଅଛ', 'ରକକ', 'ନପ', 'ଭୟଭ', 'ବହକ', 'ଇଅଛ', 'ନଇୟ', 'ତପ', 'ନଗରକ', 'ରଜ', 'ନଯ', 'ବଙ', 'ଶମର', 'ଆଯ', 'ଆବଶ', \"େ।'\", 'ଶଯ', 'ଶଧରମ', 'ପରଦ', 'ରଥ', 'ଯଶ', 'ଇତ', 'ତଡ', 'ୟଥ', 'ଅବସ', 'ଲତ', 'ହନଙ', 'ଘରକ', 'ଶୟ', 'ଛଡ', 'ହଜ', 'ଶରକ', 'ଶକକ', 'ରସବ', 'ସପର', 'ଉଷ', 'ଭଗ', 'ବଯସ', 'ବଚ', 'ଜଣଙ', 'ପଛ', 'ଯଦବକ', 'ବଦନ', 'ଣକ', 'ରଟ', \"ିଁ।'\", 'ଷଫଙ', 'ଉର', 'କଦ', 'ଧବ', 'ଭଣ', 'ଗସ', 'ଯରକ', 'ଟଯଲ', 'େୂ', 'ଲଲ', 'ୟଦ', 'ଉଭୟ', 'ମନର', 'ପଞ', 'ନନ', 'ମହତ', 'ଗଛ', 'ସସ', 'ଗଧ', 'କଡ', 'ଖନ', 'ସହରର', 'ଯଗ', 'ତଜ', 'ଠର', 'ଦଶମ', 'କପ', 'ବଳବ', 'ଚରଣ', 'ତଟ', 'ମଲକ', 'ଗଣନ', 'େ:', 'ଯଦଳ', 'େୃ', 'ଓହ', 'ଅପମ', 'ନଠ', 'ଷଙ', 'ରପ', 'ଅଜ', 'ବଗ', 'ପହନ', 'ୁଁ।', 'ଅପବ', 'ନକକ', 'ଘନ', 'େ?', 'ଦମ', 'ସତର', 'ଶଯନ', 'ବହନ', 'ଦହ', 'ଗଣର', 'ନଗ', 'ଇଜଣ', 'ଷମତ', 'ନବର', 'ମଜ', 'ଉଡ', 'ତଳକ', 'ମଳ', 'ଗଭ', 'ଭରସ', 'େି,', 'ଭହ', 'ରଣର', 'ଭଟ', 'ବତର', 'ଶୟତ', 'ନକର', 'ସଯ', 'ସଫଳ', 'ଠକ', 'ନଗଣଙ', 'େୋ', 'ମମ', 'ବନର', 'ନଲ', '଼ୋ', 'ଷପ', 'ଉନ', 'ପଙ', 'ଟଷ', 'ନଟ', 'ବଲ', 'ନସ', 'ବନକ', 'ବଷ', 'ଉପବ', 'ସଜ', 'େି।\"', 'େେ।\"', 'ରପର', 'ତଣ', 'ଦତ', 'ଅଧର', 'ପଷ', 'ି:', 'ଟଅ', 'କଲଦ', 'ହଲ', 'ଆବ', 'ଏଗ', 'ଏଫ', 'ଅମଙ', 'ଖଦ', 'ଏଭଳ', 'ଅଲଗ', 'ିେ', 'ଳମ', 'ଡକ', 'ଶଦ', 'ରଦର', 'ଚୟ', 'ରଥମଜ', 'ପରକ', 'ଜଯ', 'ଖସ', 'ଖବର', 'ତସ', 'ଦବଗ', 'ଟବ', 'ମଥ', 'ବଣ', 'ଛକ', 'ଜଗତ', 'କଟବର', 'ଆଳ', 'ପବନ', 'ଚଟ', 'କଟସ', 'ଆଚରଣ', 'ତରଙ', 'ଏକମ', 'ତଗ', 'ନହ', 'ଟଚ', 'ଜଗତର', 'ବଯ', 'ବବ', 'ଖମ', 'ରସର', 'ହକକ', 'ଟଥ', 'ଖକକ', 'ଅହସ', 'ଆଗଇ', 'ଆଡକ', 'ମଯ', 'ଅଣଯ', 'ଟକର', 'ଆଶର', 'ଆଙ', 'ସମକ', 'ବତନ', 'ସଲ', 'ମନକ', 'ଚଢ', 'କରଣ', 'ଇର', 'ଇନ', 'ଜନକ', 'ଶଗ', 'ନଗରଗ', \"?'\", 'ଗଡ', \"ାେ'\", 'ଯଲର', 'ଛଳ', 'ହଠ', 'ଆଗର', 'ତବର', 'ପଯ', 'ଶଧରଗଣ', 'ଅସର', 'ଜଳପ', 'ଷଗଣ', 'ଅଟକ', 'ଈ', 'ା!', 'ନଭ', 'ଗଙ', '।\"\\'', 'ଜକକ', 'ରଷ', 'ଇଷ', 'ଡର', 'ଉଜ', '1', 'ଟରକ', 'ବରକ', 'ନମସ', 'ଯଦବ', 'ବଶ', 'ଖଳ', 'ଦଇପ', 'ଲଭ', 'ହଳ', 'ଭପ', 'କଲଲ', 'ରରଣ', 'ା:', 'ଆଧ', 'ବନଯ', 'ଳକମ', 'ା?', 'ଆସକ', 'ଅଷ', 'ଯକକ', 'ଶଓରଙ', 'ସହରଗ', 'ଚମ', '୍େ', 'ମରକ', 'ିଃ', 'ମଇଦ', 'ବତମଯ', 'ଭକକ', 'ଅମତ', 'ଣବ', 'ସହକ', 'ଭବତ', 'େୁ।', 'ପଲର', 'ଛଅ', 'ଡଙ', 'ଯଲଙ', 'ଟଇ', 'ଲୟ', 'ଗଣକ', 'ଜକର', 'େ।\"\\'', 'ପଢ', 'ଅମଳ', 'ସଫ', 'ଇକ', 'ହଦଦ', 'ଲକକ', 'ଟଛ', 'ଷୟଗ', 'ଷଗ', '଼ୁ', 'ଗଗ', 'ସସହ', 'ତଲ', 'ଏରସ', 'ଋଣ', 'ଶମଯ', 'େ?\"', 'ଅଲ', 'ନଗଣର', 'ଥମ', 'ବମ', 'ରଭକ', 'ି଼', 'ଜକଗଣ', 'ରକର', 'ତଳର', 'ଈଶ', 'ଊର', 'ରଫ', 'ଗହମ', 'ସସମ', ')', 'ରଖନ', 'ରଚଣ', 'ଗପ', 'ତଳଭ', 'ଯଗଣ', 'ଉକ', 'ିଁ?', \"ୁ।'\", 'ଷକମ', 'ଭସ', 'ଦହର', 'ପଶକ', 'ଥଲ', 'ଯଧ', 'ହଣ', 'ଦଖଯ', 'ଆହସ', 'ଳସ', 'ତଗଣ', 'ଛଣ', 'େ!', 'ଗହ', 'ବଳନ', 'ୟଯ', 'ରସନ', 'େଁ।\"', 'ପହ', 'କଢ', 'ପଦର', 'ପଥଗ', 'ଝଡ', 'ଟଗ', 'ସରଳ', 'ୟତ', 'ବଳକ', 'ବତକ', 'ହରଣ', 'ଦଳର', 'ି।\"\\'', 'ତରର', 'ସଞ', 'ୟବ', 'ଟଭ', 'ଚତକ', 'ନଗରକକ', 'ଦଙ', 'କଯ', 'ଇଗଲ', 'ଆପ', 'ବକକ', 'ଶଟ', 'ୁଁ,', 'ପପ', 'ମକକ', 'ଖଦନ', 'ଜଳକ', 'ଉପୟ', 'ଝର', 'ଯକର', 'ଉଦର', 'ଯବରଣ', 'ପତନ', 'ସନକର', 'ଏଜ', 'ସଘ', 'ଐଫ', 'ଭଦ', 'ହଗ', 'ବଳଦ', 'ଦନର', 'ଘକ', 'କହକ', 'ସହରକକ', 'ସହବ', 'ଜଳର', 'ବକମ', 'ବସନ', 'ବପର', 'ଯଦର', 'ନଫ', 'ଣକର', 'ପସନ', \"ା।'\", 'ରଗଣଙ', 'ଜଙ', 'ଫସଲ', 'ଯକତ', 'ତଗତ', 'ମହଲ', 'ରମର', 'ଷଗଣଙ', 'ଷଶ', 'ଋତ', '!\"', 'ଲହ', 'ସହସ', 'ରବଳ', 'ଅବଜ', 'ଫଟ', '\"\\'', 'ଶଙ', 'ଗଢ', 'ହଙ', 'ବସତ', 'ଝରଣ', 'ରଜଣ', 'ଁ।\"', '12', 'ପରଲମଶ', 'ଦକର', 'ଅଛକ', 'ସହଜ', 'କରକ', 'ରଶସ', 'ଗଦଲ', 'ରଠ', 'ଓଜନ', 'ଅସମ', 'ଅଗଣ', 'ନଳ', 'ଯସବ', 'ସହଭ', 'ଦଯର', 'ଅଖ', 'ଉପରକକ', 'ଶରରକ', 'ିେ।', 'ଓଟ', 'ଏସ', 'ଯଷ', 'ଚମଡ', 'ହଟ', 'ଧତ', 'ଫନ', 'ବଛ', 'ଈର', 'ଫଳକ', 'କପଟ', 'ବତଗ', 'େ;', 'ଜକଙ', 'ଟପ', 'ଶନର', 'ଆଡକକ', 'ଟଯ', 'ଯତମ', 'ଯମସ', 'ସରକ', 'ଯବର', 'ଯମର', 'କଗଣ', 'ଘରର', 'ଜପ', 'ା?\"', 'ରବଞ', 'ଖଟ', 'ଉପପତ', 'ଟନର', 'ଅପହରଣ', 'ରଥର', 'ଣପ', 'ହଶ', 'ଷଯକ', 'ଚଳର', 'ସନର', 'ଟସରଣ', 'ୋେ', 'ଅହଙ', 'ଲଭମ', 'ଗଠନ', 'ଘଡ', 'ମଝ', 'ଲଣ', 'ଅଯ', 'ଫଲ', 'ଆଉଥର', 'ୋ।\"', 'କପର', 'ଲଢ', 'ତକଙ', 'ଓବ', 'କଲକ', 'ଦବଦ', 'ଉଲଗ', 'ୋ,', 'ରୟ', 'ଅଳଙ', 'ନୟ', 'ଆଗକ', 'ଆଗତ', 'କରମ', 'ୟକକଙ', 'ପରବର', 'ଅବର', 'ୁ?', 'ଗବ', 'ଯମକ', 'ଟଶ', 'ଟଳ', 'ସକମ', '଼ୀ', 'ରହନ', 'ୋ।', 'ୟବନ', 'ହଦ', 'ନଗରଦ', 'ସମତ', 'ଷଷ', 'ଅହଲ', 'ୟଟ', 'ଧଳ', 'ଳଦ', 'ଝରକ', 'ସଇ', 'ଦଶଟ', 'ଶଳ', 'ମଚ', 'ଖଜ', 'ତରଳ', '2', 'ଡଇ', 'ଓଷ', 'ଟଝ', 'ଟଟ', 'ଗକକ', 'ଟଅନ', 'ଟକକ', 'ରରକ', 'ସଐର', 'ରହସ', 'ନୟମ', 'ଲମସ', 'କରଟ', 'ୁ!', 'ଲଟ', 'ିଁ।\"\\'', 'ଆମର', 'ବବର', 'ଅଳସ', 'ଦତଳ', 'କଇ', 'ଠନ', 'ନଗରମ', 'ଭଶ', 'ଟଅଛ', 'ଟଏ', 'ଭହକ', 'ଓବଦ', 'ଯକମ', 'ଷୟକ', 'ତଭ', 'ସହରକ', 'ମଠ', 'ଭଲପ', 'ଆଗମନ', 'ନରହତ', 'ା-', 'ତକକ', 'ତଦନ', 'ଶକର', 'ଥଗ', 'ସପକ', 'ଯଜନକ', 'ଟମତ', 'ଜବ', 'ଧନସମ', 'ଜଗତକ', 'ଶମଣ', 'ଗଛର', 'ଜଟ', 'ଆପଣମ', 'ଲଯ', 'ସରଙ', 'ଏର', 'ଗଧମ', 'ଏପ', 'ଇଗଣ', 'ଖତ', 'ାେେ', 'ନଚ', 'ରତମ', 'ଅରଣ', 'ଟଇଟ', 'ତହକ', 'ଲସ', 'ୟମଙ', 'ୟଖ', 'ଲବଣ', 'ଯଲକ', 'ଦଦ', 'ାେ,', 'ସଚ', 'ଏକମତ', 'ବଳପ', '୍।\"', 'ସରହ', 'ଁ?', 'ଘସ', 'ଜନଶ', \"ି'\", 'ୀ;', 'ଗରକ', 'ନରକ', 'ଟଛନ', 'ଥନଙ', '20', 'ଅଥଲ', \"ୁ'\", 'ବକଙ', 'ଇସରଙ', 'େ଼', 'ନଖ', 'ଶପ', 'ରମଶ', 'ଚଳକ', 'ଆଣନ', 'ଖଇ', 'ଆରଦ', 'ଉପକ', 'ଉପପର', 'ଯଦଳର', 'ବସର', 'ରଆତ', 'ଅସହ', 'ଗରମ', 'କଲନ', 'ମପ', '100', 'ଥଟ', 'ସତଣ', 'ିଁ?\"', 'ସବଳ', 'େୁ,', 'ତଜଣ', 'ଆଦର', 'ରହକ', 'ଣକକ', '3', 'ଅବନର', 'ରଦତ', 'ଷସ', 'ତକତ', 'ଦଯକ', '600', 'ଘଉଡ', 'ବନୟ', 'ପଇସ', 'ଜଧ', 'ଶରବ', 'କପଡ', 'ପକର', 'ଏକବର', 'ଛପ', 'ଟଖରକ', 'ଟବନ', 'ଭରକ', 'ଣଗ', 'ସକକ', 'କଫର', 'ଘରକକ', 'ଧନକ', 'ଧମ', 'ଇଶମ', 'ଆସଫ', 'ବଭ', '200', '଼।', 'ଣଠ', 'ସରର', '7', 'ା\"', 'ଛଦନ', 'ତଥର', 'ଶଜ', 'ହଇ', 'ଶୟଙ', 'ଐଶ', 'ଅବମ', 'କବଳର', '00', 'ଛଦ', 'ପସବ', 'ଅଥବ', 'ଡନ', 'ଉବ', 'ଜଣକର', 'ତରକକ', 'ଦଉଡ', 'ଯପର', 'ମଫ', 'ବଲର', 'ଦଇଦ', 'ମଡ', 'ଅମର', 'କସ', 'ଅବଧ', 'ଅଯର', 'ଆଠ', 'ଷତର', 'ଓଟମ', 'େ-', 'ରଡ', 'ଜଯଲ', 'େ\"', 'ଲଦ', 'ପଠଇ', 'ୀ।\"', 'ଥତ', 'ରବନ', 'ଘଣ', 'ବତବ', 'ଷଯର', 'ଯଠ', 'ଓଗ', 'ବସବ', 'ରପତ', 'ଦପ', 'ମନସ', 'ବଳଶ', 'ଟଧ', 'ନସବ', 'ଅସକ', 'ଯଯ', 'ଜଗଣ', 'ବରର', 'ପକଇ', 'ଯତବକ', 'ଇୟଙ', 'ଯଦଳକ', 'ଇସର', 'ଅସତ', 'ପମ', 'ରବଧ', 'ନଶ', 'ଫକ', 'ଅତର', 'ଆତଙ', 'ଦଶଜଣ', 'ପଛକ', 'ଳକର', 'ଣଭ', 'ଗଧକ', 'ୁଁ।\"', 'ଏଥର', 'ୟହ', 'ୟଷ', 'ଦବର', 'ବଳତ', 'ୟହସ', 'ମୟ', 'ଫଳର', 'ଜଘନ', 'ନବମ', 'ଖଲ', 'ଶଗଡ', 'ଆହକ', 'ବତଗଣ', 'ପଥରଟ', 'ଆହତ', 'ଉପଲର', 'ୟଯଙ', 'ନଥନ', 'ବନଦ', 'ବୟସ', 'ନଗତ', 'ଷତକ', 'ଶଧରଙ', 'ଇଅଛନ', 'ଚଜଣ', 'ମଷଗ', 'ଛଅଟ', 'କବରକ', 'ଯଦଇ', '୍େ,', 'ରଧର', 'ଳବ', 'ଳଯ', 'ଆରବ', 'ଲଇ', 'ଁେ', 'ଡଗ', 'ଶବକ', 'ସରଣକ', 'ପଥଦଇ', 'ନଇଯ', 'ଗଠ', 'ଭରକର', 'ଧକକ', 'ଟବକ', 'ବତମ', 'ଭଇ', 'ଗଛଟ', 'ଥଲହମ', 'ଯୟନ', 'ଜଦ', 'ୟମଗ', 'ରକନ', 'ନଡ', 'ଯଟ', 'ତସହ', 'େ.', 'ଯଣ', 'ଳନଦ', 'ତଯ', 'ଜନତ', 'ଆପତ', 'ଭରଣ', 'ମଞ', 'ଳବର', 'ଡଣ', 'ଧଡ', 'ଅଜଣ', 'ଷବ', 'ରସବକ', 'ଡପତ', 'ଟଇଜଣ', 'ଟବର', 'ଐନ', 'ଉପନଗର', 'ସତକ', 'ଦୟର', 'ସଳଖ', 'ଛଳନ', \"େେ।'\", 'ଜଲଣ', 'ସଫଳତ', 'ଷଡ', '଼େ।', 'ମପତ', 'ଆଦମ', '300', 'ଇଙ', 'ଏଲମ', 'ସମତଳ', 'ଦଭ', 'ଧନବ', 'ସକର', 'ଠପ', 'ଞବଲଦ', 'ୁ?\"', 'ସହବର', 'ଈଗ', 'ଇଜଣଙ', 'ଳକଟ', 'ଡଟ', 'ୁ)', 'ସମୟଠ', 'ଉଭୟଙ', 'ଛବ', 'ଗଳର', 'ତରଫର', 'ବକର', 'ସମଯ', 'କଳଙ', 'ହସବ', 'ି;', 'ଚବ', 'ଶଠ', 'ଗଶ', 'ଝକ', 'ହରକ', 'ଗଟ', 'ଥହ', 'ଥରକ', 'ଯତବ', 'ଥନର', 'ୋ-', 'ମହଣ', 'ହକମ', 'ଶଯତ', 'ଭୟର', 'ଜୟ', 'ଶହ', 'ଷଦ', 'ନଗରଟ', 'ଳକକ', 'ବଥ', 'ଯନର', 'ଥବ', 'ୁଂ', 'ଧମକ', 'ଏଲଷ', 'େୀ,', 'ଧରସ', 'ଚଉଦ', '0', 'ଜଦଣ', 'ଚଞ', 'ଈଥ', 'ଘଜ', 'କରଇ', 'ଖଚ', 'ସଲଲ', 'ୟକକର', 'ଷଠ', '୍!', 'ରତକ', 'ନଗରସବ', 'ଠଲ', 'ସହରଗକ', 'ଲରକ', 'କଟରକ', 'ଭଲକ', 'ଆଶଙ', 'ଉଅଛନ', 'ଟବତ', 'ଟଖକକ', 'ଟଭବ', 'ସକଗଣ', 'ଘମ', 'ଛକର', 'ଜନରବ', 'ଏଣତ', 'କବରର', 'ସନକ', 'ରଲତ', 'ରମଲ', 'ରବଣ', 'ହଶବ', 'ଗଳମଯ', 'ଷୟର', 'ରହଦ', 'ଥଙ', 'ନପର', 'ଥଲର', 'ା୍', 'ତରସ', 'ଦହକ', 'େ,\"', 'ଅସମର', 'ଏଟ', 'ସଫର', 'ମଟ', 'ହବର', 'େ)', 'ଦଯଙ', 'ଷଗଣର', 'ତଠ', 'ଥପର', 'ଜଞ', 'ି-', 'ଢଳ', 'ା।\"\\'', 'ଆବରଣ', 'ଳତ', 'ବନସ', 'ନହସ', 'ଆଇନ', 'ଅଦରକ', '଼ୋ', 'ସଐ', 'ମହକ', 'ସତଜ', 'ଅଶକ', 'ଟଆ', 'ଗଷ', 'ଠଗଣ', 'ଅବଲମ', 'ଅନକଙ', 'ୟଗଣ', 'ଖବ', 'କରତ', 'ଭଡ', 'ମସକ', 'କଲର', 'ଞତ', 'ଟଳମଳ', '24', 'ଭରଶ', 'ଈଷ', 'ୟମର', 'ସକଳର', 'ଶଲହ', 'ଯଫ', 'ଉଟ', 'ଇବର', 'ଷଧର', 'କଦର', 'ସଦସ', \"େି।'\", 'ଗଯ', 'ଅବନତ', 'ଜନସମ', 'ମହନଯ', 'ଖଞ', 'ଓନ', 'ଅଫ', '8', 'ରଖକ', 'ଁ?\"', 'ଞମ', 'ନତମସ', 'ବଯର', 'ୁ।\"\\'', 'ଗହଳ', 'ଇଲନ', 'ପଗଡ', 'ନକଲ', 'ଣମ', 'ଦକକ', 'ଣମଯ', 'ଶବର', 'ଛଉ', 'ଲପ', 'ଘରଟ', 'ଷଭ', 'ଶତମ', 'ମରନ', 'ଧକର', 'ଛଡଇ', 'ସଲଫ', 'କରବ', 'ରଯସ', 'ଇସହ', 'ସଐତ', 'ପସ', 'ଇଲକ', 'ଦଧ', 'ଧନର', 'ବଚକ', 'ଟକକକ', 'କଫ', 'ଚତର', 'ଅଠର', 'ଉଲର', 'ରବଶ', '଼,', 'ମଇଳ', 'ଖକର', 'ନହପ', 'ଇଭ', 'ଏଦନ', 'ିଁ!', 'ୟପ', 'ଲପନ', 'ା)', 'ଷପର', 'ଥଯ', '400', 'ୀ)', 'କଟତର', 'ସଦଯ', 'ମଲକର', 'ଇଦବ', 'ଦଶଦ', 'ତପର', 'ଗଜ', 'ି!', 'ପଲକ', 'ପରଠ', 'ଲୟଲର', 'ଥଲକ', 'ବଠ', 'ଫସ', 'ନଗରସ', 'ଲହମ', 'ଦଇନ', 'ପଛର', 'ନଗଣକ', 'ହଯ', 'କଞ', 'ଚଦଶ', 'ଇଖଣ', '10', 'ମସଲ', 'ଗହଣ', 'ଜଯଧ', 'ମରଙ', 'ଓଟପକ', 'ି\"', 'ନଜ', 'ଣଦଣ', 'ଜପଥ', 'ରଲ', 'ଠଗ', 'ଖରକ', 'ହଫର', \"େ'\", 'ଆରପ', 'ଯମଯ', 'େୋ', 'ଟଖସ', 'ଟସନ', 'ଜସ', 'ଟୟ', 'ରବମଯ', 'ରମଣର', 'ରକମ', 'ମସବ', 'ପଦକ', 'ା,\"', 'ଶଫଟ', 'ଖଚର', 'ସଯଉ', 'ରଥକ', 'ୟତମ', 'ପକହ', 'ସଫନ', 'ସଫଙ', 'ଅଟଳ', 'ହନନ', 'ସଚତନ', 'ମନକର', '଼େ,', 'ଗଛକ', 'ଚଇ', 'ଡଳର', 'ସଡ', 'ଚଟବସ', 'ଷରଦନ', 'କରଆଦ', 'ନସକ', 'ଜବଦ', 'ଠଇ', 'ଆପଲ', 'ଗମନକ', 'ଷଟ', 'ପହର', 'ଥଣ', 'ସବଦ', 'ଓଫ', 'କଳହ', 'ଯଗଣଙ', 'ମରର', 'ଷଲତ', \"ୀ'\", 'ଗଇବ', 'ଈମ', 'ସଦଖ', '.', 'ଥଳକ', 'କବରସ', 'ଶଫ', 'ଗଲଣ', 'ଧଭ', 'ଦସ', 'ରବକ', 'ରଥଗ', 'ଓସ', 'ତଗଣଙ', 'ଘତ', 'ପଛପଟ', 'ରଗଣର', 'ଳୟ', 'ଶସବ', 'ଇହ', 'ଭଜ', 'ବଶତ', 'ଉପଭ', 'ନଗରରକ', 'ଭପର', 'ଟହନ', 'ତଳକକ', 'ଗଦର', 'ଷକକ', \",'\", '120', 'ଆମକକ', 'ଷସବ', 'ଭକର', 'ତଇ', 'ଶରଣ', 'ହଇର', 'ଆଉଜ', 'ଦକଥ', 'ଉଦକକ', 'ଧରନ', 'ନରର', 'ତସଲ', 'ତଳମଯ', 'କବରପ', '80', 'ପଥରଗ', 'ଷତବ', 'ଗଧଟ', 'ଯକଳ', 'କଳସ', 'ମନଷ', 'ଆଉମଧ', 'ଳଙ', 'ଫନର', 'ଅବଦ', 'ଅରଣନ', 'ତରଣ', 'ତକମ', 'ନସନ', 'ପବନକ', 'ଖମଣ', '଼ା,', 'ବଖର', 'ସମୟକ', 'ରମଣକ', 'ଜଳଷ', 'ଫତ', 'ଏବର', 'ଏଲମର', 'ଷଦକ', 'ବନଧ', 'ୋ-', 'ିା', '୍\"', 'ଫଳବତ', 'ଗସର', 'ସଯଲତଲବଲଳ', 'ଇଲଲ', 'ଗଲର', 'ଘଦ', 'ଜବରଦସ', 'ଦବନ', 'ମକର', 'କରର', 'ଜପକ', 'ଅବତରଣ', 'ବଳର', 'ବଧକର', 'ପଥକ', 'ତମତ', 'କଚର', 'ପବଦ', 'ଚହ', 'ପରର', 'ଜଡ', 'ଶଲମ', 'ପୟ', 'ଧହ', 'ଥନକ', 'ଲମଠ', 'ତରଟ', 'ହସର', 'ତହତ', 'ରଗକ', 'ରଜଣଙ', 'ଏଲତ', 'ଷଧ', 'ଚଳକକ', 'ଅସଦ', 'ଡପ', 'ତକକର', 'ଯଷରକ', 'ଗଗଣ', 'ଆଗକକ', 'ଟରସ', 'େେ।\"\\'', 'ଲବଙ', 'ବଶଷ', 'ସବହ', 'ଫଣ', 'ଶଯର', '4', ',\"', 'ି,\"', 'ନତମ', 'ହଦଦଷ', 'ଧଟ', 'ଫଲର', 'ରସହ', 'କଲବଳ', 'ହଷ', 'ନତର', 'ଈଷବଲ', 'ବଗଣ', 'ଆସଫର', 'ସରହଙ', 'ଐନଯ', 'ଚତମ', 'ଶଷଦ', 'ଦଖଯକ', 'ରମଯ', 'ଆଭ', 'ଔଷଧ', 'ଉପସର', 'ଟଶତ', 'େ଼ା', 'ଷଦକଙ', 'ଜଳଭ', 'ଆଇ', 'ି!\"', 'ଏବଲ', 'ଣରକ', 'ହପ', 'ଝଗଡ', 'ଣଯ', 'ମସକର', 'ଯଜ', 'ଆମକ', 'ଭଲଭ', 'ଣବର', 'ଗଲଲ', 'ପଲଙ', 'ବତସ', 'ଅସନ', \"ି?'\", \"େଁ।'\", 'ମଭ', 'ଜନପ', 'ଗଧର', 'ଇବକ', 'ଜକନ', \"ି,'\", 'ନକରନ', 'ଳଗ', 'ପବନର', 'ୟଜଣକ', 'ଷଡୟନ', 'ତମଣ', 'ଆସବ', 'ଚଉଡ', '\"।', 'ବହସ', '30', 'ମବଦ', 'ଢର', 'ପତଙ', 'ଷରଣ', 'ଉହ', 'ଜକତ', 'ଜନର', 'ନଥନଲ', 'ଲଘ', 'ରଦକ', 'ମବଳ', 'ଥଲହ', 'ଚଉଦଟ', 'ଏକଦ', 'ରହବ', 'ୟଗ', 'ରଣଭ', 'ଅଥଚ', 'ନଗରବ', 'ଗଣକକ', 'ଟଗଣ', 'ସଗଣ', 'ଟଏତ', 'କରଜ', 'କକକ', 'ବନକକ', 'ଚମତ', 'ଜଳନ', 'ଶଗକ', 'ଅଦକ', 'କବଳରକ', 'ଯକଥ', 'ଗହଙ', 'ଃ,', '?\"\\'', 'ଖପ', 'ଦବଙ', 'ଜଯଗ', 'ଧସର', 'ସତଲବ', 'କଟଲର', 'ଲୟଲ', 'ବରଫ', '70', 'ଏଥନ', 'ରଚନ', 'ଅଲର', 'ନହଦଦ', 'ପକହଙ', 'ୟହତ', 'ହମଙ', 'ସଯର', 'ଝଲକ', 'ଧନଭଣ', 'ଓଢ', 'ପଦଦଳ', 'ନଦନଦ', 'ଗମଣ', 'ୀ,\"', 'ଳକଗଣ', 'ୟଯର', 'ଅନକଗ', 'ରମୟ', 'ବରଯ', 'ଗଧଛ', 'ଦୟକ', 'ନଯମ', 'ଈନ', '500', 'ରଯମ', 'େ।)', 'ତନର', 'ଅଣତ', 'ପଦସ', 'ୟଥର', 'ହତର', 'ଷନ', '5', 'କଦମ', 'ସହକର', 'ଗଥ', 'ଗଇଲ', 'ଏସମସ', 'ନସର', 'ତସହଲ', 'ନଜନକ', 'ସରହର', 'ଯନକ', '୍?\"', 'େଃ', 'ଭଧ', 'ନଜର', 'ଷକଙ', 'ଏଇ', 'ଶଣ', 'ୟଶସ', 'ତଚର', 'ଲଠ', 'କଅ', 'ଆଶରର', 'ବତଠ', 'ଧମଧ', 'ଯଦକ', 'ନଦଇ', 'ବଥର', 'ଛଲ', 'ଘରମ', '6', 'ବସକ', 'ଶରଠ', 'ଛଅଦ', 'ବକଗଣ', 'ଫମ', 'ନରହ', 'ଅମଳର', 'ବଇଚ', 'ନଦବ', 'ଆଠଟ', 'ରଭଦ', 'ଷରଣକ', 'ରଜସ', 'ୀ-', 'ଜଲ', 'ଜକଗଣଙ', 'ଷଣସ', 'ା;', 'ରଣତ', 'େଁ?', 'ଣଦ', 'ଦଠ', 'ଆବଦ', 'ସହରମ', 'ଗଲକ', 'ରଚକ', 'କପତ', 'ଯରଠ', 'କରଗତ', 'ୋ?', 'ଟବଙ', 'ଶରକକ', 'ଟଠ', 'ଯଦଣ', 'ଯମକକ', 'ଟରର', 'ବଳଦମ', 'ପଥରକ', 'ଆଖନ', 'ଅଯକକ', 'ଲକମ', 'ଅକଷ', 'କଗ', 'ଶଧରଗଣଙ', 'ଗହକକ', 'ସଖ', 'କଜଣଙ', 'ଆବଦନ', 'ବଢଇ', 'ଖଲକକ', 'ଗତକ', 'ନରକକ', '40', 'ଶତର', '700', '22', 'ମରକକ', 'ସହଲଲ', 'ଥରହର', 'ଶଲଲ', 'ତସର', 'ଆକର', 'ଫଟଙ', 'ଥଳର', 'ଥମଙ', 'ଆହସଙ', 'ବଲଦ', 'ଫଳପ', 'ସରଦନ', 'ଓପ', 'ଶଖନ', 'ସହତ', 'କରଙ', 'ଷଯମ', 'ୁ\"', 'ଅଦର', 'ଝଇ', 'ଦଖଯର', 'ଉଦଯ', 'ଳଯକ', 'ଡଳକ', 'ପଶମ', 'ଝନ', 'ମକଦ', 'ସହଜର', 'ୟପର', 'ଗଛଗ', 'ତଫନ', 'ଜନଗହଳ', 'ଛଟ', 'ନସଙ', 'ମନକଥ', 'ଲଢଇ', 'ଜଖ', 'ରରଣକ', 'ଥସ', 'ଆଥ', 'ପମୟ', 'ଧପ', 'ଏଦ', 'ମହଲଲଲ', 'ରମକ', 'ଜଳଧ', 'ତଦଶ', 'ରଧନ', 'ଊଷ', 'ରଥମର', 'ହତସର', 'ଏକଶହ', 'ସଟ', 'ାଁ,', \"',\", 'ାେ।', 'ଇଥର', 'ବନଙ', 'ପବତ', 'ତବଲ', 'ଦଳକ', 'ଓସସମ', 'ଭଲଟ', 'େୁ।\"', 'ଓନନ', 'ଫଳବ', 'ଅଘଟଣ', 'ପଟର', 'ସରଦ', 'ଳକଙ', 'ଭୟକର', \"ୋ।'\", 'େି?', 'ଆପଥର', 'ଚକଟ', 'ଉନଥ', 'ହହ', 'ଚକଗ', 'ଶତପତ', 'ଖରର', 'ଦମନ', 'ଛଦବ', 'ଦନକ', 'ଣଧ', 'ଅପହ', 'ଉଭଇ', 'ରବସ', 'ଊଣ', 'ୟଠ', 'ଳପ', 'ପଜନକ', 'ଆଇବ', 'ଅବସର', 'ୋ୍', 'ଯଲଠ', 'ଠସ', 'ସବର', 'ନଅଟ', '୍?', 'ଗବର', 'ନଅ', 'ଧଦ', 'ଆଗରକ', 'ଟଗକ', 'ଗଲକକ', 'ଭଷ', 'ଜଣକକ', 'ଓଦ', 'ଟଢ', 'ଉଠନ', 'ରଣରକ', 'ଧରକ', 'ଳଭ', 'ହଫ', 'ସକଙ', 'ଟତର', 'େି?\"', 'ବନଇ', 'ଜକକକ', 'ଥନକକ', 'ତସବ', 'ପରମଶ', 'ଭକରମ', 'ସବକ', 'ଚକର', 'ଶଯକକ', 'ପଥପ', 'ରସଲ', \"'।\", 'ୟଶ', 'ଷତଳ', 'ଫରନ', 'ବହମ', 'ମଯଙ', 'ଚଲ', 'ପତଳ', 'କଣର', 'ସସଠ', 'କସହ', 'ରହମଲଙ', 'ଶବନ', 'ରଥଚ', 'ପନକ', 'ତକଟ', 'ପହତ', 'ତନଯ', 'ମରମ', 'ମମଯ', 'ପତନର', 'ଯତକ', 'ୀ?', 'ସଢ', 'ଭନ', 'ଯମଣ', 'ଯତଳ', 'ପଥଭ', 'ଗସବ', 'ଚକମକ', 'ଳସର', 'ଖଗ', 'ଯତମଙ', 'ଳଣ', 'କମନ', 'ଣୟ', 'ମହମ', 'ଲବସ', 'କଚ', 'ଚକସବ', 'ଏନ', 'ଲଗଇ', 'ଠଇଲ', 'ଇକନ', 'ଅଣୟ', 'ତସଙ', 'ୀ\"', 'ଯଜନ', 'ଏଦନର', 'କମଣ', 'ମକରଣ', 'ମପର', 'ଯରଦ', 'ାା', 'ବଜନ', 'ତଳସ', '150', \"ୀ।'\", 'ଔରସ', 'ପଛଆଡ', 'ଆଇଲ', 'ିି', 'ା!\"', 'ଇଠ', 'ଧନଶ', 'ରଥମଥର', 'ିେ,', 'ସହଲ', 'ବରସମ', 'ଏଦର', ')।', 'କନସ', 'ନହତ', 'ପକଇବ', 'ିେ।\"', 'ଈକ', 'ଆସନତ', 'ତକଥ', 'ମହସ', 'ଧରମ', 'ଆବଲ', 'ୀ!', 'ନବଜ', 'ତଚ', 'ଗଚ', 'ି.', 'ଲବର', 'ଛଚ', 'ଅଯଥ', 'ଭସବ', 'ମଘ', 'ଦଶହ', 'ତଗଣର', 'ି)', 'ରଗଣକ', 'ମଦକ', 'ଷଇ', 'ଉମ', 'ରଯଶ', 'ଗମନର', 'ଫଳକର', 'ଉଭୟର', 'ଏକଶତ', 'ଗଣତ', 'ଧରଣର', 'ହଳଦ', 'ତଜଳ', 'ଉସ', 'ଛଅବର', 'ରଜନ', 'ଯପଶ', 'ବପନ', 'ୋ୍', 'ୂ,', 'ଷହର', 'ଆଛ', 'ଓହଳ', 'ଏତଦ', 'ରହଙ', 'ୋ?\"', 'ନହଲ', 'ମଦବ', 'ଉଦବ', 'େଁ?\"', 'ଯଦଠ', 'ବଗଣର', 'ଣଯଠ', 'ଥୟ', 'ପଲଟ', \"!'\", 'ଟଣନ', 'ଟଣକ', 'ନଗଣକକ', 'ନଗରଗକ', 'ମଧକ', 'ବତରକ', 'ସରଳତ', 'ଟକଟ', 'ତକରଣ', 'ଉପୟକ', 'ଦଯକକ', 'ଗଣଠ', 'ଟଆକକ', 'ତରବର', 'ଭରର', 'ଏଗକ', 'ରଞ', 'ଠକନ', 'ଫସଲର', 'ମନପ', 'ଗଚରମ', 'ଟବକମ', 'ସହରଠ', 'ଉଛକ', 'ଗରର', 'ଅକସ', 'ଐନଗଦ', 'ସହରରକ', 'ଯଦକକ', 'େଁ!', \"ଁ।'\", 'ଥଲହମର', 'କଐ', 'ଓଲଟ', 'ଟଶଳ', 'ଅରକ', 'ଶତକ', 'ଋତକକ', 'ଳକକକ', 'ନହସର', 'ଥକବଳ', 'ଟଶଳବ', 'ଭଲକଥ', 'େେ?', 'ରଥସବ', 'ଗପର', 'ଅବନରକକ', 'ଶଯଙ', 'ତରମ', 'ଥରଙ', 'ରଲବଶ', 'ସଯପର', 'ମସର', 'ଷଯସର', 'ଆଲମ', 'ଓସସ', 'ଲଯର', 'ଲହର', 'ମହରଯ', 'ଭତ', 'ରମଙ', 'ତରଗ', 'ଗଆଡ', 'ଗଇ', 'ହମଯ', 'ଝରଗ', 'ଓଳମ', 'ଯରଙ', '44', '50', 'ସଯଙ', 'ଷପତ', '28', 'ଆସଫଙ', 'ଯଯଲ', 'ଭବଷ', 'ଉଦକ', 'ବଯସର', 'ସମବ', 'ଷତଗ', 'ତକଗ', 'ବବଯର', 'ଏବଦ', 'ଷଣକ', 'ହନନଲ', 'ଜଳଦ', 'ଟସବ', 'ଜଗଣର', 'ରଧକ', 'ଖଙ', 'ଖପର', 'ଘଖଣ', 'ପଭ', 'ଚଣ', 'ଳନପ', 'ଆଳସ', 'ମଫଳ', 'କଭ', 'ଜନସ', 'ଠତର', 'ମଲନ', 'ଶବଗ', 'ଅପକ', 'ତଉଲ', 'ଖଭ', 'ହବକ', 'ନଛତ', 'ଭଲନ', 'ସମବତ', 'ଅତଳ', 'ୟସବ', 'ଆଖପ', 'ଳୟକ', 'ଆଲଫ', 'ଭବନଗ', 'ହଲଇ', 'ଈରସଙ', 'ପରଶ', 'ୟମଟ', 'ୟଭ', 'ରବମୟ', 'ଜଳଯ', 'ଁ\"', 'ଏକଦଶମ', 'ୁ,\"', 'ଦକମ', '800', 'ତଲର', 'ତରହର', 'ଉପଯ', 'ଯସକଳ', 'ଡସବ', 'ଉପନ', 'ସକଲ', 'ଏଫର', 'ମହଲତ', 'ଦଶଥର', 'ଇଣ', 'ଦଳସର', 'ଆଗସର', 'ଶଧରକ', 'ତମସ', 'ଶରଦ', 'ଭରପ', 'ଅବଗତ', 'େି।\"\\'', 'ଶକଟ', 'ଆଞ', 'ସବଲ', 'ତମନ', 'ଫଳଦ', 'ଗକର', 'ୈା', 'ଛମ', 'ଜଳସବ', 'ଦଳବଦ', 'ତନଜ', 'ଏଥମ', 'ନଯର', 'ଓମର', 'ନଘଟ', 'ନପଡ', 'ମଷଚ', 'ଅଢଇ', 'ଚଖଣ', 'ଢହ', 'ଦପଟ', 'ବଳଯ', 'ସମଭ', 'ଫଳକକ', 'ଳଟ', 'କରଚ', 'ପଣର', 'ଲସବ', 'ଷଯଗ', 'ଛଞ', 'ଷପକ', 'ତରସବ', 'ବଆଡ', 'ବଟକର', 'ଏକବ', 'ଗମଲ', 'ଯମଙ', 'ପରପ', 'ଦଖଲ', '୍)', 'ସସଜ', 'ସଲମ', 'ଦରଙ', \"୍।'\", 'ଲବକ', 'ତରଦ', 'ଟଗଣଙ', 'ଶନସ', 'ସଲଖ', 'ମଖ', 'ଏମନ', 'ଘଟକ', 'ଧମଧକ', 'ତରଫଳକ', 'ତମଯ', 'ନଦର', 'ପଲରକ', 'ଷରକ', 'ଟଞ', 'ଦଷ', 'ଗଛମ', 'ଟଐ', 'କଜ', 'ଓଜନର', 'ଉଧ', 'ଧଙ', 'ଅବସନ', 'ମନମ', 'ନଗଣମ', 'ଣସବ', 'ବତକକ', 'ଯଦରକ', 'ରଚଳ', 'ଛତ', 'ଆଖନକକ', 'ଆଯତ', 'ନନର', 'ଶଧରକକ', 'ସରମ', 'ଟଗତ', 'ଥଦ', 'ଥଶମ', 'ଦଥ', 'ଶଗଣ', 'ଦଫଳ', 'ଇଉଫ', 'ଟଅମ', 'ଷଯସବ', 'ନହରଯ', 'ଆଠବର', 'ଖଜର', 'ଇଞ', 'ମନଭ', 'ଣପଣ', 'ଟରମ', 'ଯସର', 'ଟବକକକ', 'ଧଯ', 'ଆନକ', 'ଏବଦର', 'ଗହର', 'ସତବ', 'ଡଇବ', 'ଳଠ', 'ୟଜର', 'ଋତକ', 'ଳରସ', 'କଟତମ', 'ଟହକ', 'ଟଯଲକ', 'ଦଇଗ', 'ଭକରକକ', \"ଁ'\", 'ପଥରସବ', 'ଏକର', 'ଇପଡ', 'ଅବନରର', 'ସମବଦନ', 'ଗଳଜନକ', 'ଅପରପ', 'କଲଣ', 'ରହମଲ', 'କବଚ', 'ଶତକକ', 'ପଦଗ', 'ସହସମ', 'ଏଲବ', 'ସମୟଲର', 'ଅଲଟ', 'ଦରଟ', 'ତଲଳ', \"େ?'\", '666', 'ଷଘ', 'ଶବଟ', 'ଳସବ', 'ଗଳକର', 'ଜଗଣଙ', 'ଠଧ', 'ଦଶପ', 'ଯମମ', 'କବରମ', 'ଭରକମ', 'ଅପସ', 'ଦସବ', 'ତଧ', 'ଏସର', '760', 'େ)।', 'ଏଶକ', 'ଡପର', 'ଭୟକ', 'କନନ', 'ଜନବ', 'ମଧର', 'ଦଳଗ', 'ଆଗନ', 'ଦଳନ', 'ଢଗ', 'ଧସ', '଼ି,', '60', 'ଉପଶମ', 'େ|', 'ଖଜଣ', 'କଣସ', 'ବକଗ', 'ପଥରର', 'ଧମକର', 'ଳଗଣ', 'ଏକଦଳ', 'ୟମଯ', 'ଷଣଯ', 'ଠମ', 'ୋେ', 'ଖତଦ', 'ଏକମନ', 'ଲଲଯ', 'ଲପର', 'େୁଃ', 'ଛଟପଟ', 'ଓଠ', 'ଚମକ', 'ଜଳପର', 'କମଇ', 'ଅଚ', \"ୁଁ।'\", 'ଳମଣ', 'ଡବ', 'ଝଲସ', 'ଆପର', 'ଝଟକ', 'ପନର', '଼ୁ।', 'ଆଟ', 'ଶକମ', 'ୟଜଣ', 'ଧଗଣ', 'ଯପଥ', 'ଛଗ', 'ତମର', 'ହପର', 'ନଗଛ', 'ସସଥ', 'ପସର', 'ଫଙ', 'କସର', 'ଶକଗଣ', 'ଛଦନକ', 'ରଧଭ', 'ଜଳଶ', 'ଦଭମ', 'ପସମ', 'ପଗଣ', 'ଚତନ', 'ଓକ', 'ଫଟତ', 'ଉଭୟକ', 'ଛଅହ', 'ଡପଗ', 'ପନସ', 'ବସଙ', 'ଭରମ', 'ଭରପତ', 'ୋ।\"', 'ଜଳଇ', 'ନଚତ', 'ପଟକ', 'ଥଲମ', 'ଉଟମ', 'ୟମକ', 'ଘରଦ', 'ଇଭଉଣ', 'ଘରଠ', 'ଈରସ', 'ନକହ', 'ଯମୟ', 'ଆଲକଜ', 'ତଫ', 'aaa', 'ପଦଣ', 'ରଥମପଶ', 'ୁ!\"', 'ି୍', 'ଜଳସମ', 'ଆଢ', 'ଆଦମକ', 'ଆଦମଙ', '130', 'ଏକପ', 'ଯରହ', '15', 'ବତଗଣର', 'ଶଲହର', 'ଏବରର', 'ପଲଗ', 'ତରହ', 'ଯରର', 'ଛଯ', 'ସଗଣଙ', 'ଶୟଗଣ', 'ଚଜଣଙ', 'ମଲକଙ', 'ମଲକଠ', 'ହରର', 'ଅଢ', 'କରଦ', '13', 'ଖନନ', 'ରଣକ', 'ପଥରଖଣ', 'ଦଲନ', 'ଓଟର', 'ଇଶହ', 'ଲହଲ', 'ଇସଗ', 'ଲଭସମ', 'ସସସସଗ', 'ନଗରସର', 'ଫସର', 'ଓମ', 'ଓନନକ', 'ତବସ', 'ବସଯ', 'ରତଦ', 'ଇଷବ', 'ଅଧକ', '14', 'େିଁ', 'ଧଠ', 'ସଗଣର', 'କଇଟ', 'ଲଯମ', 'ପଲମ', 'କବଦ', 'ଔରସର', 'ଥଳଭ', 'ହୟ', 'ତଟକ', 'ୁ-', 'ବକଟ', 'ଏଇଥ', 'େେ?\"', 'ନକଟକ', 'ଥଦଣ', 'ବଳଦକ', 'ଚରମ', 'ଯମଗ', 'ଡମ', 'ଅଠଇ', 'ୁ୍', 'ଗଳଦ', 'ଣଘଣ', 'ଣହସ', 'ୟକମ', 'ସଲଲକ', 'ପଥସବ', 'ପକଥନ', 'ଏକହ', 'େେୀ', 'ବଲଚ', '775', 'ଣକଡ', 'ତପଦ', 'ମଦମ', 'ମଦର', 'ଣପତ', 'ରକଟ', 'ଦମସ', 'ତଶ', \"ା'।\", 'ଠପର', 'ସତଦ', 'ମବସ', 'ଗୟ', 'ଖଳନ', 'ଅଣଚ', 'ଭସହ', 'ରଯକର', 'ଘନର', 'ନତକ', 'ହନର', 'ଠପଟ', 'ସରଞ', '୍!\"', 'ଚପ', 'ଦହନ', \"େ!'\", 'ଗବତ', 'ସହୟ', 'ାଃ-', 'ଈପର', 'ଧପର', 'ଇନଥ', 'କସବ', 'ତହନ', 'ଶପଥକ', 'ଓଗର', 'ଇତସ', 'ତୟ', 'ଐନନ', 'ଟପଣ', 'ଭଲମନ', 'ଟଫ', 'ଅଠତ', 'ଗଣମ', 'ଟପର', 'ଠମଯ', 'ତରମଯ', 'ଟସକ', 'ନହକ', 'ଟହର', 'ଅପକର', 'ପଥରମ', 'ସଧ', 'ଶଯନକ', 'ନଜଳ', 'ପକକ', 'ବଢନ', 'ଟଲକ', 'ଫଳସବ', 'ଭଳନ', 'ଟଆଳ', 'ୟସ', 'ଭୟତ', 'ଗଦଅଣ', 'ଶପକ', 'ଦଶହଜ', 'ଛସବ', 'ାଃ', 'ପଡକ', 'ଟଇପକ', 'ଆଶରଙ', 'ଗଚର', 'ାେଁ', 'ତଗକ', 'ଭଅ', 'ରଣକକ', 'ପତକ', 'ପଛକକ', 'ଯଗକ', 'ଠକଲ', 'ସମତଳଭ', 'ଐ', 'ୟଗଣଙ', 'ସମୟରକ', 'ମଗକ', 'ଅଫକ', 'ଅଶର', 'ଥଠ', 'ଆଶନ', 'ବଟ', 'ମହନ', 'ଟରଣ', 'ଟଅଛକ', 'ଟଚରମ', 'ଅତଯବ', 'ଥକକ', 'ଐକ', 'ନବତ', 'ସହଚର', 'ନରଖ', 'ଆଫ', '୍।\"\\'', 'ଆକସ', 'ଟଳନ', 'ସଲମକ', 'ଥରକକ', 'ଭରକଙ', 'ଟଇମ', 'ଦଟ', 'ଇବସନ', 'ଦଶବର', 'ଜଠ', 'ମଉଜ', 'ଥଲଠ', 'ଭରକଗଣ', 'ୟଜଙ', 'ଠଭ', 'ୟକକଥର', 'ତନପ', 'ଛଜ', 'ଅଠ', 'ସମକକ', 'ବଖ', 'ଉଲକକ', 'ବତଇ', 'ବଇ', 'ଲଗଲ', 'ବଡପ', 'ରବଦ', 'ଜପଦ', 'ଅବନ', 'ଣପର', 'ହଖ', 'ଡଉଛନ', 'ଆରଣ', 'ସଦପ', 'ବହଙ', 'ରହମ', 'ଚପଦସ', 'ମଯର', 'ଷବର', 'ଓବଦଇଦ', 'ଉଲଠ', '100ଟ', '18', 'ଥରର', \"ା?'\", 'ତଯକକ', 'ହଶଙ', 'ଖସର', 'ଲନସମ', 'ସବଲଳ', 'ଲୟଲସଲ', 'ସଦଇ', 'ଦଳପତ', 'ଦଭକ', 'ଅକଳନ', 'ସସଗ', 'ସକଲତକ', 'ଇଧ', 'ତସସମ', 'ଯସଦଶ', 'ବହତ', 'ଓଠର', 'ଆସନର', 'ତହପନ', 'ଶମରଙ', 'ଇଷବଲର', 'ହଳକ', 'ଉଭ', 'ଭଇବ', 'ଇଷବଲ', 'ଯକଙ', 'ି?\"\\'', 'ପଥଟ', 'ଉଗ', 'ଯତର', 'ରଯବ', 'ରହସଙ', 'ଦଯନ', 'ସଦଲଲ', 'ପଲକହ', 'ମଲଶକର', 'ନସହ', 'ଚପର', 'ନଗରଠ', 'ଯମସବ', 'ମତର', 'ଓବଦଙ', 'ଯଦଙ', 'ଅହବ', 'ଯହଦ', 'ମଦମନ', 'ଐଟମ', 'ବସମ', 'ଆସସ', 'ୟହଦ', 'ଖରଙ', 'ଶହର', 'ଉଲମ', 'ଦନଙ', '26', 'ହସନ', 'ଉଷଙ', 'ଯଦଳଙ', 'ପରମମ', 'ଅରଣନର', 'ପଥରକଟ', 'ଛଅଜଣ', 'ଦୟଙ', 'ଦଖଯଙ', 'ଦଶତମ', 'ଅସସ', 'ଷତମ', 'ଯମତ', 'ଚଗ', 'ଆରବର', 'ପବଯସ', 'ଅମସ', 'ନଗରପ', 'ଥସବ', 'ଧନରତ', 'ଟକଠ', 'ତରତର', 'କମନଙ', 'ଶବସର', '254', 'ଦରର', 'ଦଦର', 'ଶଥର', 'ଦଥଯ', 'ପଶହ', 'ହଖଲ', 'ଉପରଭ', 'ଥକମ', 'ନହମ', 'ଇଏ', 'ହଗଯ', 'ତଜନକ', 'ଘରଗ', 'ଇଦଇ', 'ବଣର', 'ନଳବଣ', 'ଯପଥର', 'ମନଦଇ', 'ପଦସବ', 'ଦଲକ', 'ତଋତ', 'ନଦଣ', 'ଆମନ', 'ରଖର', 'ବନଶ', 'ସମଯର', 'ଅବଶଷ', 'ଜନଠ', 'ବନପଥ', 'ବଗର', 'ଚଳନ', 'ଗଗନ', 'ରମଠ', 'ୟକକକ', 'ଆହରଣ', 'ବଗଗ', 'ପରନ', 'ଯଯର', 'ଆପଦ', 'ହଳପ', 'ଗଏ', 'ଚଳଣ', 'ଳନକ', 'ପପର', 'ଘରଚଟ', 'ଯସହବ', 'ନସହବ', 'ତସହଲବ', 'ଆଲଲ', 'ଜଳଜ', 'ଜଗତବ', 'ଠନକ', 'ତରବ', 'କଦରର', 'ବଗଣକ', 'ଡତ', 'ରଭଳ', 'ଜପଥର', 'ଅପହରଣକ', 'କସହବ', 'ଆଦରଣ', 'ଜନମ', 'ମରଣଶ', 'ଭବଦନ', 'ଣମନ', 'କରଣକ', 'ପଦତଳ', 'ଲରଙ', \"ୁ,'\", 'କଅଣ', 'ଆମଠ', 'ଧନସବ', 'ଲଦବ', 'ତଗମନ', 'ବରକନ', 'ଗଣକମ', 'ରଯପତ', \"ା,'\", 'ଏବଦମଲକ', 'ଜଳମଗ', \"୍'\", 'ଆବନ', 'ଆଣବ', 'ଢଭ', 'ସଫଳକ', 'ଦଶଶ', 'ଉଲଯ', 'ରବତ', 'ଠଖଣ', 'ୋଂ', 'ବୟସର', 'ଉଦୟ', 'ଆରପଟ', 'ୟତକ', \"ୁ?'\", 'ଛଇ', 'ଓଲଟଇ', 'ଭବନ', 'ଅତରତକ', 'ନଉଥ', 'ତକଡ', 'ୁ(', 'ରଇବ', 'ଅଶଷ', 'ଜନଗଣନ', 'ଆସନଟ', 'ଏଇଟ', '(\"', 'ଠଇବ', 'ରଣଙ', '?\")', 'ହତବ', 'ବଚସ', 'ୟଣ', 'ଷୟମ', 'ଜଳପଥର', 'ରହଜନକ', 'ଭରଷ', 'ଣବବ', 'ଷୟସବ', 'ତସକ', 'ସହନଶ', 'ଥପରତ', 'ଉଇଲ', 'ପହରଣ', 'ହଦଣ', 'ଶଜଣ', \"ୋ'\", 'ଏକହଜ', 'ଜଳଠ', 'ଚଷଠ', 'ରଳଯଙ', 'ହଜକ', 'ରଳଯ', 'ଉତଗ', 'ା)।', 'ୟବନର', 'କଲହର', 'ଶମଙ', 'ଷଦର', 'ଅଲମ', 'ଓବଲ', 'ଫକଷଦର', '403', 'ଏବରକ', '430', 'ପଲଗକ', 'ତରହକ', '9', 'ରଣଠ', 'ମବର', 'ଆନର', 'ଲହଯ', 'ବରଦ', 'ଆଠଦ', 'କଗଣଙ', 'ାଁ!', 'ଧବସ', 'ତଧର', 'ନହର', 'ସମୟପର', 'ସଜଣଙ', 'ଧବମ', 'ଓଟଗ', 'ଇଲଦ', '17', 'ଉଦରର', 'ବନବ', 'ଯଗଣର', 'ା\"।', 'ଯବତ', 'କଳଶ', 'ପଲସବ', 'ରସଦଖ', 'ଶଲଷସର', 'ଓସଯ', 'ପଲରସସ', 'ଇସମ', 'ସସଯ', 'ମସଦଲଲ', 'ଣଜ', 'କବକ', 'ସମତକ', 'ଫସକ', 'ଓନମ', 'ହଦର', 'ଈରମ', 'ା.', 'ଐନମ', 'ନପତ', 'ବନଇବ', 'ଣହ', 'ଫନତ', 'ରରନ', 'ମହଜ', 'ନଆଣ', 'ପଟଗ', '29', 'ଚବର', 'ଏବବ', 'ଓହଦ', 'ୟହଲଲ', 'ଅସବଲ', 'ଶନକ', 'ଆବଗ', 'ରସଠ', 'ଯଭକ', '।\"\"', 'ଆଟଦର', 'ବଚନ', '110', 'ନଳବନ', 'ଣଇବ', 'ଯବସର', 'ବଯମ', 'ପଦମ', 'ୋଃ।', '137', 'ବଥମ', 'ଳଦଳ', 'ଧବନ', 'ଆଗଇବ', 'ତମଦ', 'ମରଣର', 'ବସଟ', 'ଟବଣ', 'େ!\"', 'ଦଶପତ', 'ନକତ', 'ଉଞ', 'ଷତଟ', 'ସବଟ', 'ବଓ', 'ପଶର', 'ୟତର', 'ଗହମର', 'ଅୟ', 'ନମନ', 'ଜଯର', 'ଦଶଆଜ', 'ଓଢଣ', 'ଖଚନ', 'ସମପର', 'ଣପଟ', 'ଳଧ', '730', '550', 'ମରକତ', 'ଶପଥର', 'ଲବଣକ', 'ରଥମଟ', 'ବହନକର', 'ଆଦଶ', 'ଜଳଚର', 'ଚରଳ', 'ଅଭକ', 'ରସବର', 'ରମହ', 'ଛଦନର', 'ନଧ', 'ବତନଜ', 'ସକଳବ', 'କଣସବ', 'ପଇ', 'ପଦବ', 'ଣଥ', 'ଶଭ', 'ଅଝଡ', 'ଫଳଧ', 'ତଳତ', 'ିଁା', 'ଐନନର', 'ଜକକର', 'ଷକର', 'ରଜନନ', 'ସମନ', 'ଉପରର', 'ଚଦ', 'ୁ?\"\\'', 'ୁ;', 'ସଥ', 'ସକରନ', 'ସସସ', 'ନଇନ', 'ନଜନ', 'ଅଥ', 'ଘପଥ', 'ଆରର', 'ଷଯପ', 'ୀ:', 'ରଚଳନ', '୍;', 'ଳଯର', \"ି!'\", 'ଷଷଠ', 'ଶଫର', 'ମଖଲ', 'ଗବରର', 'ଣଯର', 'ଗରଠ', 'ଐନର', 'ଇପତ', 'ତରରକ', 'ଶନକକ', 'ଖଟଟ', 'ନକଟ', 'ଦଯତ', 'ଚଉକ', 'ଅସବ', 'ଇଛକ', 'ଟଳତ', 'ଷମଯ', 'ଟମଯ', 'ଉପଲବ', 'ଳରକ', 'ବଯକକ', 'ଫଳକଦ', 'ୟଟବ', 'ତଦନକ', 'ନବସ', 'ଏକକ', 'ଞଦବ', 'ଦଗମନ', 'ଭଲର', 'ାେ)', 'ବନଗ', 'ବନଛ', 'ଟଇଫ', 'ଟଛକ', 'ଶମଧ', 'ଯମରକ', 'ଟଇଗ', 'ମଧରକ', 'ଯଛଡ', 'ରପଥ', 'ଟପକ', 'ତଦବ', 'ଈକକ', 'ଠତ', 'ଟଇଗକ', 'ଟଆମ', 'ଯମଗକ', 'ପଡନ', 'ଇଜଣକ', 'ଅଚଞ', 'ଚଢଳ', 'ରବଗ', 'ମନୟ', 'ମନକକ', 'ଟଶଳତ', 'ଉଅଛକ', 'ଟସରଣକ', 'ଟରପକ', 'ତକକକ', 'ପଠନ', 'ଗଚରଙ', 'ଗରକକ', 'ପଥରଗକ', 'ପଛପଟର', 'ହବକକ', 'ଦଳଟ', 'ୂଁ', 'ଗଲରକ', 'ଟଆପଥର', 'ସଐକ', 'ଗଲଠ', 'ରଥଗକ', 'ନଗଭ', 'ଗନକ', 'ଅଫକର', 'ଗଶକ', 'ତଭର', 'ବରଟ', 'ଲଢକ', 'କନସର', 'ନଗଭର', 'ଜଳସ', 'ଇଲତ', 'ମଥତ', 'ଶଧରର', 'ସହରଟ', 'ଏମକ', 'ସହରସବ', 'କସକ', 'ଏବସ', 'ଲକତ', 'ଯଳଯ', 'ଓଶ', 'ସତକଥ', 'େେ!', 'ଳନକର', 'ପଦରକ', 'ଗପଥ', 'ଖନକ', 'ଏହକ', 'କଖ', 'ତବକ', 'ଟଜକ', 'ଇଖ', 'ଟଦଇ', 'ଦଶକ', 'ରକକକ', 'କଐମ', 'ଜଳତ', 'ଦଳପର', 'ଟଚକ', 'ଦଶଜଣଙ', 'ଯନମ', 'ଯଦଳକକ', 'ନରଙ', 'ଦଅ', 'କଗଣଠ', 'ଗଡର', 'ଲଲର', 'ଶମବସ', 'ଭତକ', 'ଏଟମ', 'ଟଆଇ', 'ନରନ', 'ଦଶଖଣ', 'କଗକ', 'ଅଗମ', 'ଗଧପ', 'ଧଲ', 'ଆଲକ', 'କଗଣର', 'ଇଦଲ', 'ଯଭଦ', 'େୈ', 'ବପଟ', 'ଟଆଡ', 'ଋତଙ', 'ହମର', 'ରସରକ', 'ଟଚର', 'ହଫନ', 'ଶଗଡକକ', 'ଦରବ', 'ଶସହ', 'କଢଇ', 'ଟଅଙ', 'ଥଳରକ', 'ଭୟଥ', 'ଟବକଙ', \"ା',\", 'ବଣକକ', 'ଟଫଣ', 'ଟଆଟ', 'ଟଆଇବ', 'ଅଯକ', 'ଦଳକକ', 'ପରକକ', 'ଋଣଗ', 'ଟମନ', 'ଫକକ', 'ବଲକକ', 'ଜଣଇବ', 'ଥସବଳ', 'ଲଗକକ', 'ଥଶ', '360', 'ଶତଙ', 'ଫଲଟ', 'ଭରକଗଣଙ', 'ତଯନ', 'ଲଗକ', 'ଆଣକ', 'ଜଜ', 'କରଛନ', 'ଘଉଡଇ', 'ଇକକ', 'ଆପମ', 'ତରଫରକ', 'ଫଲକକ', 'ହଶଯ', 'ଫଲଙ', 'ଲନସଯ', 'ସଦଖନ', 'ରଣସଲ', 'ବରସର', 'ଆପଣସସମ', 'ତସକହ', 'ଟସଦଖ', 'ଟସସ', 'ମସଗ', 'ସହଉଛ', 'ଲଭସହଉଛସମ', 'ଲତସଗ', 'ସନଇଗଲଲ', 'ଆପଣସମ', 'ସହତକ', 'ପଦସର', 'ଟସଫର', 'ସଦବ', 'ତରସଦଲଲ', 'ଇଗଲଲ', 'ସସଲତଲବଲଳ', 'ଚସର', 'ଅପଲକ', 'ପଧମ', 'କଇବ', 'ଶବତ', 'ଯହବ', 'ପଦପ', 'ଅନଭ', 'ଅଗଣନ', 'ଯଦସ', 'ଏରସକ', 'ବଢଇମ', 'ଆରବନ', 'ଏକଧ', 'ଯସସ', 'ପଥରସର', 'ରସଗ', 'ଓସସହ', 'ଓସଗ', 'ଭସର', 'କଣସର', 'ଦଲଢହ', 'ଣସର', 'ଠଲସ', 'ସଛ', 'ଆଲଦଶସଦଲଲ', 'ରରସକ', 'ଶସମ', 'ରହପ', 'ଷଜ', 'ହକଗଣ', 'ଲକର', 'ଛଅମ', 'ଅପରନ', 'ଏକଗ', 'ଈଷବଲକ', 'ଷଭଟ', 'ଫଟର', 'ଗପଲ', 'ଭରନ', 'ଝରର', 'କରଥ', 'ଯଞ', 'ୟଲ', 'େୂ,', 'ଇଷବଲକ', 'ଖତପର', 'ମଷଠ', 'ତନକ', 'ଜମନ', 'ଅଣଗ', 'ଲମଙ', 'ହକଦ', 'ରସସ', 'ପଲଯ', 'ତକଲର', 'ହଲହ', 'ରଜକର', 'ଏସରହଦ', 'ବଲଦନର', 'ଉଷର', 'ବବଧ', 'ଦକଙ', 'ବରଖ', 'ଆହସର', 'ଫରତ', 'ବଧକଲ', 'ଉନବ', '),', 'ଊସ', 'ଶଲହଙ', ':-', 'ଓତସମ', 'ଲବରଙ', 'ୟହତଙ', 'ମରଦଙ', 'ମଗତ', 'ଷହ', 'ହସଙ', 'ଦଶଗ', 'ଲନର', 'ବରତ', 'ପରବ', 'ଉଲମଙ', 'ଉଷନ', 'ତଲହ', 'ଶହରଯ', 'ଶଖ', 'ଲଥଯ', 'ସଖର', 'ଇଶବ', 'ଊଥଯ', 'ଟଲମ', 'ବପତ', 'ଯକଗଣ', 'ରବଳତର', 'ପଟଇ', 'ଇଲହ', 'ଶମନ', 'ୁ଼', '220', '112', 'ଫଲହ', 'ଦରତ', 'ସହରବ', '11', '38', 'ଊନବ', 'ଦଲତ', 'ମମତ', 'ଏଷର', 'ୟଶବକ', 'ଲଥ', 'ମଶଲ', 'ତରପ', 'ହଷବ', 'ପଟନ', 'ନମମ', 'ରଘର', 'ମଜଗ', 'ଲଭଳ', 'ପବଳ', 'ହତଚକ', 'କଶ', 'ଏକଚ', 'ଫରକ', 'ୁୁ', 'ଶଯନକକ', 'ଦଳଭ', 'ହରଣକ', 'ବଳଦର', 'ଗଳକ', 'ଓଫଲ', 'ଲଶନ', '372', 'ଆରହର', 'କଯର', '98', '223', '95', '42', '743', '52', '247', '128', 'ଆଟର', 'ଗସମ', 'ତମହ', 'ତଲମ', '652', '337', '245', '435', 'ା:-', 'ନଆସ', 'ଜସମ', 'ଖତର', 'ଅଦନ', 'ବବଯ', 'ଲଟର', \"େ,'\", 'ଋକ', 'ମଶଷ', 'ଶଧରଗ', 'ପଲଲ', 'ଦଳଦଳ', 'ଉପରଦଇ', 'ରଦଶ', 'ଖନର', 'ହଗଯର', 'ଜଭଣ', 'ଖକମ', 'ହଥକ', 'ବଶନ', 'ଟରଙ', 'ଚପଦ', 'ଖଯ', 'ଷସମର', 'ଲଦଦ', 'ଜଳବ', 'ଖସଡ', 'ସମୟଗ', 'ଫଳତ', '଼େି', 'ବତସବ', 'ଷଭଳ', 'ରଗଡ', 'ଇପର', 'ଇରହ', 'ବରଫର', 'ପଥରଠ', 'ପଠଇବ', 'ଝଲମଲ', 'ଆପଥରର', 'ଏରସବ', 'ଇହଲ', 'ଉଥଲ', 'ଦଲଖଣ', 'ୁ\"।', 'କରଣର', 'ଛର', 'ଗହଣର', 'ଯଯନ', 'ଉପବନ', 'ଖମଯ', 'ଜଣର', 'ରମଜ', 'ଖଠ', 'ଶବଦ', 'ଚଡ', 'ମନଇଚ', 'ଧବଣ', 'ଉଙ', 'ରକଥ', 'ଋଣର', 'ରତର', '଼ି।', 'ରଟନ', 'ଣବତ', 'ଚଷ', 'ମରଣକ', 'ଜଯୟ', 'ମଗର', 'ମନପସନ', 'ନଜକ', 'ିଁ,\"', 'ଦଜନକ', 'ଗଗଣର', 'ତନୟ', 'ଳଚ', 'ଡଦ', 'ଭରଣପ', 'ତମଗ', 'ଘଷ', 'ନସମ', 'ଷଲତର', 'ରସସହ', 'ନଲବ', 'ରସଦଶସର', 'ସଶ', 'ଲନସଭ', 'ନସଲ', 'ଆସଲ', 'ସହଲବ', 'ଲନସସମ', 'ଓସଲ', 'ରସସମ', 'ମସହ', 'ପବନସର', 'ଡସଦଲବ', 'କଲତ', 'ଇବଲ', 'ଶସର', 'ଲନସଲ', 'ପଛସର', 'ସକହ', 'ରସଯ', 'ସଫଳସହବ', 'ସସଲତଲବଲଳସସମ', 'ରସମ', 'ବରମ', 'ତସହବ', 'ଣସହବ', 'ଯରତ', 'ପଥରଦ', 'ଆଗଣ', 'ରଣଯନକ', 'ଅଭୟ', 'ଯଛ', 'ଛଣପଟ', 'ଟଳଟଳ', \"଼।'\", 'ତଫଳ', 'ଫଳଶ', 'ବଳସ', 'ରଳଯର', 'ପଦଚ', 'ଶବମ', 'କଳନ', 'ଚଭ', 'ମଲତ', 'ଜଳଲଷ', 'ଯତସର', 'ସଦବତ', 'ଲନସଯପର', 'ମସଭ', 'ମଲଘ', 'ଦଲଉ', 'ଲଭସକ', 'ତସହବସବ', 'ଜପଥଗ', 'ମଦପ', 'ଭକଥ', 'ଛକସ', 'ଫତର', 'ଛକମ', 'ଅକବ', 'ଲଶ', 'ନନକ', 'ଆଠଜଣ', 'ଆମପ', 'ଜଗଣକ', 'ୁା', 'ଘଞ', 'ଏଲମକ', \"଼ି'\", '଼େେ', 'ଜନବସତ', 'ଚକମ', 'ତରଞ', 'ତଜର', 'ଆଚରଣକ', 'ହଗଣ', 'ରବବ', 'ଶନଗ', 'ଳରଙ', 'ଆଚମ', 'ଚହଲ', 'ତବତ', 'କବରଗ', 'ଶଧ', 'ଞର', 'ଭତର', 'ଶପର', 'ଯଧର', 'ମରଠ', 'ଞକ', 'ଜରକ', 'ଢତ', 'ଠକର', 'ଶୟକ', 'ଜପର', 'ବହର', 'ଭରପର', 'ଜଳମଯ', 'ଯଖଳ', 'ଭକଲ', 'ଆବନର', 'ଗଛପର', 'କଳଦନ', 'କତକ', 'ଏକହଳ', 'ତତମ', 'ବରଗ', 'ଗଦବ', 'ଏବଠ', 'ଚରକ', 'ଶଆଡ', 'ଇନବ', 'ମନପର', 'ଇବନ', 'ଖଇବ', 'କଡମଡ', 'ଲହଡ', 'ଷୟଟ', 'ଜଣଇ', 'ଯକହ', 'ଚଢଇମ', 'ଖକଷ', 'ଛତକ', 'ତଷ', 'ଚହଳ', 'ୟତଙ', 'ହଭ', 'ନରମ', 'ଭବନର', 'ପଳଇବ', 'ବଭଳ', 'ଗପତ', 'ଲରସ', 'ପଚର', 'ଉଚର', 'ଆଳମ', 'ହଇୟ', 'ଡତକ', 'ୋ\"', \"େି'।\", 'ମଋତ', 'ଦଇଯ', 'ଗଡଇ', 'ୟଫ', 'ସଦୟ', 'ଧଇ', 'ଣଇ', 'ଂ,', 'କତର', 'ଚଢଇଙ', 'ବଡବଡ', 'ଏଡ', 'ଖତସ', 'ବଳମ', 'ମତକ', 'ସମୟଟ', 'ଗହମକ', 'କବରଟ', 'ଟଇବ', '।\")', 'ଆଉଜଣ', 'ବରଗଣ', 'ତରମଣ', 'ଗଲଗଥ', 'ମସପ', 'ଛଅନ', 'ଫଫ', 'ପଫ', 'ମତଭଦ', 'ମତଇ', 'ଆରୟପ', '୍\\u200d', 'ହଜନକ', 'ସହଯ', 'ପଦଜନକ', 'କଟଇବ', 'ବନରକ', 'ପରଚର', 'ପରହ', 'ଦୟଗ', 'ଆଦମର', 'ତଗଛର', 'ଳନର', 'ସମଲ', 'as', 'hath', 'every', 'so', 'ଷଲ', 'ଏକଆ', '\",', 'ଧକତ', 'ବଦହ', 'ଦରମ', 'ନତସହବ', 'ମସଦଇଛନ', 'ଲରସସମ', 'ୟମପ', 'ସସସମ', 'ଭଜନ', 'ଷରତ', 'ିଁ।\",', 'ସହବନ', 'ବଶବର', 'ିଁ।)', 'ଫରଙ', 'ତନତ', 'କପଲ', 'ତଚରମ', 'ମରକତମଣ', 'ଘଧନ', 'ଜଳଚ', 'ଗମନଶ', 'ତସନ', 'ତବଢ', 'ଣଯମ', 'ଏବଲଙ', 'ଈରଦ', 'ଈରଦର', '930', '105', '807', '912', '815', '905', '840', '910', '830', '895', '162', '962', '65', '365', '187', '782', '969', '182', 'ଘବ', '595', '777', '0ଦ', 'ଦଶମମ', 'ୃଂ', '601', 'ଫଳବନ', 'ରବଣତ', 'ଏହର', '950', 'ଏରକ', 'କଲହ', 'ଊଷଲ', 'ତଲକ', 'ନଭଶ', 'ଫକଷଦ', 'ଶଲହକ', '34', 'ପଲଗର', '209', '207', '205', 'ସଜଳ', 'ଐଣ', 'ଚଙ', 'ଆନରର', '318', 'earth', 'ୟକଗଣ', 'ଊରଠ', 'ଯଳନ', 'କନଜ', 'ପଦଧ', 'ଏହପର', 'ମଧସ', 'ନଝ', 'ଲଦଶ', 'ଲଫ', 'ଟବହ', 'ଗହନ', 'ତହଶ', 'ଡକର', 'ଘତଳ', 'ମନହରଯ', 'ତଳମ', 'ସଜଣକ', 'ଅଧଭର', 'ଁି।\"', 'ଲହଯର', 'ଆୟବ', 'ପଲପଲ', 'ଏଷକ', 'ୌ!', 'ଆଅ', 'ୌ?\"', 'ଡତଳ', 'େୀ।', 'ଭଊଣ', 'ଇଆଣ', 'ଗଳମ', 'ଗଳନମ', 'ତନଖ', 'ଯଇ', 'ଲଯଦ', 'ଚଉତ', 'ଭୟନ', 'ରହକର', 'ପଥରଗଦ', 'ାା\"', 'ଗଲଯଦ', 'ଈଛଳ', 'ସବତ', 'ଧବତ', 'ଈଓଟ', 'ଶହସଲ', 'ସଲୟ', 'ଲନସଗ', 'ଲଷଫସଗ', 'ଆଲଗ', 'ପଲଛସଲୟ', 'ଲଷଫକ', 'ସସସଯଲତଲବଲଳ', 'ଲଲସସ', 'ପଲରସଲୟ', 'ଲଷଫ', 'ସମୟଲରସଯଉ', 'ନଲଉଛନ', 'ଭରସମ', 'ରସଦବ', 'ତବସର', 'ଛସତଲବସମ', 'ସଦଇଅଛ', 'ସଦଯସହ', 'ଣସମ', 'ନଗଣସଛ', 'ବକସଗ', 'ଟସନଇୟ', 'ଏସତଲବ', 'ରଣସମ', 'ନସରସସ', 'ଶଳସର', 'ନସଦଶସ', 'ହସମ', 'ଏକଶ', 'ମକସର', 'ଲଦଇସସହ', 'ବସସଠ', 'ବସସହ', 'ଇଲଣ', 'ଯଥର', '180', 'ଅବଲନ', 'ଲହନ', 'ଶନଙ', 'ବଦଦର', 'ଗରଖ', 'ଏରର', 'ଶଶ', 'ଐନମର', 'କରଗ', 'ବପକ', 'ହକର', 'ଦଶଭ', 'ୟଶଷ', 'ସଫଇ', 'ଶକଟମ', 'ଦଶଗଧ', 'ବରଯର', 'ହଳଜଣ', '66', 'ଆପଦଜନକ', 'ହନପ', 'ସଫଲ', 'କବରଶ', 'ବଳଦଗ', 'ପରଧଯ', 'ଧବଳ', 'ଳକଠ', 'ଃୁ', 'ଜନଙ', 'ଦନପ', 'ମପଟକ', 'ାେ!\"', 'ନଶକ', '133', 'ନହସକ', 'ସହପର', 'ଟକଲ', 'ୟବଗ', 'ଏଇଥରକ', 'ଳଦଳକ', 'ଶରବସ', 'କଏଦ', '43', '0ବର', 'ଗନବ', 'ରଭଛ', 'େୁ?', 'ଘନମ', 'ମପଟ', 'ଡଉଥ', 'ଥପନ', 'ପଖ', 'ଉଶ', 'ନଭଣ', 'ଘଡଘଡ', 'ବତଟ', 'ନଟକ', 'ଯଗଦ', \"େଁ'\", 'ପଥହର', 'ରତଳ', 'ତମବର', 'ଁଁ', 'ଷଭମ', 'ମଳତ', 'ଣକପଡ', 'ଛଅଖଣ', 'ଏହଳ', 'ହଳଟ', 'ରକଡ', 'ଗଣଟ', 'ଧପଟ', '୍ା', 'ୟକକଦ', 'ଚଶତ', 'ଇଶତ', 'ଦପର', 'ଆଛନ', 'ଫଲକର', ',,', 'ଗରଗଣ', 'ତରପଟ', 'ପଛପ', 'ଛଡସବ', 'ମକଙ', '03', 'କମରବନ', 'ଁି', 'ରମମ', 'ମଦତ', 'ତରଖ', 'ଞବବଦ', 'ଉପଲକ', 'ଞବତ', 'ଚଧ', 'ଫନକ', 'ଜଳଜନ', 'ଜଳଚରମ', 'ମସପକ', 'ଘଗଳ', 'ଡନଳ', 'ଉଡନ', 'ଛଅଷଠ', 'ଗଜନ', 'ବକଳ', 'ଛଉଥ', 'ରଆଡ', 'ହରସ', 'ଛଉର', 'ତନଗଣଙ', 'ନଜଣ', 'ଛଦକ', 'ଇହସ', 'ଶଣବସ', 'ଏକଥର', 'ଆରକ', 'ୟଜକ', 'ନତପ', 'ବନପଶ', 'ନବମବର', 'ଦବମ', 'ଜବପନ', 'ଦଶସହସ', 'ଅଘଟଣମ', 'ତଦହ', 'ରଝଡ', 'ନଣ', 'ଐନରର', 'କନଙ', '୍ୋ', 'ଶଦଯ', 'ହଯଲର', 'ଗଳଗ', 'ଭସମସ', 'ୟସମସ', 'ତଶବକ', 'ଉସର', 'ତଦନନ', 'ରଣବ', 'ଶଦଯର', 'ବବକ', 'ଯଅଛ', 'ରବଳଇଚ', 'ତରଭ', 'ିଁ,।\"', \"ା!'\", 'େଁ!\"', 'ଇଲଦଦ', 'ଶଲର', 'ଧନଷ', 'ନହବ', 'ଶରସ', 'ଫଳୟ', 'ନଫଲ', 'ଅମନ', 'ଅପଖ', 'ଷହରର', 'ପଲତର', 'ଯମତମ', 'ବଫଳ', 'ହଜଳ', 'ଦଇୟ', 'ଯହର', 'ୟହସଠ', 'ଫହ', 'ମପଣ', 'ୀଂ', 'ଶଭଦ', 'ଲପଯ', 'ନହସଙ', 'ସରହଠ', 'ଲୟଠ', 'ୟହଲଲଠ', 'ଈଯଷ', 'ଈଯ', 'ଲକଠ', 'ଖମଠ', 'ହଫରଠ', 'ଥଲହଠ', 'ଖରଠ', 'ତହନଠ', 'ଥଲହର', 'ଏରଣଠ', 'ଏରଣ', 'ଅସବଲଠ', 'ଫମଠ', 'ହମଠ', 'ହବରଠ', 'ସରଠ', 'କବଦଠ', 'ବଯଜ', 'ଓସମସ', 'ରସଭ', 'ଢଦ', 'ଓପଯ', 'ଦନତ', 'ଚଶହ', 'ଏକଷଠ', 'କଗଣକ', 'ନମଲ', 'ଅଟର', 'ଜଗବ', 'ଏଥମର', 'ଲସଫ', 'କନର', 'ହଗଦଗଦ', 'ରଗଦଗ', 'ଐନନଠ', 'ଅଠଚ', 'େେ;', 'ଶଫଙ', 'ନକଟସ', 'ଓଗକକ', 'ଜଣଜଣକକ', 'ଫଳଧର', 'ଧଅସ', 'ଖଦଇ', 'ପଥଠ', 'ସରନ', 'ନକଟକକ', 'ସଷବ', 'ଜଣବ', 'ନରତ', 'ଗଗନର', 'ତକଲ', 'ଟଇଖଣ', 'ସନସବ', 'ବମଗ', 'ସଳକ', 'ଭଫଳ', 'ଭୟୟକ', 'ଶପଥପ', 'ବଳବତ', 'କନଠ', 'ଜନବର', 'ଗମନକର', 'ଜଳତକ', 'ଶଧରଗଣର', '?,', 'ଶକକକ', 'ଟରକକ', 'ଟକଐ', 'ରଧରକ', 'ଗବୟ', 'ଚମର', 'ଶବକକ', 'ଡଭଙ', 'ଭମଚ', 'ତରଭର', 'ଧଣ', 'ଛବର', 'ବତନର', 'ଆଗଚଟକ', 'ମନରକ', 'ପଥରଚ', 'ଟବଳଦ', 'ନଫଳକ', 'ଏକସ', 'ଓଠରକ', 'କଳକ', 'ଯଦଲ', 'ଅପହରଣକର', 'ୟଳୟକ', 'ଥରରକ', 'ଟଇଭ', 'ଦବରର', 'ଏଥପ', 'ଦରଭ', 'ବଥଦ', 'ଷନକ', 'ଟଳର', 'ରସକର', 'ଗଇଛନ', 'ଷଗଣଠ', 'ଶନଦ', 'ଟଆଇଲ', 'ଳଦକ', 'ଧରଣ', 'ଗଧନ', 'ଟଆପର', 'ପଦରସ', 'ଟୟକ', 'ଟସଜ', 'ଠଗଦ', 'ଯବଧ', 'ଦନକକ', 'ଦନରକ', 'ହରଲ', 'ୃ?\"', 'ସଶସ', 'ହବସ', 'ଅଧମକ', 'ଅଯପ', 'ୈ', 'ନଯଗଣ', 'ଟଉ', 'ଏଯ', 'ଟକବ', 'କପଟଭ', 'ନମକ', 'ଭଇଲ', 'ଡଅ', 'ପଛରକ', 'ରଖଲ', 'ଷଫର', 'ଆରବଙ', 'ଦଫ', 'ଯଲମ', 'ରଯର', 'ବତଗକ', 'ଟବନର', 'ରନକ', 'ସମତଳର', 'ବଟନ', 'ଆନଙ', 'ଗଧରକ', 'ହଦତ', 'ଗଦଲଗ', 'ଲହମମ', 'ଅଶନ', 'ଶରନଦ', 'ହଲହକ', 'ଲବଣନଗର', 'ୟଫଲଟ', 'ଥକସ', 'ହଗଲ', 'ପଟରକ', 'ସପୟ', 'ଉପସହର', 'ଯଥବ', 'ଐନଶମ', 'ଥଆରବ', 'ଅଫନ', 'ତରଲ', 'ଏଲଫ', 'ସରଶ', 'ବଥକ', 'ଥଲବ', 'ଭରଟ', 'ବରତକକ', 'କଟତ', 'ଅନହରତ', 'ଶହତ', 'ଅକଷଫ', 'ଅଲମଲ', 'ଫଠ', 'ନକବ', 'ଇରଶମ', 'ବନବରକ', 'ଗଠନକର', 'ଭରଣଭ', 'ଇଲତକ', 'ଅଠଗ', 'ସଐଦ', 'ଦରବତ', 'ଲଗଣ', 'ଭବକ', 'ଟଲକର', 'ଶଗଣକକ', 'ୌ।', 'ଟସରଣରକ', 'ପଭକ', 'ନହସବ', 'ମଯକକ', 'ଖଜକ', 'ଟଅଞ', 'ଟଚରଗଣ', 'ଅହଲବ', 'ଧନସଐତ', 'ଆରଧନ', ',ି', 'କନସରର', 'ଲଗଲସ', 'ଗଘ', 'ରଥକକ', 'ନଯମର', 'ଷରକକ', 'ଷରର', 'ରଥରକ', 'ହଶଯମ', 'ରମରକ', 'କଐନ', 'ଶମଗର', 'ଜଳକଢ', 'ଥଳମ', 'ଯଗଣନ', 'ଜଗକ', 'ସଷ', 'ଓଟଗକ', 'ପଥରରକ', 'ିଁ!\"', 'ଠକକ', 'ଟଅକକ', 'ଳଯକକ', 'ି,।', 'ଟଡନ', 'ଟରପର', 'ଏତଗ', 'ୟବର', 'ଁ।\"\\'', 'ଯଗଣକକ', 'ସଫଳକକ', 'ରମଣକକ', 'ସତସ', 'ସଲମନ', 'ଟମକ', 'ଅଦରମ', 'ି?,', 'ଟଇଦଳ', 'ଏଲବର', 'ଖପକ', 'ଦଲର', 'ଟଅଝ', 'ଆପତତ', 'ସବକକ', 'ପରଐର', 'କବଳକକ', '୍\",', 'ଦକଠ', 'ଟଡକକ', 'ହନକ', 'ଡକକ', 'ଟରତ', 'ଟଣକକ', 'ଗକଥ', 'ତବଣ', 'ଭରପକ', 'ଭଗକ', 'ତବଳ', 'ଉପରଓଳ', 'ଟଇହ', 'ଜଣରକ', 'ମଣକ', 'ଲହମର', 'ବଯଷ', 'ବନୟମ', 'ଟଝକ', 'ଟଷରକ', 'ଟଶଲ', 'ଋତର', '?ା\"', 'ଭଦର', 'କଠଉ', 'ୟଜକକ', 'ଓବଦର', 'ହଲକ', 'ି।\"\"\\'', 'ଆଗଥର', 'ମନଦକ', 'ଏଥକ', 'ନଲକ', 'ଟଯଲର', 'ନଗରୟ', 'ଏବନ', 'ଏଜରରକ', 'ପଥଧର', 'ଶଗଡଟ', 'ସରକକ', 'ପଥରକକ', 'ବଡପକ', 'ଅଦଯ', 'ଗଧସବ', 'ନକପ', 'ଆକକ', 'ଚଟକ', 'ତଗଣକକ', 'ବସକର', 'ହଶକକ', 'ଆତର', 'ଘଗର', 'ଟଇବର', 'ଯନବ', 'ସନଭ', 'ଟଦକ', 'ବଗଛ', 'ଇଉର', 'ଏକଜକ', 'ଗଗକ', 'ଟଟଦ', 'ଈଷତ', 'ଟନଯନ', 'ଏଫସ', 'ଆଠପକ', 'ଷସଟ', 'ଇସତ', 'ରପଶକ', 'ଯପଶକ', 'ଟଇଥର', 'ଅକକ', 'ମରବ', 'ଟଇଶହ', 'ଥରପ', 'ଟପସ', 'ଚପଟ', 'ଯଗଙ', 'ଐର', 'ଭୟରକ', 'ଗମନରକ', 'ଟତଲ', 'ପଥଗମନ', ',!\"', 'ମଛଦକମ', 'ଟଇକମ', 'ଗଲଙ', 'ତରରକକ', 'ଉକର', 'ଟତକ', '.!\"', 'ଭୟଜ', 'ପରଷ', 'ଦଯରକ', 'ହକଙ', 'ଥଗକ', 'ଆଷ', 'ୟବଯଷର', 'ଅସଭ', 'ରଜନକ', 'ବଗବ', 'ଟରବର', 'ଯମଠ', 'ଟଲର', 'ଅବନରଙ', 'ଟରଷ', 'ଔରସରକ', 'ପଛପଟକ', 'ଭରଣର', 'ଚଲଇ', 'ଅମଣ', 'ଉଷକକ', 'ସଉଷ', 'ଖଲଙ', 'ଔରଷରକ', 'ଟଭକ', 'ଯଦଳମ', 'ବଟହ', 'ରହବର', 'ଃ?\"', 'ଲମକକ', 'ବକକକ', 'ଆଗଧ', 'ଠରକ', 'ଟରଖ', 'ଟସରକ', 'ନସଐର', 'ମଇ', 'ଅବକ', 'କରଇର', 'ଟକରଣ', 'ଘନନ', 'ଟମର', 'ଆରଣଙ', 'ଷଗକ', 'ଟଚନ', 'ଥକର', 'ସମୟକକ', 'ଲଯଙ', 'ଲହକ', 'ଳଗକ', 'ଖଚରଟ', 'କଜଣକ', 'ଟସମ', 'ଏପଟରକ', 'ସପଟ', 'ଯଦଳସସଦ', 'ଣତସହଲ', 'ଇଲଲସଯ', 'ଆପଣସସଇ', 'ରଣସଯଉ', 'ସଦଖକ', 'ସଯଲବ', 'ଜଲଣସହଲଲବ', 'ତସଯଲତ', 'ସସଗକ', 'ବଡସହବ', 'ଆଲଡ', 'ପଲଲଷ', 'ମସଯ', 'ଆଉଥଲର', 'ଟସଗ', 'ସସନ', 'ତସଦଲବ', 'ଏସଲ', 'ସସଫର', 'ଲଗଲଠ', '000ସଲ', 'ଓସକ', 'କଲଲସଲ', 'ଟଖସର', 'ଦଲବକ', 'ରଣସସ', 'ପସଦଇ', 'ଲୟଲସରସକ', 'ଲଣସଯ', 'ତରସଦଲ', 'ତସଛ', 'ଆଗସରସମ', 'ଆପଣସହଉଛନ', 'ଜଲଜଲବ', 'ମଲଜସରସଭ', 'ନସଦଲଲ', 'କଲଉ', 'ସହଉ', 'ୟଥଲଷ', 'ସନଇଯ', 'ଧସଲ', 'ବଯସସହ', 'ବଡଲଲ', 'ତସଯ', 'ରସକଲତ', 'ନକଲର', 'ପସହବ', 'ଏଲତଗକ', 'ଲଯକକ', 'ବନସଦଇ', 'ଯସଦଲଲ', 'ରସହଲଲ', 'ଲଗଲକକ', 'ଧଲକସଲ', 'ଘଲନ', 'ସରସଦଖ', 'ସନଲଲ', 'ତରସଦଇ', 'ସନଇନ', 'ସହଯଜ', 'ଦନଠ', 'ଉରସ', 'ଷବଦ', 'ଉଦରକକ', 'ଲଟପଟ', 'ଜପଥରକ', 'ୟକକକକ', 'ଗଡପ', 'େଃ,', 'ନରହକ', 'ଚପକ', 'ଯଛଦନ', 'ବନପଶକ', 'ଟଗଣକକ', 'ସଫକକ', 'ବରକକ', 'ଉଡକ', 'ଟବଦ', 'ରକଐ', 'ଜଳରକ', 'ଅତକ', 'ସଡକର', 'ଛତର', 'ଟମଧକ', 'ଜଲମ', 'ତଖମ', 'ଶଷତ', 'ମବକ', 'ବରହ', 'ଶଳପ', 'ବଡଭ', 'ଭଲକର', 'ସହଠ', 'ହନଗ', '005', 'େି;', '480', 'ିାଁ\"', 'କଲଲସଯ', 'ଚଚ', 'ଲଲଖ', 'ଥସର', 'ପରସସଗ', 'ଟସଖ', 'ଶସଲ', 'ଲତସସହ', 'କରତସର', 'ଆଗପଛ', 'ରସହଲ', 'ତରସର', 'ଓସକଲତକ', 'ଠସର', 'ମନସଲ', 'ଏକସଲ', 'ମନସସହ', 'ଲଲଇ', 'ବହଳର', 'ନସରସଦବ', 'ଓସସଗ', '200ଟ', 'ସଦଲ', 'ରରସମ', 'ଟଲଇ', 'ଶଗଡର', 'ଶଗଡଗ', 'ଯଲଦଶସର', 'ବଇଠ', 'ଠସଗ', 'ଆଉସସହ', 'ନଲମ', 'ତଳସର', 'ଧହସ', 'ବଲଢ', 'ସସଇ', 'ସରମର', 'ଆଲଡସଖ', 'ସରମସର', 'ଗରସର', 'ଔରସଜ', 'ଞଭ', 'ଗଳବ', 'ଜଭ', '420', 'ବଛର', 'ଜପତ', 'କମର', 'ରଖଣ', 'େଁ।\"\\'', 'ଏୟ', 'େେି', 'ରବଯ', 'ନପହଞ', '41', 'ରଥମପ', 'ଳପର', 'ଅଭବ', 'କରଇବ', '45', 'ଇମହଣ', 'ଷଭକ', 'ବତଗଣଙ', 'ଆବଲହ', 'ରହଳ', '232', 'ଡଇଲ', '27', 'ଈଷବଲଙ', 'ଈଷବଲର', 'ୟକଙ', 'ଯଲତ', 'ଖଚରର', 'ତମଳର', 'ପଦଶଦ', 'ଏସମ', 'ଣଭୟ', 'ଳଶ', 'ଆହବ', 'ଶଠତ', 'ଶୟର', 'ଇଷବଲଙ', 'ଭଳଯ', 'ଣଦୟ', 'ଜଯକଲ', 'ୟରଠ', 'ନନବ', 'ତରକଟ', 'ତଯର', 'ଡଶ', 'ଟକସବ', 'ଲଷ', 'ରତସ', 'ଲୟଲସର', 'ପଲକହଙ', 'ଷସରସଯ', 'ଷସସ', 'ଲମସରସଷ', 'ଲରସସ', 'କରଣସହ', 'ଲୟଲମ', 'ଘଲର', 'ଲଲଷର', 'ଓସମ', 'ଯସନଲଲ', 'ଲଲଷରଙ', 'ମଲଶକ', 'ଲମଶକଲର', 'ପକଳ', 'ଲରସସହ', 'ସସସସହ', 'ଆଉସସ', 'ଲଲସଯଉ', 'ଥଳସର', 'କରସହ', 'ଉପଲରସହ', 'ତଲଳସଯଉ', 'ସସସବ', 'ସନଇ', 'ଅଲରସଯଉ', 'ରବଲଶ', 'କବରସନଲଲ', 'ନଅବର', 'ଅନମ', 'ସନବ', 'ପଥସ', 'ରଶଯ', 'ହଛ', 'ଯଚ', 'ଅହମ', 'ଦକବଲଦନ', 'ଇୟକ', 'ଗଣକତ', 'ଲମତ', 'ବଡର', 'ଷକଥ', 'ଥଳଗ', 'ମସମର', 'ଚମସ', 'ତନହ', 'ଆସନଠ', 'ଏବରଙ', 'ହତସ', 'ଉସଲ', 'ୟକଷନ', 'ଫସଙ', 'ଏତସର', 'ଏତସରଙ', 'ହବଙ', 'ମଗଦ', 'ଆଖର', 'ସଲଲଙ', 'ଓରଣ', 'ଓନମଙ', 'ଅହଲଯ', 'ବଦକ', 'ଇଫଲଲଙ', 'ଇଫଲଲ', 'ଲସଙ', 'ସମୟଙ', 'ମଗବନ', 'ବଲଙ', 'ମନହ', 'ତଲମଯଙ', 'ମଗଯ', 'ନତସର', 'ଣନର', 'ଐନଯଙ', 'ଲହଦଙ', 'ହତସଲ', 'ଶରଙ', 'ସରତ', 'ଇତନନ', 'ଅହଲଲ', 'କନହସଙ', 'ହଥତ', 'ମରଦ', 'ମଲଦଙ', 'ଶବହଙ', 'ନହମଙ', 'ଅସବଯ', 'ସମଙ', 'ଏତସମ', 'ଥମର', 'େ,୍', 'ଯଶଯ', 'ଗଲତ', 'ଲନଷ', 'ପଲନ', 'ହଲଦ', 'ତସରଙ', 'ଷହରଙ', 'ତଦଳ', 'ଲୟଙ', 'ୟହମଯ', '36', '034', 'ହରଙ', 'ଈଶହ', 'ଥଲହଙ', 'ବରଦଙ', 'ତଲହଙ', 'ୟଫଲଟଙ', 'ୟଫଲ', 'ଫହଙ', 'ଣଫ', 'ଆରହ', 'ଅହର', 'ନହତକ', 'ଦଶଙ', 'ମଲକମ', 'ଶରଯ', 'ଶମଦ', 'ମରଯ', 'ଶମଶରଯ', 'ଇତହ', '690', '956', '212', 'ଛଅପ', 'ପଶଦମ', 'ରଦରଙ', 'ଈଲଯ', 'ବଯଙ', 'ଲବନ', 'ଷମଙ', 'ଉରର', 'ମଖର', 'ଇଷବଯଙ', 'ଅହଲଯର', 'ମହବ', 'ବତଙ', 'ଂୀ', '37', 'ରନଦ', 'ବହକମ', 'ନଫର', 'ରଫଯ', 'ଶଗଣଙ', 'ଫନଙ', 'ଗତଥର', 'ଠଦଣ', 'ଏଥନଙ', 'ମକନଯ', 'ସଶକ', 'ଅଠଷଠ', 'ଜଦଯ', '32', 'ଯଦଳଠ', 'ପଯକ', '6000', 'ଦଳମ', 'ନଥନଲଙ', 'ଟଦଶ', 'ଏଷରଙ', 'ୟତନ', 'ଲତଯ', 'ଅତନ', 'ସମଖ', 'ମହରଯଙ', 'ଅକମ', 'ରଘରମ', 'ଚନକ', 'ବଦକମ', 'ବଲପ', 'ଖରସ', 'ଠଭଳ', '53', '580', '575', 'ଇବଗଣ', 'ତଗଣକ', 'ତରଳଇ', 'ଆୟଇଥ', 'ଡମକ', 'ଅଣସ', 'ଯକଦଳର', 'ମଟର', 'ରଣକର', 'ଚସମ', 'ଧରଥ', '250', 'ବସଗ', 'ରଯଦ', '450', 'ୟକକଟ', '300ଟ', 'ପକରଣ', 'ଖଚରମ', 'ରଖବ', 'ାେ\"', 'ି।\"?', '!!', 'ହବଯ', 'ସହମ', 'ଅତଯ', 'ଶକଙ', 'ପଧ', 'ଆକଅମଣ', 'ଆବଲମ', 'ି|', 'ଯମପ', 'ବଦଙ', 'ସନମ', '଼ୁ,', 'ଯଯଲଙ', '|', 'ଲମବ', '35', 'ସହରନ', 'ଯପଦ', 'ରଜତ', 'ଯକଦଳ', 'ମରଭ', '!\"\\'', 'ରଦଳକ', '307', 'ଓଫଲର', 'ଚଳମ', 'ଶଇ', 'ହଳତମ', '600ଟ', 'ଦଆଯ', 'ଶଳକ', 'ଧନସ', '୍େ-', 'ତମକର', 'ଧବଦ', 'ପଇଠ', 'ନମଯ', 'ରଶମ', 'ବଇଛ', 'ଶବସରଙ', '410', 'ପମଯ', '172', '812', '945', '642', '623', 'ଅସଗଦର', '222', '056', '454', 'ଅଟରର', '323', '123', '56', '128ଜଣ', '621', '122', '156', '320', '725', '345', '630', '973', '052', '017', '74', '139', '392', '736', '720', '61', 'ଟନଗର', 'ଶଥରବ', 'ଅଫର', 'ରସଙ', 'ଜକରର', 'ଠବର', 'ଷଯବସ', 'ସକଳପ', '218', '160', '110ପ', '650', '96ଅଣ', '77', 'ଇଲଯ', 'ସଜଯ', 'ତଲଯ', 'ମନଶ', 'ଉଯଲ', 'ନଦହବଯ', 'ରଦଇ', 'ହଯର', 'ମଫର', 'ଣଅ', 'ଉଷଯର', 'ଲଫର', 'ଜଣକଠ', 'ଧକଭ', 'ସଇଟ', 'ଯଯଭ', 'ଭୟଗ', '2072', '84', '628', '667', '237', 'ଆଟରର', '88', '102', '721', '2052', 'ବଫ', 'କଋବ', '5ଜଣ', '6720', '530', 'ସତଷଠ', 'ଧଧର', 'ହଶବନ', 'ଜତପ', 'ଷଗଣକ', 'ଆଟଇ', 'ନବଯ', 'ଋକର', 'ଲଯଆଦ', '822', 'ଅମଶଯ', 'ଅହସଯର', 'ଅହସଯ', 'ଗମଧ', 'ଯଥଅର', 'ନବଲ', 'ସଋଦ', 'ଉଦନଗରର', 'ହଚ', 'ଗଦଇ', 'ରଯକ', 'ଜକପଦକ', 'ଅବଗଥ', 'କସଙ', 'ଆଇନଜ', 'ମସନ', 'ମକଲ', 'ଜନଫ', 'ହଦସ', 'ପରମସ', 'ବରଶ', 'ଧରସର', 'ହଗଯକ', 'ୟସକଳ', 'ଦଖଯଠ', 'ହଥକକ', 'େ,:', 'ଜଯକର', 'ୃ।\"', 'ମନଠ', 'ଅଦଲ', 'କରଧ', 'ଦରଖଯକ', '000three', 'o1', '000ne', 'ଗଧଗ', 'ଆଗଦ', 'ପଦଟ', 'ଡରର', 'ତଧନ', 'ତଗଣଠ', 'ଯକଣ', 'ତଭଳ', 'ବନଟ', 'ଲଦଦକ', 'ବଗଶ', 'ନଳତ', 'ଇପକ', 'ବନଭଳ', 'ାଁ।', 'ଷଦମ', 'ମନଯ', 'ଚଥ', 'ଳପତ', 'ଚଟର', 'ପଚଇ', 'ଉଦବଗ', 'ଗଭଳ', 'ଭତଳ', 'ଗରଳ', 'ଧସରକ', 'ଥରଥର', 'ଈସବ', 'ବଦଳନ', 'ଗଧଭଳ', 'କରଜର', 'ଚଯତ', 'କଲବ', 'ରତଗ', 'ଘନବ', 'ଜଳକଣ', 'ଗବଳଯ', 'ନଭଳ', 'ଗଧପର', 'ଜଗନ', 'ବଇବ', 'ଦଯଭଳ', 'ୟଅ', 'ଖଲର', 'ଆଯବର', 'ମନଲ', 'ହକତ', 'ଅପଦ', 'ମଭଳ', 'ବରଫକ', '଼\"', 'ଅପସର', 'ଢକ', 'ଶବସବ', 'ଆଯବ', 'ଶଡ', 'ମବନ', 'ଧସଜ', 'ଣଶ', 'ଠଗଡ', 'କତସ', 'ଫଇସଲ', 'ବରପର', 'ମପଥର', 'ଥକତ', 'ଭବଦ', 'ଡଖଣ', 'ଅଭଦ', 'ଦଲଠ', 'ଅଧପତ', 'ଗତଳ', 'ଶଯମ', 'ତକରଣକ', 'ଗନର', 'ଶଷଗ', 'ଶତବ', 'ଏଇସବ', 'ପଦଗତ', 'ଏକବଡ', 'ଆପଦଗ', 'ଥଡ', 'ପଜ', 'ଟଗଛ', 'କହଇ', 'ଞନ', 'ଛକଗ', 'କବରଖ', 'କବରପର', 'ଘମଯ', 'ଟବସ', 'ଖଜନକ', 'ବଯକ', 'ସଳଖପଥ', 'ହରଣର', 'ହରନ', 'ରଧତ', 'ମରସ', 'ସଇଖ', '।।', 'ଆଳଯକ', 'ଜଗତସ', 'ରରକମ', 'ଦରଜ', 'ହରଷ', 'ହକଠ', 'ରକଗଣ', 'ଯଯକ', 'ଢମ', 'ଅଧମ', 'ଭୟୟ', 'ଅଳସର', 'ଜନନ', 'ଭଳଇ', 'ଠକଠ', 'ଦଗତ', 'ଭୟଜନକ', 'ଫପର', 'ଅନଷ', 'ଶଜନକ', 'କଳହକ', 'ଭକପ', 'ଖଳବ', 'ରରକଗ', 'ନଦନ', 'ଜଖସ', 's', 'କବଜ', 'ଅସତର', 'ଉପଜ', 'କଭୟ', 'ଉକଲଙ', 'ଧମନ', 'ତକଳ', 'ଜନକଙ', 'ଭଜନକ', 'ତହସ', 'ବରଫପ', 'ପରମଗ', 'ଉପମ', 'ପରତ', 'ଛକଛକ', 'ମକଟ', 'ଧମତ', 'ଯମନ', 'ଗଳଦନ', 'ଗରଙ', 'କଟଇଦ', 'ଜଳମ', 'ଦତର', 'ତମଫଳ', 'ଅତରଦ', 'ଦଲଶ', 'ଷଲତଟ', 'ଗସରସଗ', 'ରଏହ', 'ରସସଥ', 'ଷଲତକ', 'ଷଲତସରସକହ', 'ଷଲତସର', 'ମଲଘକ', 'ଆଲଦଶସଦବ', 'ଲୟଲରସଗ', 'କଟତରସହ', 'ଏସହଲଲ', 'ଡସଦଲବସଯପର', 'ଲମମ', 'ସସହବ', 'ରଣସହବ', 'ରଣସସମ', 'ଲୟଲରସକଲତକ', 'ବନସର', 'ପସରସସମ', 'କସଲ', 'ଲସର', 'ଲନସସ', 'ଲୟଲରସଲ', 'କସଦଶର', 'ଓସଦଶ', 'ସମଷମ', 'ସମଷଶ', 'କରସଯ', 'ସଯସସମ', 'ଲଭସସମ', 'ଚସଦଲଲସସମ', 'ଚସନଲବ', 'ତମସଲ', 'ବଲରସପ', 'ସରସପ', 'ଏଓ', 'ଏସସହ', 'ତଶର', 'ରଦଲଶ', 'ଯସଗ', 'ଦଲଉଛନ', 'ରସଦଶର', 'ସଯସଦଶମଧ', 'ଗଣସକଲବ', 'ଅବଶସହଲବ', 'ପତନସହବ', 'ଲନସକଲବ', 'ଧନସକଲବ', 'ଶରଗ', 'ଯସନଇୟ', 'ଶସସମ', 'ଲନସଯଲତଲବଲଳ', 'ଲବସସଲତଲବଲଳସସମ', 'ଘନମଲଘ', 'ଫଗଣ', 'ଚରବ', 'ଲନସସହ', 'ରଜକ', 'ଜପଥସ', 'ଡସର', 'ତସରସସମ', 'ନସସମ', 'ବଲଲର', 'ତସହବସଯ', 'ଏକସଗ', 'ରସରସହ', 'ନସଦଖ', 'ଇଲବ', 'ଯଲଲ', 'ଭସଲ', 'ନସଦଲବ', 'ଶରସର', 'ଡସଦବ', 'ସମୟଲରସକହ', 'ସମଷ', 'ଧସରସସ', 'ଓସସସଦଶର', 'ୟକକସଲ', 'ଷଲତମ', 'ବଣସହ', 'ଲନସସଠ', 'ରସସଦ', 'ଆଉସସଠ', 'ଟକଲର', 'ମଲଣ', 'କରସସ', 'ଅଣଇହ', 'ଅଡ', 'ଳକହ', 'ତଳଗ', 'ଅଣନ', 'ସତରର', 'ଗନଗର', 'ଗଣଗ', 'ଘପର', 'ଭବଶ', 'ଉଳ', 'ତଳବ', 'ସଜନକ', 'ଟକସ', 'ଇଦଳ', 'ସକକର', 'ଦମଯ', 'ୋ!', 'ଧଗ', 'ରମତ', 'ତରଣକ', 'ପସମୟ', 'ରଳଯକ', 'ରକଙ', 'ସଳଖତ', 'ଜହ', 'ଶକଟଚକ', 'ଯବଦ', 'ବକଥ', 'ଡସ', 'ଗଣହତ', 'ୟକଗଣଙ', 'ଖଳଲ', 'ଜନଗର', 'ଟକପର', 'ରବଣର', 'ଟକଲତ', 'ଝରମଯ', 'ହଣକ', 'ଦରବର', 'ବଲଦନ', 'କଳସର', 'ନବଳ', 'ନବମଣ', 'ସକଳବସ', 'ଆତୟ', 'ଶଯକ', \"ୋ'\", 'ରବଳତ', 'ଆଉସକହ', 'ୟସକହ', 'ଦଲବ', 'ସତଲବସସ', 'ତନସଲ', 'ନସଖ', 'ଲକସସଗ', 'ସଯଲତଲବଲଳସସ', 'ବଳସହ', 'ଘସର', 'ଦଲବଦ', 'ଠସସ', 'ଧକଲସରସସ', 'ସରସସ', 'ମସହଲ', 'କସଦଖ', 'ରଲହସସସସଥ', 'ଏକସଦବତ', 'ରସଖ', 'ଡବତସହ', 'ଭରସଦବତ', 'ତସସ', 'ଠସପ', 'ରସରସର', 'ସସକ', 'ଡବତସହଲ', 'ଣସକ', 'ଲୟଲକ', 'ତମସବ', 'ଲଭସଦଖ', 'ଭସମଷପ', 'ଗଳସବ', '।,', 'ମମଯବ', 'ନତଜ', 'ଝପର', 'ଶଷଫ', 'ଭରତ', 'ହନଳ', 'ଟନକ', 'ଛଦର', 'ନସକଳ', 'ତକପର', 'ବଧଭ', 'ମହତମ', 'ଭୟଠ', 'ଣଡ', 'ନବସନ', 'ହତଗର', 'ରମନ', 'ନଳବ', 'ଣସଦ', 'ପହରର', 'ବଳପର', 'ଜସବ', 'ରଧବଶତ', 'ଜବସ', 'ଷଦଳ', \"'ି\", 'ଶଯନସ', 'ୟଅକ', 'କଟସବ', 'କଳହର', 'କଦରକ', 'ରଥମତ', 'ଆଜନ', 'ଦଗମନର', 'ଧନମ', 'ପଥଗମନର', 'ରମଫଳ', 'ଳମର', 'ରଣହ', 'ମଭଦକ', 'ରବପର', 'ୂୂ', 'ଥହକରମ', 'କହନତ', 'ରଯଯ', 'ପକଗଣଙ', 'ମଯତ', 'କଳମଯ', 'ଳଗଛ', 'ହସୟ', 'ଅକର', 'ଘବର', 'ୈି', 'ଶଳତ', 'ଠଖମ', 'କପଟମଯ', ',\"\\'', 'ଉପପଥର', 'ଏହସ', 'ଜସଜ', 'ଡଳସ', 'ଳଜ', 'ଯସଙ', 'ନକଥ', \"ୀ',\", 'ଫଳପର', 'ଆଚରଣର', 'ୋ\"', 'ସଗଣକ', 'ଐଲମ', 'ରସମର', 'ଥବର', '଼େ।\"', 'ିେ।\"\\'', 'ପଥଚ', 'ଜଞର', 'ହନନଲଠ', 'ହନନଲର', 'ନରଶ', 'ଆକଳନ', 'ଁ\"\\'', 'ହବତସ', 'ହକନ', 'ନଗରସମ', 'ଦଲଯ', 'ଗମର', 'ଁ,\"', 'ରହମଲକ', 'ଖଲକ', 'ସମଗର', 'ଶସଖ', 'ରବମ', 'ଷରଦନକ', 'ଶସବନ', 'ଏଫଯର', 'ଉଶମ', 'ହତମ', \"ିଁ,'\", 'ତଫନଦ', 'କଲମକ', 'ଲବହକଗଣ', 'ଞସ', 'ରଥସମ', 'ବତଗଡ', 'ସଦସବ', 'ଲକମର', 'ବତଶ', 'ଜବପନକ', 'ଶଯଗ', 'ବକଗଣଙ', '଼ୁ।\"', 'ଉସବ', 'ଜନରବକ', 'ଖଳବଦ', 'ପରବଶ', 'ସହଳ', 'ମଳନ', 'ତକପ', 'ପଦକଥ', 'ରହରର', 'ତମବସ', 'ଦଦଳ', 'ଭଦକର', 'ଝଟ', 'ଅବଲ', 'ଉତଥ', 'ଭଦକ', 'ଷବହନ', 'ୟବପ', 'ନକସ', 'ଟପତଙ', 'ନଗଣଠ', 'ରରବ', 'ଉତକ', 'ୋ।\"\\'', 'ବଗମନ', 'ଉଜଡ', 'ରଲପ', 'ଲପନକ', 'କଣକ', 'ଆଭରଣ', 'ଣଛଦ', 'ରବଚନ', 'ବନତ', 'ଚରଣର', 'ଊପ', 'ସକଳସବ', '୍ି', 'ନଯନର', 'ବରଥ', 'ଗରସ', 'ଗମଦର', 'ରଯମର', 'ଲଦର', 'ବବସ', 'ସକଳକ', 'ଧସବ', 'ଅଚଳ', 'ଘନଛ', 'ଘଗ', 'ତସମ', 'ଗହତ', 'କବରସବ', 'ଓହର', 'ପଶମକ', 'ଷତସ', 'ବତଗଣକ', 'କଳପ', 'ାେୃ', 'ବତସମ', 'ଏକଦଣ', 'ବରଣର', 'ବରଣଟ', 'ବରଣକ', 'ଠସବ', 'ଗଣସ', 'ନଳଦ', 'ଅଧହ', 'ଟକଗ', 'ଯବଳ', 'କଣମ', 'ଐନଇଗ', 'ଲଇମ', 'ମହହ', 'ମଖକ', 'ରଥମବର', 'ଆସର', 'ବରଗଣର', 'ବବଲ', 'ଅବଦନଗ', 'ନଆସନ', '/', 'E', 'ଦବପ', 'ଇଜ', 'ଞଗଣଙ', 'ଫଳଗ', 'ବଲଟ', 'ଗଗନସ', 'ଜନଗ', 'ଭଞ', 'ପହଚ', 'ମଯପର', 'ନଖସବ', 'ମହର', 'ପଦଦଳନ', 'ଭରବ', 'ଗଡବନ', 'ଭଟବ', 'ମହଗଣ', 'ବରଗଣଙ', 'ଳବସ', 'ମଳମଯ', 'ଇମଙ', 'ରମବ', 'ଥଳଚର', 'ଗଛତଳ', 'ଆବନକ', 'ଭଶଯ', 'ବସହର', 'ଭଲପଣ', 'ଶଲମନ', 'ଅରବଲକ', 'ରଇଗ', 'ତମଲ', 'ଯପଗଣ', 'ଭଳକଗଣ', 'ଷକଗଣ', 'ଭଳକ', 'ଚଢନ', 'ଠଲନ', 'ଭରଦ', 'ଯଟର', 'ଭଇଛ', 'ଫଣର', 'ଝଳପ', 'ତଶବର', 'ତଘ', 'ଭରଧ', 'ଯନଙ', 'ଗଜଦନ', 'ା\",', 'ଢଲ', 'ରଥମବ', 'ଅମତସ', 'ଏକଡ', 'ତଭଣ', 'ଉଗଛ', 'ସଲର', 'ବଣବ', 'ବଳଦପର', 'ଉଫ', 'କରପର', 'ଭଲହ', 'ଘଠ', 'ଋଣକର', 'ଆଉଛ', '\"!', 'କରଶ', 'ଝପଟ', 'ଯଗଣକ', 'ଶଇତ', 'କଇକ', 'ଶଆଡକ', 'ମଯଜନକ', 'ବଧର', 'ରବଠ', 'ନଲର', 'ଉଦଯକ', 'ୟୟ', 'ଦବଲ', 'ି।\")', 'ଆଦସ', 'ନଥଲ', 'ୟଲକ', 'ଦଇଛନ', 'ମୟଙ', 'ଖଭର', 'ବଷୟ', 'ବନମଧ', 'ଷରଟ', \"ାଁ'\", 'ଭଦରଟ', 'ଓଗଳ', 'କମୟ', 'ଜମଇ', 'ଣଛ', 'ଅଣଓସ', 'ପଶସ', \"'?\", 'ଉଯ', 'ପଡଲ', 'ଭତରକ', 'େ(', ',ୁ', 'ଘଟଇ', 'ତବଜ', 'ନଳଗଛକ', 'ଜଭବନ', 'ହଲଙ', 'ା।,', 'ମନନ', 'ନଳର', 'ରଇନବ', 'କଦହର', 'ବଢଇର', 'ଦଅନ', 'ସମଧ', 'ନଛ', 'ଯନଇ', 'ଅପଙ', 'ତଖଣ', 'ଷଣଗ', 'ଘମଧ', 'ି।)', 'ମନଦ', 'ନହଜ', 'କରଟକ', 'ୟସଙ', 'ରଥମସ', 'ୁ.\"', '?:', 'ୟମମ', 'ଆସନମ', 'ଲଇବ', 'ଅଟକଇ', 'ଓଟକ', '।)', 'ପଳଇୟ', 'ଆରଜଣକ', 'ିେେ।', 'କରଠ', 'ରଜଣଯ', 'ୁଁ?\"', '଼!', 'ରମଞ', 'ଖବରଟ', 'ବଦଳଇବ', 'ରହରଠ', 'ୀ?\"', 'ରନଗରକ', 'କଲପର', 'କପରକ', 'କବଲକ', 'ପରପର', 'ଗଛଚ', 'ଫଳହ', 'ଭଲମ', 'କଡକ', 'ପଳଇ', 'ବଜନଙ', 'ରଶକ', 'ପକଟ', 'ଚପଲ', 'ଅସଫଳ', 'ରଦପ', 'ରପଲ', 'ଭଭଳ', 'ଏଡଇ', 'ଡଠ', 'ଃ\"', 'ଜନହ', 'ଘଛ', 'ସହରଣ', 'ଡଦବ', 'ଗଧଛଆକ', 'ଜଶ', 'ଓଜ', 'ଗତଭ', \"ି'ା\", 'ଚତଇ', 'ଲଖଡ', 'ଅତରକ', 'େି-', 'ାଃ,', 'େେ:', 'ଭଗତ', 'ଜଣଇଦ', 'ନହମୟ', 'ଢତର', 'ଅଗଷ', 'ପନକଥ', 'ଚଉର', 'ଦରତମ', 'ନଗୟ', 'ମହଥଙ', 'ବହଶ', 'ବଇଦ', 'ଶଷର', 'ଅଟକଇବ', 'ନସରତ', 'ଖଇଦ', 'ଛପର', 'ସହଣ', 'ରଖଥ', 'ଭନମ', 'ହଥ', \"ୁ',\", 'ନପକ', 'ଇଥବ', 'ିା\"', 'ଚଶହର', 'ଜତକ', 'ଫଳନ', 'ଝଡତ', 'ଈରସର', 'କବସ', 'ରନଥ', 'ନଅଟକ', 'ତପତ', 'ଚଢଇ', 'େ।।\"', 'ଥତକ', 'ଜଳଇବ', 'ଝଡବର', 'ସବଠ', 'ଆଇଥ', 'ବଳଦଟ', 'ହଉତ', 'ପରଖ', 'ମପଥକ', 'ଠଘର', 'ରହଜ', 'ଓଳଇ', 'ଉଡଇ', 'ଅଇ', 'ହଇକ', \"େ...'\", 'ଧନତକ', 'ଓଟଟ', 'ଚଥଳ', 'ଦଶଥଳ', 'ମନଧ', \"ିଁ?'\", 'ଟବଜ', 'ଆସନଗ', 'ଭଲଭଲ', 'ସନଗ', 'ୁଁ?', 'ୁଁ!', 'ମୟକ', 'ଝଇବ', 'ରତଥ', \"େ',\", 'ସରସ', 'ସଘତକତ', 'ଚଇବ', 'ଯପସ', 'ି)।', 'ଲକଟ', 'ିଁ?\"\\'', 'ଁ!', \"ା')\", 'ଧଥ', 'ଆସଛ', 'ଖଥ', 'େ))।', 'ଅତରର', 'ଗରଣ', 'ସମୟଧର', 'ଏଜଗତର', 'ିି।', 'ଯଜଣ', 'ତଦହକ', 'ଯଜଣକ', \"େେ',\", ',\"।', 'ିଁ.', 'ରଡନ', 'ଅବତ', 'ଉପରମହଲ', 'ହକଲ', 'ମୟଜନକ', 'ରଯଲର', 'ଓଯ', 'ବବଦ', 'ଆଇନର', 'ଟମଦ', 'ପକଇଦ', 'ଲଖର', 'ଅସଧ', 'ଭସମ', 'ଜଳଥ', 'ଫରଣ', 'ଭଦଭ', 'ରବଚ', 'ୃ!', 'ଉଳଙ', 'ଷୟପ', 'ିଁ;', 'ନଗରକତ', 'ଶୟମ', 'ନଗରକର', 'ଯୟବସ', 'ଜସଭ', 'ଂା', 'ଲତର', '।?\"', 'ଖଳପ', 'ଡରଙ', 'ି...!\"', 'ଜନସଭ', 'ଇଉତ', 'ଢଇ', 'ପତଲମ', 'ୁ:', 'କସମ', 'ି।।\"', 'ଭଣଜ', 'ଁୁ', 'ଜମଇବ', 'ନଜରବନ', 'ଦରଗ', 'ଥସଲ', 'ପଆଡ', 'ରହଇ', '236', 'ଲଗଇବ', 'ଗରଗ', 'କପଟତ', 'ଶଜମ', 'ଭମନଙ', 'ାଂ,', 'ଯଡ', 'ବଦନକର', 'େଁ;', 'ନୟନ', 'ୋା\"', \"ଁ'-\", '?\"\\'(', 'ଭଏ', 'ଉପଦସ', 'ତହଜ', 'ତଗଛଭଳ', 'ତଗଛ', 'ୃ।', 'ଫଳସ', 'ରସରଙ', 'ମଲର', 'ମଲଠ', 'ଫବ', 'ୈୀ', 'ରଜନଙ', 'ଦନଜଣ', 'ଦଳଭଦ', 'ଷଜମ', 'ବଶର', 'ଳୟର', 'ଲତକ', 'ଆଇନଗତ', 'େଁ)', 'But', 'God', 'distributed', 'to', 'man', 'the', 'Lord', 'called', 'one', 'let', 'him', 'walk', 'And', 'ordain', 'I', 'in', 'all', 'churches', 'ଗତବୟସ', 'େଁ।)', 'ମଷଦ', 'ବଦଳର', 'ବଳଦଙ', 'ଷଣର', 'େେ।,', '23', 'ହରଣସ', 'ଭନର', 'ୟଇଥ', 'ଅପରପକ', 'ୟକକଲ', 'ଏକଅଙ', 'େଁ,\"', 'ଆଦରର', 'ଥପ', 'ନତକର', 'ଜଣକପର', '0ର', 'ହତଭ', 'ିଃ,', 'ଅମରର', 'ଅମରତ', 'ଅକପଟ', 'ଆବରଣଟ', 'ଜଗତପତ', 'ଛନତ', 'ମହତପ', 'ମସକଠ', 'ଦହରହ', 'ଚୟର', 'ଚଳଗ', 'ଗସରସନଇ', 'ନଲତ', 'ୟସଲ', 'ଷୟସର', 'ସଚଷ', 'ମତସହଲ', 'ଲନସଦଖ', 'ଲଲସଯ', 'ଶଲଷ', 'ଉପଲରସଜ', 'ରସଦଲଲସଯ', 'ଲଭସଯପର', 'ବସଲ', 'ସସସସଠ', 'ରଣସସସଦ', 'ରସଯଲତଲବଲଳ', 'ଭୟସର', 'ଗସଦଲଲ', 'ଲସହବ', 'ସରସମ', 'ସଦଇଛନ', 'ରହସହଉଛ', 'ଭବସହ', 'ରଣସର', 'ଆବବ', 'ିେ?', 'ରସବବଦନ', 'ଅବୟହ', 'ତରତ', 'ଷତଚ', 'ଭରୟ', 'ପଭର', 'ଭବନଟ', 'ଭବନକ', 'ଭବପର', 'ରବଜନକ', 'ଣବୟସ', 'ା(', 'ରଥମଦ', 'ଆଗମନକ', 'ଦହଗ', 'ଇଯଦ', 'ମନଗ', 'କଲସ', 'ଭବପ', 'ଧଶକ', 'ଅନର', 'ବନଠ', 'ଅପଶବ', 'ରଧପ', 'ଅନବରତ', '290', 'ଭନକ', 'ଷରହ', 'ଦରହ', 'ର292', 'ପରମଧନ', 'ଅନଗ', 'ଚୟତ', 'ଅଝ', '294', '295', 'ସତମ', 'ଷୟଠ', 'ବଜମ', 'ଇଉନ', 'ବୟ', 'ନ296', '297', 'ମଗନ', 'ଉଦ298', 'ମବଡ', 'ବନପଦ', 'ବଳମନ', 'ଆଗଇନବ', 'ତଉଭୟ', '299', 'ସକନ', 'ଅଣୟହଦ', 'ସନହ', 'ଗପଗ', 'ବଧନ', 'ଫଳକମ', 'କଜଣକର', 'ଥରମ', 'ଅପଦସ', 'ଗନଲ', 'େ।।', 'ସହନ', 'ହରଣମ', 'ଜଭଳ', 'ଥରକର', 'ଗଅହ', 'ତନଚ', 'ସଜହଜ', 'ଥଇଲ', 'ନରକର', 'ଆମଦ', \"ା'ା\", 'ଉଚତ', 'ନ343', 'ଦୟଠ', 'ତ345', 'କଲମ', 'ଓମଗ', 'ୋ\")', 'ଦଲଫ', 'ଯଭଳ', 'ଜବଲ', 'ପପଥର', 'ଜଗତନ', 'ରରସର', 'ସରରଙ', \"ୁ'।\", 'ଣଚନ', 'ଅଧଘଣ', 'ସସବ', 'ଅତଳଗର', 'ଅପଲ', 'ଦଦଇ', 'ଶପଥକର', 'ନବଡ', 'ୟମସ', '1260', 'ସଦଳବଳ', 'ରଥମଫଳ', 'ଜଳଉତ', 'ଡଭବ', 'ସନଠ', 'ଆପଥରମ', 'ନଗତପ', 'ଆବର', 'ଦହନର', 'ଠଜ', 'ମଲମ', 'ା),', 'ବଳମୟ', '144', 'ରକମଣ', 'ଲକମଣ', 'ତମଟ', 'ଜମଣ', 'ୟମଣ', 'ଧମଣ', 'ବନପ', 'ବନଜଳର', 'ବଗଦ', 'ନରହନ', '!\"।']\n","Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.67, Train BLEU: 0.00, Val BLEU: 0.06, Minutes Elapsed: 0.02\n","Sampling from val predictions...\n","Source: <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ଅର ୍ ଥ <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> ଥସ ଯଜଣ ଟଳ ମଲଘ ମଲଘ ମଲଘ ମଲଘ ଷହ ଷହ\n","\n","Source: Eliab his son , Jeroham his son , Elkanah his\n","Reference: ଇଲ ୀ ଯ ା ବ ୍ ନହ ା ତଙ\n","Model: <SOS> ତଲହଙ ତଲହଙ ୍ ୍ ୍ ୍ ୍ ୍ ଏବରର\n","\n","Source: <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ବ ା ଣ ି ଜ ୍ ୟ ଏବ ଂ\n","Model: <SOS> ବରଥ କଦ ଯଜଣ ଷହ ମଲଘ ମଲଘ ମଲଘ ମଲଘ ମଲଘ\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.51, Train BLEU: 0.00, Val BLEU: 11.94, Minutes Elapsed: 1.03\n","Sampling from val predictions...\n","Source: And a letter unto Asaph the keeper of the king\n","Reference: ର ା ଜ ା ଆସଫ ୍ ଙ ୍ କ\n","Model: <SOS> ତ େ ଜ ା ବ େ େ ା କ\n","\n","Source: And out of the tribe of Asher , <UNK> with\n","Reference: ଏବ ଂ ଆଶର େ ବ ଂ ଶରକ ୍ ସ\n","Model: <SOS> ତ େ ତ େ ର େ ଶ ା ତ\n","\n","Source: <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ମ ୁ ଖ ୍ <UNK> ୍ ତ ୍ ର\n","Model: <SOS> ତ ୍ ତ ୍ ର ା ତ ୍ ର\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.20, Train BLEU: 0.00, Val BLEU: 16.03, Minutes Elapsed: 2.05\n","Sampling from val predictions...\n","Source: And the LORD spake unto Moses , saying , <EOS>\n","Reference: ଏହ ା ପର େ ସଦ ା ପ ୍ ରଭ\n","Model: <SOS> ପ ା ପର ୍ ପ ା ପ ୍ ରଭ\n","\n","Source: And they told him all the words of Joseph ,\n","Reference: ତ ା' ପର େ ଯ ୋ ଷଫଙ ୍ କ\n","Model: <SOS> ସମ ା ପର େ ସମ େ ଶ ି ା\n","\n","Source: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD>\n","Reference: ସ ଂ ସ ୍ କ ୃ ତ ି <EOS>\n","Model: <SOS> ତ ୍ ତ ା ତ ୍ ତ ର ା\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.07, Train BLEU: 0.00, Val BLEU: 17.99, Minutes Elapsed: 3.06\n","Sampling from val predictions...\n","Source: O Timothy , keep that which is committed to thy\n","Reference: ତ ୀ ମଥ ି, ପରମ େ ଶ ୍ ବର\n","Model: <SOS> ହ େ ମ ୁ ତ େ ଶ ୍ ବର\n","\n","Source: Then said I , Woe is me ! for I\n","Reference: ସ େ ତବ େେ ଳ େ ମ ୁଁ ଭୟଭ\n","Model: <SOS> ତ ା' ମ ି ଳ େ ମ ୁଁ ତ\n","\n","Source: Woe unto them ! for they have gone in the\n","Reference: ଏହ ା ସମ ା ନଙ ୍ କ େ ପ\n","Model: <SOS> ସମ ା ପର ୍ ନଙ ୍ କ େୁ ର\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.00, Train BLEU: 0.00, Val BLEU: 20.03, Minutes Elapsed: 4.07\n","Sampling from val predictions...\n","Source: Blessed are they which are persecuted for righteousness ' sake\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କ ଇଚ ୍\n","Model: <SOS> ଯ ା ଶ ୍ ବର ୍ କ ବ ା\n","\n","Source: <UNK> is bound in the heart of a child ;\n","Reference: ପ ି ଲ ା ର ମନ ର େ ଅଜ\n","Model: <SOS> ତ ି ର ା ବ ା ା ଦ ଜ\n","\n","Source: He rebuketh the sea , and maketh it dry ,\n","Reference: ସଦ ା ପ ୍ ରଭ ୁ ଅତ ି କର\n","Model: <SOS> ସ େ ପ ୍ ରଭ ୁ କ ୁ ତ\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 2.97, Train BLEU: 0.00, Val BLEU: 20.95, Minutes Elapsed: 5.08\n","Sampling from val predictions...\n","Source: How much then is a man better than a sheep\n","Reference: ମଣ ି ଷତ ନ ି ଶ ୍ ଚ ି\n","Model: <SOS> ଅତଏବ ି ଡଳ ି ନ ଜ ର ବ ା\n","\n","Source: But and if thou marry , thou hast not sinned\n","Reference: କ ି ନ ୍ ତ ୁ ଯଦ ି ତ\n","Model: <SOS> କ ି ନ ୍ ତ ୁ ତ ୁ ତ\n","\n","Source: No man that hath a blemish of the seed of\n","Reference: ହ ା ର ୋ ଣ ଯ ା ଜକର ବ\n","Model: <SOS> ଯଦ ି ଲ ା ଣ ପ ା ଉ ା\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 2.97, Train BLEU: 0.00, Val BLEU: 22.19, Minutes Elapsed: 6.09\n","Sampling from val predictions...\n","Source: Edom , and Moab , and the children of Ammon\n","Reference: ତ ା' ପ ର େ ଇଦ ୋ ମ ,\n","Model: <SOS> ମ ା ହ େ େ ମ ା ମ ,\n","\n","Source: <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ଦ ୁ ର ୍ ଲଭ କ ା <UNK> ୀ\n","Model: <SOS> ପ ୍ ର ୍ ତ ୍ ୍ ର ୍\n","\n","Source: <UNK> shall make him afraid on every side , and\n","Reference: ଭୟଙ ୍ କରତ ା ତ ା ଙ ୍ କ\n","Model: <SOS> ତ ି କ ପ ୍ ୁ ର ୍ କ\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 3.00, Train BLEU: 0.00, Val BLEU: 22.41, Minutes Elapsed: 7.10\n","Sampling from val predictions...\n","Source: And the vessel of earth , that he toucheth which\n","Reference: \" ଯଦ ି କ ୌ ଣସ ି କ ୍\n","Model: <SOS> ପ େ େ ଜଣ ୍ ହ ି ବ ୋ\n","\n","Source: My face will I turn also from them , and\n","Reference: ଆଉ ଆମ ୍ ଭ େ ସମ ା ନଙ ୍\n","Model: <SOS> ମ ୁଁ ୍ ଭ େ ସମ ା ନଙ ୍\n","\n","Source: Wherefore have I seen them dismayed and turned away back\n","Reference: ଆମ ୍ ଭ େ କ ' ଣ ଦ େ\n","Model: <SOS> ତ ୁଁ ଭ େ ତ ା ଣ ା ା\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.09, Train BLEU: 0.00, Val BLEU: 22.49, Minutes Elapsed: 8.11\n","Sampling from val predictions...\n","Source: And the LORD spake unto Moses , saying , <EOS>\n","Reference: ଏହ ା ପର େ ସଦ ା ପ ୍ ରଭ\n","Model: <SOS> ଅନନ ୍ ପର େ ସଦ ା ପ ୍ ରଭ\n","\n","Source: So went Satan forth from the presence of the LORD\n","Reference: ତ ା' ପର େ ଶଯତ ା ନ ସଦ ା\n","Model: <SOS> ଏହ ା ପର େ ପ ା କ ସଦ ା\n","\n","Source: And give thee the blessing of Abraham , to thee\n","Reference: ପରମ େ ଶ ୍ ବର ଅବ ୍ ରହ ା\n","Model: <SOS> ତ ୁ ଶ ୍ ବର ତ ୁ ରହ ା\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.24, Train BLEU: 0.00, Val BLEU: 21.66, Minutes Elapsed: 9.12\n","Sampling from val predictions...\n","Source: O thou that dwellest upon many waters , abundant in\n","Reference: ହ େ ଜଳର ା ଶ ି ନ ି କଟର\n","Model: <SOS> ତ େ ଦ ି ନ ି ଣ ! !\n","\n","Source: Hear ye , and give ear ; be not proud\n","Reference: ତ ୁ ମ ୍ ଭମ ା ନ େେ ସବ\n","Model: <SOS> ମ ା ମ ୍ ଭମ ା ନଙ ୍ କ\n","\n","Source: These be they who separate themselves , <UNK> , having\n","Reference: ଏହ ି ଲ ୋ କମ ା ନ େ ତ\n","Model: <SOS> ସମ ା ଲ ି କମ ା ନ େ ଯ\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 3.38, Train BLEU: 0.00, Val BLEU: 21.76, Minutes Elapsed: 10.12\n","Sampling from val predictions...\n","Source: In that day I will perform against Eli all things\n","Reference: ମ ୁ ଏଲ ି ର ପର ି ବ ା\n","Model: <SOS> ମ ୁଁ ନ ି ଯ ନ ି ବ ା\n","\n","Source: If after the manner of men I have fought with\n","Reference: ଯଦ ି ମ ୁଁ ଏଫ ି ସଠ ା ର\n","Model: <SOS> ଯଦ ି ଲ ୋ ନ ା ଲ ୋ ର\n","\n","Source: The <UNK> <UNK> of <UNK> flourished from the <UNK> to\n","Reference: ଖ ୍ ର ୀ ଷ ୍ ଟ ୀ ୟ\n","Model: <SOS> ପ ି ର ୀ ଷ ୍ ଟ ୀ ର\n","\n","Model training completed in 10 minutes with 2.97 best validation loss and 22.49 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_CHMB1Nbngrz","colab_type":"text"},"source":["## Show dev and test results"]},{"cell_type":"code","metadata":{"id":"DA1Gcfl1rqZ4","colab_type":"code","colab":{}},"source":["def plot_single_learning_curve(results, figsize=(14, 5)): \n","    \"\"\" Plots learning curve of a SINGLE experiment \"\"\"\n","    results_df = pd.DataFrame.from_dict(results)\n","    results_df = results_df.set_index('epoch')\n","    results_df = results_df[['val_bleu', 'val_loss']]\n","\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n","    results_df['val_loss'].plot(ax=axes[0])\n","    axes[0].set_ylabel('Validation Loss')\n","    results_df['val_bleu'].plot(ax=axes[1])\n","    axes[1].set_ylabel('Validation BLEU')\n","    axes[0].set_xlabel('Epoch')\n","    axes[1].set_xlabel('Epoch')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ8ttWthk5dx","colab_type":"code","outputId":"aeac236e-a549-4901-fd96-c0cdba692091","executionInfo":{"status":"ok","timestamp":1587530603646,"user_tz":240,"elapsed":1423,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["experiment_results = load_experiment_log(experiment_name=EXPERIMENT_NAME)\n","plot_single_learning_curve(experiment_results[0]['results'])"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1008x360 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RGA9kMUZmhEr","colab_type":"code","outputId":"64f87cc2-159f-475a-c067-dec7d39486f4","executionInfo":{"status":"ok","timestamp":1587530611569,"user_tz":240,"elapsed":1609,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["summarize_results(experiment_results)[['model_name', 'best_val_loss', 'best_val_bleu', 'runtime', \n","                                       'total_params', 'trainable_params', 'dt_created']]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_name</th>\n","      <th>best_val_loss</th>\n","      <th>best_val_bleu</th>\n","      <th>runtime</th>\n","      <th>total_params</th>\n","      <th>trainable_params</th>\n","      <th>dt_created</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>en-od-rnn-without-attn-2020-04-22 04:31:00</td>\n","      <td>2.96698</td>\n","      <td>22.490249</td>\n","      <td>10.115134</td>\n","      <td>32018094</td>\n","      <td>32018094</td>\n","      <td>2020-04-22 04:42:13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                   model_name  ...           dt_created\n","0  en-od-rnn-without-attn-2020-04-22 04:31:00  ...  2020-04-22 04:42:13\n","\n","[1 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"h_LGqZE-nuXv","colab_type":"code","outputId":"ced66eed-b3ee-443d-de87-762c5ec6c1a0","executionInfo":{"status":"ok","timestamp":1587530673576,"user_tz":240,"elapsed":1511,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# reload model \n","MODEL_NAME_TO_RELOAD = 'en-od-rnn-without-attn-2020-04-22 04:31:00'\n","checkpoint = torch.load('/content/drive/My Drive/ds1012/MT/model_checkpoints/{}.pth.tar'.format(MODEL_NAME_TO_RELOAD), map_location=device)\n","model.load_state_dict(checkpoint)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"iGtDelPvnvYv","colab_type":"code","outputId":"0e021f36-39af-489e-bcd1-14cc3fb7d04e","executionInfo":{"status":"ok","timestamp":1587530678230,"user_tz":240,"elapsed":1977,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# check performance on validation set \n","val_loss, val_bleu, val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens,\\\n","val_attn = evaluate(model=model, loader=loaders_full['dev'], \n","                    src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n","print(\"Validation BLEU: {:.2f} | Validation Loss: {:.2f}\".format(val_bleu, val_loss))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Validation BLEU: 22.49 | Validation Loss: 3.09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EmgtuBRSnxz6","colab_type":"code","outputId":"109e854f-c2b3-4f9b-9167-89a320a8efd5","executionInfo":{"status":"ok","timestamp":1587530682461,"user_tz":240,"elapsed":2617,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_loss, test_bleu, test_hyp_idxs, test_ref_idxs, test_source_idxs, test_hyp_tokens, test_ref_tokens, test_source_tokens,\\\n","test_attn = evaluate(model=model, loader=loaders_full['test'], \n","                     src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n","print(\"Test BLEU: {:.2f} | Test Loss: {:.2f}\".format(test_bleu, test_loss))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Test BLEU: 17.44 | Test Loss: 3.70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vqeovmmsM8Wx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}