{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_cz_on_ps_and_od.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLIfaSWFMUgyMBgQKngJcK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L8oK1k3C8IyV","colab_type":"code","outputId":"243c4b79-fc3d-4fa7-e935-438bd4aa66e7","executionInfo":{"status":"ok","timestamp":1589497673542,"user_tz":240,"elapsed":1512,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":189,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8BM71zNk9C1-","colab_type":"code","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","  \n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import torch\n","import torch.nn as nn \n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from io import open\n","from collections import Counter\n","from functools import partial\n","import unicodedata\n","import re\n","from torch.autograd import Variable\n","from gensim.models import KeyedVectors\n","from gensim.models.wrappers import FastText\n","import random\n","import time\n","from datetime import datetime\n","import pickle as pkl\n","import string\n","import os\n","from os import listdir \n","from ast import literal_eval\n","from nltk.tokenize import WordPunctTokenizer \n","\n","\n","import numpy as np \n","import pandas as pd \n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import random\n","import math \n","\n","\n","\n","\n","\n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt \n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","import sacrebleu\n","import random\n","import time\n","from datetime import datetime\n","import pickle as pkl\n","import string\n","import os\n","from os import listdir \n","from ast import literal_eval\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.style\n","import matplotlib as mpl\n","from collections import OrderedDict\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jev6MwG3KM6d","colab_type":"code","outputId":"6a4f6ab9-2eef-48bb-864c-8448bed3cf63","executionInfo":{"status":"ok","timestamp":1589480854735,"user_tz":240,"elapsed":3929,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# !pip install sacrebleu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n","\r\u001b[K     |█████▍                          | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n","Installing collected packages: portalocker, sacrebleu\n","Successfully installed portalocker-1.7.0 sacrebleu-1.4.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zJHiRKo3cNwh","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'cz'\n","\n","SRC_MAX_SENTENCE_LEN = 10\n","TARG_MAX_SENTENCE_LEN = 10\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000 # odia only has 6246 tokens. so will change this later\n","\n","BATCH_SIZE = 64"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZIceAKsv8NM","colab_type":"text"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"wVZdXJTg4_Jm","colab_type":"text"},"source":["### Split and save raw data into train.src.tok, train.targ.tok, val.src.tok, val.targ.tok, test.src.tok, test.targ.tok"]},{"cell_type":"code","metadata":{"id":"52PTi2UR3yYl","colab_type":"code","colab":{}},"source":["#### Create full data for (English, Pashto): combining 4 files each (not needed if you have the dataset in your directory)\n","\n","# en_ps_EN = ['bible.en-ps.clean.en', 'KDE4.en-ps.en', 'ted-wmt20.en-ps.en', 'Ubuntu.en-ps.en']\n","# en_ps_PS = ['bible.en-ps.clean.ps', 'KDE4.en-ps.ps', 'ted-wmt20.en-ps.ps', 'Ubuntu.en-ps.ps']\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/en.tok', 'w') as outfile:\n","#     for file_name in en_ps_EN:\n","#         with open(\"/content/drive/My Drive/ds1012/MT/data/en-ps/{}\".format(file_name)) as infile:\n","#             outfile.write(infile.read())\n","#         outfile.write('\\n')\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/ps.tok', 'w') as outfile:\n","#     for file_name in en_ps_PS:\n","#         with open(\"/content/drive/My Drive/ds1012/MT/data/en-ps/{}\".format(file_name)) as infile:\n","#             outfile.write(infile.read())\n","#         outfile.write('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFLDa2sR3DUW","colab_type":"code","colab":{}},"source":["#### Create train, dev, test for (English, Pashto)\n","\n","# random.seed(1234)\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/en.tok') as infile:\n","#     data = infile.readlines()\n","# train_idx = int(len(data)*0.7)\n","# dev_idx = int(len(data)*0.85)\n","# random.shuffle(data)\n","# train = data[:train_idx]\n","# dev = data[train_idx:dev_idx]\n","# test = data[dev_idx:]\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(train))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/dev.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(dev))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/test.en.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(test))\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/ps.tok') as infile:\n","#     data = infile.readlines()\n","\n","# random.shuffle(data)\n","# train = data[:train_idx]\n","# dev = data[train_idx:dev_idx]\n","# test = data[dev_idx:]\n","\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(train))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/dev.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(dev))\n","# with open('/content/drive/My Drive/ds1012/MT/data/en-ps/test.ps.tok', 'w') as outfile:\n","#     outfile.write(\"\".join(test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzyxoc3874r0","colab_type":"code","outputId":"98a9ed49-1c5b-4cf1-ecaa-97f7c85bdaed","executionInfo":{"status":"ok","timestamp":1589480952433,"user_tz":240,"elapsed":440,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# show examples for ps\n","with open('/content/drive/My Drive/ds1012/MT/data/en-ps/train.ps.tok') as f:\n","    data = f.read().split('\\n')\n","data[:10]\n","# Note: data are not clean where both en and ps has sentence like '%d:%02d:%02d'"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['مخبره',\n"," 'دا د اِسمٰعيل زامن وُو ، چې په دې ترتيب سره پېدا شوى وُو : نبايوت ، قيدار ، ادبيئل ، مِبسام ،',\n"," 'د کډي د کتابتونونو لپاره په مختاړي کې وژباړل شو',\n"," 'د قوم د راغونډولو د خبر د پاره به دواړه بيګلې غږولے شى . خو دا آواز به لنډ نۀ وى .',\n"," 'په پرليکه اکر کې پېلول',\n"," '. دا خوښبکس وتوانوﺉ چې د ليکبڼه ډول امستنې بدلې کړﺉ@ info: tooltip',\n"," 'عيسىٰ دَ هغوئ سره دَ غرۀ نه راکُوز شو اَؤ په هوار ميدان کښے ودريدو . په دغه ځائے کښے دَ هغۀ ګڼ مُريدان اَؤ ډير خلق چه ټول دَ يهُوديه اَؤ بيتُ المُقدس دَ صور اَؤ دَ صيدا دَ سمندرى غاړے نه راټول شوى وُو اَؤ دَ هغۀ آؤريدو ته راغلى وُو اَؤ چه دوئ دَ خپلو رنځُونو نه شفا ومُومى .',\n"," 'ننوت لېلې_',\n"," 'خو کله چه هغوئ دَ عيسىٰ خوا ته راغلل نو هغه ئے وليدو چه مړ دے ، نو هغوئ دَ هغۀ پښے ماتے نۀ کړلے .',\n"," '%d:%02d:%02d5:02:%Id%dshort time format']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"TF-rm5DGGtZK","colab_type":"code","colab":{}},"source":["#### Create train, dev, test for (English, Odia)\n","\n","# for i in ['train', 'dev', 'test']:\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.final'.format(i)) as infile:\n","#         lines = infile.readlines()\n","#     en_od_EN = []\n","#     en_od_OD = []\n","#     for line in lines:\n","#         en_od_EN.append(line.split('\\t')[1])\n","#         en_od_OD.append(line.split('\\t')[2])\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.en.tok'.format(i), 'w') as outfile:\n","#         outfile.write(\"\\n\".join(en_od_EN))\n","#     with open('/content/drive/My Drive/ds1012/MT/data/en-od/{}.od.tok'.format(i), 'w') as outfile:\n","#         outfile.write(\"\".join(en_od_OD))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cAQpuj4Imsz","colab_type":"code","outputId":"9df3d009-4bb3-494b-9aeb-b40f3d8b0734","executionInfo":{"status":"ok","timestamp":1587525324750,"user_tz":240,"elapsed":1830,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#### Show examples for od\n","with open('/content/drive/My Drive/ds1012/MT/data/en-od/train.od.tok') as f:\n","    data = f.read().split('\\n')\n","data[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ଆରମ୍ଭରେ ପରମେଶ୍ବର ଆକାଶ ଓ ପୃଥିବୀକୁ ସୃଷ୍ଟି କଲେ।',\n"," 'ପୃଥିବୀ ସେତବେେଳେ ସଂପୂରନ୍ଭାବେ ଶୂନ୍ଯ ଓ କିଛି ନଥିଲା। ଜଳଭାଗ ଉପରେ ଅନ୍ଧକାର ଘାଡ଼ଇେେ ରଖିଥିଲା ଏବଂ ପରମେଶ୍ବରଙ୍କର ଆତ୍ମା ଜଳଭାଗ ଉପରେ ବ୍ଯାପ୍ତ ଥିଲା।',\n"," 'ପରମେଶ୍ବର ଆଲୋକକୁ ଦେଖିଲେ ଏବଂ ସେ ଜାଣିଲେ, ତାହା ଉତ୍ତମ, ଏହାପ ରେ ପରମେଶ୍ବର ଆଲୋକକୁ ଅନ୍ଧକାରରୁ ଅଲଗା କଲେ।',\n"," 'ପରମେଶ୍ବର ସହେି ଆଲୋକର ନାମ ଦେଲେ \" ଦିନ\" ଏବଂ ଅନ୍ଧକାରର ନାମ ଦେଲେ \"ରାତି।\"',\n"," 'ଏହାପରେ ପରମେଶ୍ବର କହିଲେ, \"ଜଳ ମଧିଅରେ ବୃହତ ଗମ୍ବୁଜ ଜାତ ହାଇେ ଜଳକୁ ଦୁଇଭାଗ କରୁ!\"',\n"," 'ଏହିପରି ପରମେଶ୍ବର ତାରଣେ ନିର୍ମାଣ କଲେ ଏବଂ ତାଣେ ଉପର ଜଳଠାରୁ ତାରଣେ ତଳ ଜଳକୁ ଅଲଗା କଲେ। ତହିଁରେ ସହେିପରି ହେଲା।',\n"," 'ପରମେଶ୍ବର ସହେି ତାରଣେ ନାମ ଦେଲେ \"ଆକାଶ\" ତା\\'ପରେ ସଠାେ ରେ ପ୍ରଭାତ ଏବଂ ସଠାେରେ ସୁର୍ୟ୍ଯାସ୍ତ ହେଲା। ଏବଂ ଏହା ଦି୍ବତୀଯ ଦିନ ଥିଲା।',\n"," 'ଏହାପରେ ପରମେଶ୍ବର କହିଲେ, \"ଆକାଶମଣ୍ଡଳ ଅଧଃସ୍ଥ ସମଗ୍ର ଜଳ ଏକ ସ୍ଥାନ ରେ ସଂଗୃହିତ ହେଉ। ୟଦ୍ବାରା ଭୂମି ଶୁଖିଲା ଦଖାୟିବେ।\" ଏବଂ ଏହିପରି ହେଲା।',\n"," 'ପରମେଶ୍ବର ଶୁଖିଲା ଭୂମିର ନାମ \"ପୃଥିବୀ\" ଦେଲେ। ଏବଂ ଜଳସମୁହ ଭାଗର ନାମ ଦେଲେ, \"ସମୁଦ୍ର।\" ଏହା ପରମେଶ୍ବରଙ୍କ ଦୃଷ୍ଟିରେ ଅତି ଉତ୍ତମ ଦିଶିଥିଲା।',\n"," 'ପରମେଶ୍ବର କହିଲେ, \"ପୃଥିବୀ ତୃଣ ଓ ସଜୀବ ଶାକ, ଜୀବ ସମ୍ବଳିତ ନିଜ ନିଜ ଜାତି ଅନୁୟାଯୀ ଫଳ ଉତ୍ପନ୍ନ କରୁ,\" ଏହିପରି ହେଲା।']"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"8lENZAm9csX9","colab_type":"code","outputId":"1d255cf2-e43f-4eaa-f563-0d3dd2c5d204","executionInfo":{"status":"ok","timestamp":1589481004258,"user_tz":240,"elapsed":1903,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#### Show examples for od\n","with open('/content/drive/My Drive/ds1012/MT/data/en-cz/train.cz.tok') as f:\n","    data = f.read().split('**=')\n","data[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Při vytváření fondu EU pro přizpůsobení je třeba brát v potaz zejména přizpůsobování lesů a na jejich odolnost.',\n"," 'Jde především o přistěhovalce z východu.',\n"," 'Základní koncept potravinové soběstačnosti, jenž nemůže být oddělen od zajišťování potravin, není řešen.',\n"," 'Musíme změnit výši i podobu rozpočtu, tak aby více přímo odpovídal našim hlavním politickým prioritám.',\n"," 'Je důležité banky rekapitalizovat, ovšem rekapitalizované banky za situace, kdy jsou malé a střední podniky na kolenou, jsou cestou do záhuby.',\n"," '(CS) Afrika bývala špatným svědomím Evropy kvůli koloniální politice.',\n"," 'Tyto kvalitní informace by měly být samozřejmě dostupné na internetu, který je moderním prostředkem komunikace, a to v mateřském jazyce pacientů.',\n"," 'Bylo zde uvedeno, že jednotný trh hraje klíčovou roli při zajišťování růstu.',\n"," 'Domnívám se, že to byla neuvěřitelná chyba ze strany předsednictva a sekretariátu.',\n"," 'Miguel Ángel a Edén Galván strávili ve vězení devatenáct dní.']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"IoUv2m-7wGVd","colab_type":"text"},"source":["### Generate Vocab and Tokenize"]},{"cell_type":"code","metadata":{"id":"z8hlbmXHyF5b","colab_type":"code","colab":{}},"source":["RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","\n","def get_filepath(split, src_lang, targ_lang, lang_type): \n","    \"\"\" Locates data filepath given data split type (train/dev/test), translation pairs (src_lang -> targ_lang), \n","        and the language type (source or target) \n","        e.g. to load train.en.tok for en-ps pair, use get_filepath(split='train', src_lang='en', targ_lang='ps', lang_type='source')\n","    \"\"\"\n","    folder_name = \"/content/drive/My Drive/ds1012/MT/data/{}-{}/\".format(src_lang, targ_lang)\n","    if lang_type == 'source': \n","        file_name = \"{}.{}.tok\".format(split, src_lang)\n","    elif lang_type == 'target': \n","        file_name = \"{}.{}.tok\".format(split, targ_lang)\n","    return folder_name + file_name\n","\n","\n","def build_vocab(token_lists, max_vocab_size): \n","    \"\"\" Takes lists of tokens (representing sentences of words), max_vocab_size and returns: \n","        - id2token: list of tokens, where id2token[i] returns token that corresponds to i-th token \n","        - token2id: dictionary where keys represent tokens and corresponding values represent their indices\n","        Note that the vocab will comprise N=max_vocab_size-len(RESERVED_TOKENS) most frequently occuring tokens\n","    \"\"\"\n","    num_vocab = max_vocab_size - len(RESERVED_TOKENS)\n","    all_tokens = [token for sublist in token_lists for token in sublist]\n","    token_counter = Counter(all_tokens)\n","    vocab, count = zip(*token_counter.most_common(num_vocab))\n","    id2token = sorted(RESERVED_TOKENS, key=RESERVED_TOKENS.get) + list(vocab)\n","    token2id = dict(zip(id2token, range(max_vocab_size)))\n","    \n","    # check how many unique tokens + pct of corpus are represented in our vocab \n","    tokens_in_vocab_pct_corpus = 100 * sum([token_counter[token] for token in vocab]) / len(all_tokens)\n","    print(\"A vocabulary of {} is generated from a set of {} unique tokens, representing {:.1f}% of entire corpus\".format(\n","        len(vocab), len(token_counter), tokens_in_vocab_pct_corpus))\n","    \n","    return token2id, id2token \n","\n","\n","\n","def generate_vocab(src_lang, targ_lang, src_vocab_size, targ_vocab_size):\n","    \"\"\" \n","        Takes source and target language names and vocab sizes, outputs a nested dictionary vocab \n","        containing token2id and id2token for both source and target languages. \n","        Note the first level of keys is lang_name (e.g. 'en'), and that of nested dictionary are token2id and id2token.\n","    \"\"\"\n","    vocab = {} \n","    for lang, vocab_size in zip([src_lang, targ_lang], [src_vocab_size, targ_vocab_size]): \n","        \n","        # load train data \n","        train_data_fp = get_filepath(split='train', src_lang=src_lang, targ_lang=targ_lang, \n","                                     lang_type='source' if lang == 'en' else 'target')\n","        # tokenize train data\n","        tk = WordPunctTokenizer() \n","        with open(train_data_fp) as f:\n","            train_tokens = [tk.tokenize(line) for line in f.read().split('**=')]\n","\n","        # generate token2id and id2token \n","        token2id, id2token = build_vocab(train_tokens, vocab_size) \n","        \n","        # store token2id, id2token as a dict in nested dict lang \n","        vocab[lang] = {'token2id': token2id, 'id2token': id2token}\n","        \n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrYvZioLPL6O","colab_type":"code","colab":{}},"source":["### it takes a long time to generate vocabulary, so save to pickle for reimport in future \n","\n","## en-ps pair\n","# SRC_LANG = 'en'\n","# TARG_LANG = 'ps'\n","# SRC_VOCAB_SIZE = 10000 \n","# TARG_VOCAB_SIZE = 10000 \n","# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n","# vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","# pkl.dump(vocab, open(vocab_filename, \"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj9r73yNXLYi","colab_type":"code","colab":{}},"source":["# # en-od pair\n","# SRC_LANG = 'en'\n","# TARG_LANG = 'od'\n","# SRC_VOCAB_SIZE = 10000 \n","# TARG_VOCAB_SIZE = 10000 \n","# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n","# vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","# pkl.dump(vocab, open(vocab_filename, \"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"af85TY93c6RJ","colab_type":"code","outputId":"1fe829de-90b8-4b0d-8ad0-0b5965b44798","executionInfo":{"status":"ok","timestamp":1589481134212,"user_tz":240,"elapsed":16224,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# # en-cz pair\n","# SRC_LANG = 'en'\n","# TARG_LANG = 'cz'\n","# SRC_VOCAB_SIZE = 10000 \n","# TARG_VOCAB_SIZE = 10000 \n","# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n","# vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","# pkl.dump(vocab, open(vocab_filename, \"wb\"))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A vocabulary of 9996 is generated from a set of 52636 unique tokens, representing 98.1% of entire corpus\n","A vocabulary of 9996 is generated from a set of 166363 unique tokens, representing 89.7% of entire corpus\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5O5Cvi57WFy_","colab_type":"code","colab":{}},"source":["# reload from pickle for en-ps\n","SRC_LANG = 'en'\n","TARG_LANG = 'cz'\n","SRC_VOCAB_SIZE = 10000\n","TARG_VOCAB_SIZE = 10000\n","\n","vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","vocab = pkl.load(open(vocab_filename, \"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaLv-3KPWFdU","colab_type":"code","colab":{}},"source":["# usage \n","## vocab['en']['id2token']\n","## vocab['od']['token2id']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZNb6UqV-cLx7","colab_type":"text"},"source":["### Generate Data using Vocab"]},{"cell_type":"code","metadata":{"id":"G66g-ayLXxWu","colab_type":"code","colab":{}},"source":["def get_filepaths(src_lang, targ_lang): \n","    \"\"\" Takes language names ('ps', 'en') to be translated from and to (in_lang and out_lang respectively) as inputs, \n","        returns a nested dictionary containing the filepaths for input/output data for train/dev/test sets  \n","        e.g. fps['train']['source']['filepath']\n","    \"\"\"\n","    fps = {} \n","    \n","    # store language names \n","    fps['languages'] = {} \n","    fps['languages']['source'] = src_lang\n","    fps['languages']['target'] = targ_lang \n","    \n","    # store filepaths \n","    for split in ['train', 'dev', 'test']: \n","        fps[split] = {} \n","        for lang_type in ['source', 'target']: \n","            fps[split][lang_type] = {} \n","            fps[split][lang_type]['filepath'] = get_filepath(split, src_lang, targ_lang, lang_type)\n","            \n","    return fps\n","\n","\n","def text2tokens(raw_text_fp, lang_type): \n","    \"\"\" Takes filepath of raw text and outputs a list of lists, each representing a sentence of words (tokens) \n","        Note that it appends to target sentences <SOS> at the start, and <EOS> at the end, but only <EOS> at the end for source sentences\n","    \"\"\"\n","    with open(raw_text_fp) as f:\n","        tk = WordPunctTokenizer()\n","        tokens_data = [tk.tokenize(line) for line in f.readlines()]\n","        # for szech only\n","        # tokens_data = [tk.tokenize(line) for line in f.read().split('**=')]\n","        if lang_type == 'source': \n","            tokens_data = [datum + ['<EOS>'] for datum in tokens_data]\n","        elif lang_type == 'target': \n","            tokens_data = [['<SOS>'] + datum + ['<EOS>'] for datum in tokens_data]\n","    return tokens_data \n","\n","\n","def tokens2indices(tokens_data, token2id): \n","    \"\"\" Takes tokenized data and token2id dictionary and returns indexed data \"\"\"\n","    indices_data = [] \n","    for datum in tokens_data: \n","        indices_datum = [token2id[token] if token in token2id else RESERVED_TOKENS['<UNK>'] for token in datum ]\n","        indices_data.append(indices_datum)    \n","    return indices_data\n","\n","\n","def process_data(src_lang, targ_lang, src_max_sentence_len, targ_max_sentence_len, vocab, sample_limit=None, filter_long=True): \n","    \"\"\" \n","        - Main function that takes source and target language names, vocab dict generated, \n","        and an optional sample_limit representing the number of sentences to subset if necessary (for evaluation).\n","        we filter out long senstences whose length goes above src(targ)_max_sentence_len if filter_long\n","        - Returns data as a nested dictionary containing the indices and tokens of train/dev/test data \n","        for both source and target languages. \n","        - Note the hierachy of data dict is: data[split][lang_type]['tokens' or 'indices'], \n","        e.g. to access indices of source training data, use data['train']['source']['indices'] or data['train']['source']['tokens']\n","    \"\"\" \n","    \n","    # get filepaths \n","    data = get_filepaths(src_lang, targ_lang)\n","    \n","    # loop through each file, read in text, convert to tokens, then to indices \n","    for split in ['train', 'dev', 'test']: \n","        for lang_type in ['source', 'target']: \n","            # read in tokens \n","            data[split][lang_type]['tokens'] = text2tokens(data[split][lang_type]['filepath'], lang_type)\n","    \n","    # for training data, keep only pairs with both source and target sentences within max_sent_len \n","    if filter_long: \n","        original_train_size = len(data['train']['source']['tokens'])\n","        source_lengths = np.array([len(l) for l in data['train']['source']['tokens']])\n","        target_lengths = np.array([len(l) for l in data['train']['target']['tokens']])\n","        keep_mask = (source_lengths <= src_max_sentence_len) & (target_lengths <= targ_max_sentence_len)\n","        data['train']['source']['tokens'] = list(np.array(data['train']['source']['tokens'])[keep_mask])\n","        data['train']['target']['tokens'] = list(np.array(data['train']['target']['tokens'])[keep_mask])\n","        new_train_size = len(data['train']['source']['tokens']) \n","        print(\"{} data points are removed from training data after filtering out long sentences: {} remain.\".format(\n","            new_train_size - original_train_size, new_train_size))\n","    # further limit number of samples if applicable \n","    if sample_limit is not None: \n","        for split in ['train', 'dev', 'test']: \n","            for lang_type in ['source', 'target']: \n","                data[split][lang_type]['tokens'] = data[split][lang_type]['tokens'][:sample_limit]\n","\n","    # convert tokens to indices \n","    for split in ['train', 'dev', 'test']: \n","        for lang_type in ['source', 'target']: \n","            data[split][lang_type]['indices'] = tokens2indices(tokens_data=data[split][lang_type]['tokens'],  \n","                token2id = vocab[data['languages'][lang_type]]['token2id'])\n","\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zE2ptrCoXxQC","colab_type":"code","colab":{}},"source":["# Load data for en-cz\n","data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False) # 449691\n","data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) #64\n","data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False) #1000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PooErl-qXw7w","colab_type":"text"},"source":["### Create Dataloaders"]},{"cell_type":"code","metadata":{"id":"F9cQLOCkWFU5","colab_type":"code","colab":{}},"source":["class TranslationDataset(Dataset): \n","    \"\"\" \n","    Class that represents a train/validation/test/dataset that's readable for Pytorch. \n","    Note that this class inherits torch.utils.data.Dataset\n","    return \n","    \"\"\"\n","    def __init__(self, src_indices, targ_indices, src_max_sentence_len, targ_max_sentence_len):\n","        \"\"\" \n","        Initialize dataset by passing in a list of input indices and a list of output indices with defined maximum length for each sentence\n","        \"\"\"\n","        self.src_indices = src_indices\n","        self.targ_indices = targ_indices\n","        self.src_max_sentence_len = src_max_sentence_len\n","        self.targ_max_sentence_len = targ_max_sentence_len\n","        assert (len(self.src_indices) == len(self.targ_indices))\n","        \n","    def __len__(self): \n","        return len(self.src_indices)\n","    \n","    def __getitem__(self, key): \n","        \"\"\" \n","        Triggered when dataset[i] is called, outputs lists of input and output indices, as well as their \n","        respective lengths\n","        \"\"\"\n","        src_idx = self.src_indices[key][:self.src_max_sentence_len]\n","        src_len = len(src_idx)\n","        targ_idx = self.targ_indices[key][:self.targ_max_sentence_len]\n","        targ_len = len(targ_idx)\n","        return [src_idx, targ_idx, src_len, targ_len]\n","    \n","\n","def collate_func(src_max_sentence_len, targ_max_sentence_len, batch): \n","    \"\"\" Customized function for DataLoader that dynamically pads the batch so that all data have the same length\"\"\"\n","    \n","    src_idxs = [] \n","    targ_idxs = [] \n","    src_lens = [] \n","    targ_lens = [] \n","    \n","    for datum in batch: \n","        # append original lengths of sequences \n","        src_lens.append(datum[2]) \n","        targ_lens.append(datum[3])\n","        \n","        # pad sequences before appending \n","        src_idx_padded = np.pad(array=np.array(datum[0]), pad_width = ((0, src_max_sentence_len - datum[2])), \n","                                mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n","        targ_idx_padded = np.pad(array=np.array(datum[1]), pad_width = ((0, targ_max_sentence_len - datum[3])),\n","                                 mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n","        src_idxs.append(src_idx_padded)\n","        targ_idxs.append(targ_idx_padded)\n","    \n","    return [torch.from_numpy(np.array(src_idxs)), torch.from_numpy(np.array(targ_idxs)), \n","            torch.LongTensor(src_lens), torch.LongTensor(targ_lens)]\n","\n","\n","def create_dataloaders(processed_data, src_max_sentence_len, targ_max_sentence_len, batch_size): \n","    \"\"\" Takes processed_data as dictionary output from process_data func, maximum sentence lengths, \n","        outputs a nested dictionary called 'loaders' that holds train, dev, and test loaders, \n","        e.g. loaders['dev'] holds the data loader for dev/validation set \n","    \"\"\"\n","    loaders = {} \n","    for split in ['train', 'dev', 'test']: \n","        dataset = TranslationDataset(processed_data[split]['source']['indices'], processed_data[split]['target']['indices'], \n","                                     src_max_sentence_len, targ_max_sentence_len)\n","        loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n","                                    collate_fn=partial(collate_func, src_max_sentence_len, targ_max_sentence_len))\n","    return loaders"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19-Ds_oWqH3K","colab_type":"code","colab":{}},"source":["# create dataloaders \n","## in the form \n","loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNDeUl6ipWNk","colab_type":"code","colab":{}},"source":["# examine dataloader (dont' run if you use the loders later)\n","# for src_idx, targ_idx, src_len, targ_len in loaders_full['train']:\n","#     print('source index:',src_idx,'\\ntarget index:', targ_idx, '\\nsource length', src_len, '\\ntarget length', targ_len)\n","#     break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7VbjRqUu7s7","colab_type":"text"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"vhd2ztkhu7bH","colab_type":"text"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"o0fZbmIPu7H7","colab_type":"code","colab":{}},"source":["# RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class EncoderRNN(nn.Module):\n","    \"\"\" RNN encoder\"\"\" \n","\n","    def __init__(self, rnn_cell_type, src_vocab_size, enc_hidden_dim, num_layers, enc_dropout, src_max_sentence_len):\n","        super(EncoderRNN, self).__init__()\n","        self.src_vocab_size = src_vocab_size\n","        self.enc_embed_dim = 300\n","        self.enc_hidden_dim = enc_hidden_dim \n","        self.enc_dropout = enc_dropout \n","        self.src_max_sentence_len = src_max_sentence_len\n","        self.num_layers = num_layers\n","        self.embedding = nn.Embedding(src_vocab_size, self.enc_embed_dim)\n","        self.rnn_cell_type = rnn_cell_type \n","        if self.rnn_cell_type == 'gru': \n","            self.rnn = nn.GRU(input_size=self.enc_embed_dim, hidden_size=self.enc_hidden_dim, num_layers=self.num_layers, \n","                dropout = enc_dropout, batch_first=True, bidirectional=True) \n","        elif self.rnn_cell_type == 'lstm': \n","            self.rnn = nn.LSTM(input_size=self.enc_embed_dim, hidden_size=self.enc_hidden_dim, num_layers=self.num_layers, \n","                dropout = enc_dropout, batch_first=True, bidirectional=True)\n","\n","    def forward(self, enc_input, enc_input_lens):\n","        # save computation by packing paded sequence\n","        batch_size = enc_input.size()[0] # the number of sentences in 1 batch\n","        _, idx_sort = torch.sort(enc_input_lens, dim=0, descending=True)\n","        _, idx_unsort = torch.sort(idx_sort, dim=0)\n","        enc_input, enc_input_lens = enc_input.index_select(0, idx_sort), enc_input_lens.index_select(0, idx_sort) # 0 dimension to reselect\n","        embedded = self.embedding(enc_input) # [batch_size, seq len(the length of each sentence), emb dim(the embedding for each word in a sentence)] e.g [64,10,300]\n","        embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, enc_input_lens, batch_first=True)\n","        # implement rnn\n","        hidden = self.initHidden(batch_size) \n","        if self.rnn_cell_type == 'gru': \n","            output, hidden = self.rnn(embedded, hidden)\n","        elif self.rnn_cell_type == 'lstm': \n","            memory = self.initHidden(batch_size)\n","            output, (hidden, memory) = self.rnn(embedded, (hidden, memory)) \n","        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, \n","                                                            total_length=self.src_max_sentence_len,\n","                                                            padding_value=RESERVED_TOKENS['<PAD>'])\n","        # output: (batch, seq_len, num_directions * hidden_size)\n","        # get the output and hidden in the original unsorted order\n","        output = output.index_select(0, idx_unsort)\n","        hidden = hidden.index_select(1, idx_unsort)\n","        output = torch.cat([output[:, :, :self.enc_hidden_dim], output[:, :, self.enc_hidden_dim:]], dim=2)\n","        hidden = hidden.view(self.num_layers, 2, batch_size, self.enc_hidden_dim) # # h_n.view(num_layers, num_directions, batch, hidden_size)\n","        hidden = torch.cat([hidden[:, 0, :, :].view(self.num_layers, 1, batch_size, self.enc_hidden_dim).squeeze(dim=1), \n","            hidden[:, 1, :, :].view(self.num_layers, 1, batch_size, self.enc_hidden_dim).squeeze(dim=1)], dim=2) \n","        hidden = hidden.view(self.num_layers, batch_size, 2 * self.enc_hidden_dim)\n","\n","        return output, hidden\n","\n","    def initHidden(self, batch_size):\n","        return torch.zeros(2*self.num_layers, batch_size, self.enc_hidden_dim).to(device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xIJdgWplu6--","colab_type":"text"},"source":["### Decoder"]},{"cell_type":"code","metadata":{"id":"F06VQX-Ku62S","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module): \n","\n","\t\"\"\" Vanilla decoder without attention, but final layer from encoder is repeatedly passed as input to each time step. \n","\t\tHandles output from EncoderRNN, which concats bidirectional output. \n","\t\"\"\" \n","\n","\tdef __init__(self, dec_hidden_dim, enc_hidden_dim, num_layers, targ_vocab_size, targ_max_sentence_len):\n","\t\tsuper(DecoderRNN, self).__init__()\n","\t\tself.dec_embed_dim = 300\n","\t\tself.dec_hidden_dim = dec_hidden_dim \n","\t\tself.enc_hidden_dim = enc_hidden_dim\n","\t\tself.targ_vocab_size = targ_vocab_size\n","\t\tself.targ_max_sentence_len = targ_max_sentence_len\n","\t\tself.num_layers = num_layers\n","\t\tself.embedding = nn.Embedding(targ_vocab_size, self.dec_embed_dim)\n","\t\tself.gru = nn.GRU(self.dec_embed_dim + 2 * self.enc_hidden_dim, self.dec_hidden_dim, num_layers=self.num_layers) \n","\t\tself.out = nn.Linear(dec_hidden_dim, self.targ_vocab_size) \n","\t\tself.softmax = nn.LogSoftmax(dim=1) \n","\n","\tdef forward(self, dec_input, dec_hidden, enc_outputs): \n","\t\tdec_input = dec_input \n","\t\tdec_hidden = dec_hidden \n","\t\tenc_outputs = enc_outputs \n","\t\tbatch_size = dec_input.size()[0]\n","\t\tembedded = self.embedding(dec_input).view(1, batch_size, -1)\t\n","#\t\tcontext = enc_outputs[:, -1, :].unsqueeze(dim=1).transpose(0, 1) \n","\t\tcontext = torch.cat([enc_outputs[:, -1, :self.enc_hidden_dim], \n","\t\t\t\t\t\t\t enc_outputs[:, 0, self.enc_hidden_dim:]], dim=1).unsqueeze(0)\n","\t\tconcat = torch.cat([embedded, context], 2) \n","\t\toutput, hidden = self.gru(concat, dec_hidden)\n","\t\toutput = self.softmax(self.out(output[0]))  \n","\t\treturn output, hidden\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eKcvBFUau6tj","colab_type":"text"},"source":["### Bidirectional Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"OW5q5aTQu6dY","colab_type":"code","colab":{}},"source":["class EncoderDecoder(nn.Module): \n","\n","\t\"\"\" Encoder-Decoder without attention \"\"\"\n","\n","\tdef __init__(self, encoder, decoder, decoder_token2id): \n","\t\tsuper(EncoderDecoder, self).__init__() \n","\t\tself.encoder = encoder \n","\t\tself.decoder = decoder \n","\t\tself.targ_vocab_size = self.decoder.targ_vocab_size\n","\t\tself.src_max_sentence_len = self.encoder.src_max_sentence_len \n","\t\tself.targ_max_sentence_len = self.decoder.targ_max_sentence_len \n","\n","\tdef forward(self, src_idx, targ_idx, src_lens, targ_lens, teacher_forcing_ratio): \n","\t\t\n","\t\tbatch_size = src_idx.size()[0]\n","\t\tenc_outputs, enc_hidden = self.encoder(src_idx, src_lens)\n","\t\tdec_hidden = enc_hidden \n","\t\tdec_outputs = Variable(torch.zeros(self.targ_max_sentence_len, batch_size, self.targ_vocab_size))\n","\t\thypotheses = Variable(torch.zeros(self.targ_max_sentence_len, batch_size))\n","\t\tdec_output = targ_idx[:, 0] \n","\n","\t\tfor di in range(1, self.targ_max_sentence_len): \n","\t\t\tdec_output, dec_hidden = self.decoder(dec_output, dec_hidden, enc_outputs)\n","\t\t\tdec_outputs[di] = dec_output \n","\t\t\tteacher_labels = targ_idx[:, di-1] \n","\t\t\tgreedy_labels = dec_output.data.max(1)[1]\n","\t\t\tdec_output = teacher_labels if random.random() < teacher_forcing_ratio else greedy_labels \n","\t\t\thypotheses[di] = greedy_labels\n","\n","\t\tattn_placeholder = Variable(torch.zeros(batch_size, self.targ_max_sentence_len, self.src_max_sentence_len))\n","\n","\t\treturn dec_outputs, hypotheses.transpose(0,1), attn_placeholder \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2-GF1kWu6WI","colab_type":"text"},"source":["## Train and Evaluate"]},{"cell_type":"code","metadata":{"id":"aTU2Y4HBu6P0","colab_type":"code","colab":{}},"source":["#RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","RESULTS_LOG = '/content/drive/My Drive/ds1012/MT/experiment_results/{}_{}_experiment_results_log.pkl'.format(SRC_LANG, TARG_LANG)\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def filter_reserved_tokens(sentence_as_list): \n","    \"\"\" Takes a list of tokens representing a sentence, removes everything after <EOS>, \n","    as well as remove reserved tokens <SOS>, <EOS>, <PAD>. Outputs filtered sentence as a string. \"\"\" \n","\n","    # drops everything after <EOS> \n","    try: \n","        output = sentence_as_list[:sentence_as_list.index('<EOS>')]\n","    except: \n","        output = sentence_as_list\n","\n","    # drops <SOS>, <EOS>, <PAD>  \n","    output = ' '.join([idx for idx in output if idx not in ['<SOS>', '<EOS>', '<PAD>']]) \n","\n","    return output \n","\n","\n","def tensor2corpus(tensor, id2token):  \n","    \"\"\" Takes a tensor representing a batch of sentences (size: batch_size * max_sentence_length), and returns \n","        its token equivalent (as list of tokens) \"\"\" \n","    list_of_lists = tensor.cpu().numpy().astype(int).tolist()\n","    #print(np.max(list_of_lists))\n","    to_token = lambda l: [id2token[idx] for idx in l]\n","    corpus = [to_token(l) for l in list_of_lists] \n"," \n","    return corpus\n","\n","\n","def reconstruct_corpus(token_list): \n","    \"\"\" Takes a list of tokens, filter out reserved tokens, and returns a list of sentence strings \"\"\" \n","\n","    sentences = [filter_reserved_tokens(sublist) for sublist in token_list]\n","\n","    return sentences  \n","\n","\n","def calc_corpus_bleu(ref_list, hyp_list): \n","    \"\"\" Takes a list of reference sentences and a list of hypothesis sentences, flattens them, and outputs their corpus bleu \"\"\"\n","\n","    # convert ref_list and hyp_list into strings \n","    hyp_stream = reconstruct_corpus(hyp_list)\n","    ref_streams = [reconstruct_corpus(ref_list)]\n","    \n","    # compute bleu score \n","    bleu_score = sacrebleu.corpus_bleu(hyp_stream, ref_streams).score  \n","\n","    return bleu_score \n","\n","\n","def evaluate(model, loader, src_id2token, targ_id2token, teacher_forcing_ratio=1): \n","    \"\"\" Evaluates a model given a loader, id2token dicts, and teacher_forcing_ratio. \n","        Outputs avg loss, avg bleu, as well as indices and tokens representing source, reference, and model translations. \n","    \"\"\"\n","    \n","    with torch.no_grad():\n","\n","        model.eval() \n","        total_loss = 0 \n","\n","        # initialize empty list to hold all source, reference and model translations \n","        reference_corpus = []\n","        hypothesis_corpus = [] \n","        source_corpus = [] \n","        attn_weights_corpus = []\n","        \n","        for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(loader): \n","\n","            # for each batch, compute loss and accumulate to total \n","            batch_size = src_idxs.size()[0]        \n","            src_idxs, targ_idxs, src_lens, targ_lens = src_idxs.to(device), targ_idxs.to(device), src_lens.to(device), targ_lens.to(device)\n","            outputs, hypotheses, attn_weights = model(src_idxs, targ_idxs, src_lens, targ_lens, \n","                teacher_forcing_ratio=teacher_forcing_ratio)\n","            outputs = outputs[1:].transpose(0, 1)\n","            targets = targ_idxs[:,1:]\n","            attn_weights = attn_weights[:,1:]\n","            outputs_for_nll = outputs.contiguous().view(-1, model.decoder.targ_vocab_size).to(device)\n","            targets_for_nll = targets.contiguous().view(-1).to(device)\n","            loss = F.nll_loss(outputs_for_nll, targets_for_nll, ignore_index=RESERVED_TOKENS['<PAD>'])        \n","            total_loss += loss.item()  \n","\n","            # append to lists holding corpus \n","            hypothesis_corpus.append(hypotheses)\n","            reference_corpus.append(targets)\n","            source_corpus.append(src_idxs)\n","            attn_weights_corpus.append(attn_weights)\n","\n","    # concat list of index tensors into corpus tensors (as indices), then convert to list of sentence (as tokens)\n","    hyp_idxs = torch.cat(hypothesis_corpus, dim=0) \n","    ref_idxs = torch.cat(reference_corpus, dim=0)\n","    source_idxs = torch.cat(source_corpus, dim=0)\n","    attn = torch.cat(attn_weights_corpus, dim=0)\n","\n","    hyp_tokens = tensor2corpus(hyp_idxs, targ_id2token)\n","    ref_tokens = tensor2corpus(ref_idxs, targ_id2token)\n","    source_tokens = tensor2corpus(source_idxs, src_id2token)\n","\n","    # compute evaluation metrics \n","    avg_loss = total_loss / len(loader)\n","    avg_bleu = calc_corpus_bleu(ref_tokens, hyp_tokens)\n","    \n","    return avg_loss, avg_bleu, hyp_idxs, ref_idxs, source_idxs, hyp_tokens, ref_tokens, source_tokens, attn   \n","\n","\n","def train_and_eval(model, loaders_full, loaders_minibatch, loaders_minitrain, params, vocab, \n","    lazy_eval=True, print_intermediate=1000000, save_checkpoint=True, save_to_log=True, inspect_samples=None, print_attn=False): \n","    \n","    \"\"\" Main function to train and evaluate model: takes a model, loaders, and a bunch of parameters and \n","        returns trained model along with a results dict storing epoch, train/val loss, and train/val bleu scores. \n","        Note that: \n","        - lazy_train = train and validate only on a single mini batch (for quick prototyping) \n","        - lazy_eval = skip evaluation on train set altogether (not even the 1K proxy) \n","        - print_intermediate = reports loss and bleu scores every 'print_intermediate' minibatches or end of each epoch \n","        - save_checkpoint = saves model's state dict into a .pth.tar file named after model_name \n","        - save_to_log = saves results to log \n","        - inspect_samples = specify number of samples to print out every 1K batches \n","    \"\"\"\n","    \n","    start_time = time.time() \n","\n","    # extract local variables from params \n","    learning_rate = params['learning_rate'] \n","    targ_id2token = vocab[params['targ_lang']]['id2token']\n","    src_id2token = vocab[params['src_lang']]['id2token']\n","    num_epochs = params['num_epochs']\n","    teacher_forcing_ratio = params['teacher_forcing_ratio']\n","    clip_grad_max_norm = params['clip_grad_max_norm']\n","    experiment_name = params['experiment_name']\n","    model_name = params['model_name']\n","    lazy_train = params['lazy_train']\n","    attention_type = params['attention_type']\n","    # print(targ_id2token)\n","    # designate data loaders used to train and calculate losses \n","    if lazy_train: \n","        train_loader_ = loaders_minibatch['train'] # used to train \n","        dev_loader_ = loaders_minibatch['dev'] # used to calculate dev loss \n","        train_loader_proxy = loaders_minibatch['train'] # used to calculate train loss \n","    else: \n","        train_loader_ = loaders_full['train']\n","        dev_loader_ = loaders_full['dev'] \n","        # evaluating on full training set prohibitively expensive, so use a 1K batch instead as proxy \n","        train_loader_proxy = loaders_minitrain['train'] \n","\n","    # initialize optimizer and criterion \n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss(ignore_index=RESERVED_TOKENS['<PAD>'])\n","    results = [] \n","    \n","    # loop through train data in batches and train \n","    for epoch in range(num_epochs): \n","        train_loss = 0 \n","        for batch, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader_):\n","            DEBUG_START = time.time() \n","            src_idxs, targ_idxs, src_lens, targ_lens = src_idxs.to(device), targ_idxs.to(device), src_lens.to(device), targ_lens.to(device)\n","            model.train()\n","            optimizer.zero_grad()\n","            final_outputs, hypotheses, attn_weights = model(src_idxs, targ_idxs, src_lens, targ_lens, teacher_forcing_ratio=teacher_forcing_ratio)\n","            # attn_weights = attn_weights[:,1:]\n","            final_outputs = final_outputs[1:].transpose(0, 1)\n","            targets = targ_idxs[:,1:]\n","            outputs_for_nll = final_outputs.contiguous().view(-1, model.decoder.targ_vocab_size).to(device)\n","            targets_for_nll = targets.contiguous().view(-1).to(device)\n","            loss = criterion(outputs_for_nll, targets_for_nll)\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_max_norm)\n","            optimizer.step()\n","\n","            # evaluate and report loss and bleu scores every 'print_intermediate' minibatches or end of each epoch\n","            if batch % print_intermediate == 0 or ((epoch==num_epochs-1) & (batch==len(train_loader_)-1)):\n","\n","                result = {} \n","                result['epoch'] = epoch + batch / len(train_loader_) \n","\n","                # calculate metrics on validation set \n","                result['val_loss'], result['val_bleu'], val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens, val_attn = \\\n","                    evaluate(model, dev_loader_, src_id2token, targ_id2token, teacher_forcing_ratio=teacher_forcing_ratio)         \n","\n","                # calculate metrics on train set (or proxy thereof) only if lazy_eval not set to True \n","                if not lazy_eval: \n","                    result['train_loss'], result['train_bleu'], train_hyp_idxs, train_ref_idxs, train_source_idxs, train_hyp_tokens, train_ref_tokens, train_source_tokens, train_attn = \\\n","                            evaluate(model, train_loader_proxy, src_id2token, targ_id2token, teacher_forcing_ratio=teacher_forcing_ratio) \n","                else: \n","                    result['train_loss'], result['train_bleu'] = 0, 0  \n","\n","                results.append(result)\n","\n","                print('Epoch: {:.2f}, Train Loss: {:.2f}, Val Loss: {:.2f}, Train BLEU: {:.2f}, Val BLEU: {:.2f}, Minutes Elapsed: {:.2f}'\\\n","                      .format(result['epoch'], result['train_loss'], result['val_loss'], \n","                              result['train_bleu'], result['val_bleu'], (time.time() - start_time) / 60 ))\n","                    \n","                if inspect_samples is not None: \n","                    # sample predictions from training set, if available \n","                    if not lazy_eval: \n","                        print(\"Sampling from training predictions...\")\n","                        sample_predictions(train_hyp_idxs, train_ref_idxs, train_source_idxs, train_hyp_tokens, train_ref_tokens, \n","                            train_source_tokens, targ_id2token, train_attn, print_attn=print_attn, num_samples=inspect_samples)\n","                    # sample predictions from validation set \n","                    print(\"Sampling from val predictions...\")\n","                    sample_predictions(val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens, \n","                        targ_id2token, val_attn, print_attn=print_attn, num_samples=inspect_samples)\n","                    \n","                if save_checkpoint: \n","                    if result['val_bleu'] == pd.DataFrame.from_dict(results)['val_bleu'].max(): \n","                        checkpoint_fp = '/content/drive/My Drive/ds1012/MT/model_checkpoints/{}.pth.tar'.format(model_name)\n","                        check_dir_exists(filename=checkpoint_fp)\n","                        torch.save(model.state_dict(), checkpoint_fp)\n"," \n","    runtime = (time.time() - start_time) / 60 \n","    dt_created = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    total_params, trainable_params = count_parameters(model)               \n","\n","    if save_to_log: \n","        append_to_log(params, results, runtime, experiment_name, model_name, dt_created, total_params, trainable_params)\n","\n","    print(\"Model training completed in {} minutes with {:.2f} best validation loss and {:.2f} best validation BLEU.\".format(\n","        int(runtime), pd.DataFrame.from_dict(results)['val_loss'].min(), \n","        pd.DataFrame.from_dict(results)['val_bleu'].max()))\n","\n","    return model, results  \n","\n","def sample_predictions(hyp_idxs, ref_idxs, source_idxs, hyp_tokens, ref_tokens, source_tokens, id2token, \n","    attn, print_attn, num_samples=1, ): \n","\n","    \"\"\" Sample a few source sentences, reference and model translations to review \"\"\" \n","\n","    for i in range(num_samples): \n","        rand = random.randint(0, len(hyp_idxs)-1) \n","        source = ' '.join(source_tokens[rand])\n","        print(\"Source: {}\".format(source))\n","        reference_translation = ' '.join(ref_tokens[rand]) \n","        print(\"Reference: {}\".format(reference_translation))\n","        model_translation = ' '.join(hyp_tokens[rand])\n","        print(\"Model: {}\".format(model_translation))\n","        if print_attn: \n","            print(\"Attention Weights: {}\".format(attn[rand]))\n","        print()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq-dDt3lc9Wi","colab_type":"code","colab":{}},"source":["def check_dir_exists(filename): \n","    \"\"\" Takes filename string and check whether its implied directory exists, otherwise creates it \"\"\" \n","\n","    if not os.path.exists(os.path.dirname(filename)):\n","        os.makedirs(os.path.dirname(filename))\n","    else: \n","        pass \n","        \n","\n","def append_to_log(hyperparams, results, runtime, experiment_name, model_name, dt_created, total_params, trainable_params, filename=RESULTS_LOG): \n","    \"\"\" Appends results and details of a single experiment to a log file \"\"\"\n","    \n","    # check directory exists, else creates it \n","    check_dir_exists(filename)\n","        \n","    # store experiment details in a dictionary \n","    new_result = {'experiment_name': experiment_name, 'model_name': model_name, 'hyperparams': hyperparams, \n","        'results': results, 'runtime': runtime, 'dt_created': dt_created, \n","        'total_params': total_params, 'trainable_params': trainable_params}\n","    \n","    # if log already exists, append to log \n","    try: \n","        results_log = pkl.load(open(filename, \"rb\"))\n","        results_log.append(new_result)\n","\n","    # if log doesn't exists, initialize first result as the log \n","    except (OSError, IOError) as e:\n","        results_log = [new_result]\n","    \n","    # save to pickle \n","    pkl.dump(results_log, open(filename, \"wb\")) \n","\n","\n","def load_experiment_log(experiment_name=None, model_name=None, filename=RESULTS_LOG): \n","    \"\"\" Loads experiment log, with option to filter for a specific experiment_name \"\"\"\n","    \n","    results_log = pkl.load(open(filename, \"rb\"))\n","    \n","    if experiment_name is not None: \n","        results_log = [r for r in results_log if r['experiment_name'] == experiment_name]\n","\n","    if model_name is not None: \n","        results_log = [r for r in results_log if r['model_name'] == model_name]\n","\n","    # sort by dt_created \n","    results_log = sorted(results_log, key=lambda k: k['dt_created'], reverse=True)\n","        \n","    return results_log\n","\n","\n","def summarize_results(results_log): \n","    \"\"\" Summarizes results_log (list) into a dataframe, splitting hyperparameters string into columns, and reducing \n","        the val_acc dict into the best validation accuracy obtained amongst all the epochs logged \"\"\"\n","    results_df = pd.DataFrame.from_dict(results_log)\n","    results_df = pd.concat([results_df, results_df['hyperparams'].apply(pd.Series)], axis=1)\n","    results_df = results_df.loc[:, ~results_df.columns.duplicated()] # unfortunately saved model_name and experiment_name twice \n","    results_df['best_val_loss'] = results_df['results'].apply(lambda d: pd.DataFrame.from_dict(d)['val_loss'].min())\n","    results_df['best_val_bleu'] = results_df['results'].apply(lambda d: pd.DataFrame.from_dict(d)['val_bleu'].max())\n","    return results_df.sort_values(by='dt_created', ascending=False) \n","\n","\n","def count_parameters(model): \n","    \"\"\" Returns total and trainable parameters of a given model \"\"\" \n","    all_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    return all_params, trainable_params"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hv61C_BjRe37","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'cz'\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000\n","# model architecture params \n","NETWORK_TYPE = 'rnn'\n","RNN_CELL_TYPE = 'gru'\n","NUM_LAYERS = 2 \n","ENC_HIDDEN_DIM = 512\n","DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n","TEACHER_FORCING_RATIO = 1\n","CLIP_GRAD_MAX_NORM = 1\n","ENC_DROPOUT = 0 \n","DEC_DROPOUT = 0  \n","ATTENTION_TYPE = 'without'\n","\n","# training params  \n","NUM_EPOCHS = 5\n","LR = 0.00015 \n","OPTIMIZER = 'Adam'\n","LAZY_TRAIN = False\n","\n","# name the model and experiment \n","if NETWORK_TYPE == 'rnn': \n","    EXPERIMENT_NAME = '{}-{}-rnn-{}-attn'.format(SRC_LANG, TARG_LANG, ATTENTION_TYPE)\n","elif NETWORK_TYPE == 'cnn': \n","    EXPERIMENT_NAME = '{}-cnn'.format(SRC_LANG)\n","MODEL_NAME = '{}-{}'.format(EXPERIMENT_NAME, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1nv-1_ZgsDZ","colab_type":"code","colab":{}},"source":["# store as dict to save to results later \n","params = {'experiment_name': EXPERIMENT_NAME,'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n","          'rnn_cell_type': RNN_CELL_TYPE, 'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, \n","          'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, 'src_vocab_size': SRC_VOCAB_SIZE, \n","          'targ_vocab_size': TARG_VOCAB_SIZE, 'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, \n","          'dec_hidden_dim': DEC_HIDDEN_DIM, 'teacher_forcing_ratio': TEACHER_FORCING_RATIO, \n","          'clip_grad_max_norm': CLIP_GRAD_MAX_NORM, 'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n","          'attention_type': ATTENTION_TYPE, 'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, \n","          'learning_rate': LR, 'optimizer': OPTIMIZER, 'lazy_train': LAZY_TRAIN}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"drHV_zknIXxk","colab_type":"code","outputId":"466abd51-e8ce-4943-9bab-2bed82732b57","executionInfo":{"status":"ok","timestamp":1589497712418,"user_tz":240,"elapsed":350,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(vocab['cz']['id2token'])"],"execution_count":191,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000"]},"metadata":{"tags":[]},"execution_count":191}]},{"cell_type":"code","metadata":{"id":"9X5tqYQmjp_8","colab_type":"code","colab":{}},"source":["encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, src_vocab_size = SRC_VOCAB_SIZE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n","                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT)\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kq4PLDErkTGz","colab_type":"code","outputId":"9c98e202-dd88-4a5c-e106-3f8331673b28","executionInfo":{"status":"ok","timestamp":1589492446368,"user_tz":240,"elapsed":9986451,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model, results = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=True, save_to_log=True, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 9.15, Train BLEU: 0.00, Val BLEU: 7.67, Minutes Elapsed: 1.25\n","Sampling from val predictions...\n","Source: I also noted in the discussion that the forthcoming Single\n","Reference: Během diskuse jsem si také <UNK> , že by\n","Model: <SOS> počátkem , , , , , , , ,\n","\n","Source: Thirdly , our most controversial discussions concerned the <UNK> .\n","Reference: Za třetí , <UNK> diskuse mezi námi se týkaly\n","Model: <SOS> profesní <UNK> , , , , , , ,\n","\n","Source: We therefore must not treat this as run - of\n","Reference: Proto nesmíme tuto záležitost brát jako <UNK> agendu ,\n","Model: <SOS> , , , , , , podobě podobě Jemenu\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.07, Train Loss: 0.00, Val Loss: 5.52, Train BLEU: 0.00, Val BLEU: 9.09, Minutes Elapsed: 3.55\n","Sampling from val predictions...\n","Source: However , it is important to explain that the monetary\n","Reference: Nicméně je důležité vysvětlit , že měnová unie je\n","Model: <SOS> <UNK> je však , , , je <UNK> <UNK>\n","\n","Source: <UNK> alone will not drive us to succeed . <EOS>\n","Reference: <UNK> slova nás k úspěchu <UNK> . <EOS> <PAD>\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> . <EOS> <EOS>\n","\n","Source: On the instrument for stability , the Commission proposed to\n","Reference: Na základě rozhodnutí Soudního dvora z roku 2008 Komise\n","Model: <SOS> Na Komise Komise Komise Komise <UNK> <UNK> , ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.14, Train Loss: 0.00, Val Loss: 5.14, Train BLEU: 0.00, Val BLEU: 11.24, Minutes Elapsed: 5.83\n","Sampling from val predictions...\n","Source: This report , presented today , is indeed to be\n","Reference: Na zprávu , která dnes byla <UNK> , skutečně\n","Model: <SOS> Tato zpráva zpráva je je je je je ,\n","\n","Source: on behalf of the EFD Group . - Mr Barroso\n","Reference: jménem skupiny EFD . - Pane Barroso , nedávno\n","Model: <SOS> jménem skupiny Verts . - Pane předsedající , <UNK>\n","\n","Source: So the security of Europe is directly connected to the\n","Reference: To znamená , že bezpečnost v Evropě přímo souvisí\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.21, Train Loss: 0.00, Val Loss: 4.89, Train BLEU: 0.00, Val BLEU: 12.53, Minutes Elapsed: 8.12\n","Sampling from val predictions...\n","Source: I agree with the resolution ' s call for the\n","Reference: Souhlasím s výzvou vůči členským státům a regionům ,\n","Model: <SOS> Souhlasím s s <UNK> , , , , ,\n","\n","Source: This is a cornerstone of democracy . <EOS> <PAD> <PAD>\n","Reference: Právě takovýto postoj je základem demokracie . <EOS> <PAD>\n","Model: <SOS> To je je <UNK> . . <EOS> <EOS> <EOS>\n","\n","Source: I want to pick out one : ' I am\n","Reference: Chtěl bych jeden vybrat : \" Nejsem si jist\n","Model: <SOS> Chci bych <UNK> : : : <UNK> <UNK> :\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.28, Train Loss: 0.00, Val Loss: 4.72, Train BLEU: 0.00, Val BLEU: 13.12, Minutes Elapsed: 10.40\n","Sampling from val predictions...\n","Source: Member of the Commission . - Mr President , I\n","Reference: členka Komise . - Vážený pane předsedající , velmi\n","Model: <SOS> člen Komise . - Pane předsedající předsedající , chtěl\n","\n","Source: On the basis of these premises , I voted for\n","Reference: Na základě toho jsem hlasovala pro jmenování portugalského kandidáta\n","Model: <SOS> Na jde straně jsem jsem pro pro zprávu ,\n","\n","Source: <UNK> , particular attention has been paid to ensuring complementarity\n","Reference: <UNK> byla pozornost věnována zejména doplnění a <UNK> posílení\n","Model: <SOS> <UNK> <UNK> je <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.36, Train Loss: 0.00, Val Loss: 4.57, Train BLEU: 0.00, Val BLEU: 13.48, Minutes Elapsed: 12.68\n","Sampling from val predictions...\n","Source: With these keys , they can open the door to\n","Reference: <UNK> <UNK> mohou otevřít dveře na otevřený trh ,\n","Model: <SOS> S jde <UNK> <UNK> <UNK> , , , <UNK>\n","\n","Source: We need to give a positive answer to that question\n","Reference: Musíme na tyto otázky odpovídat kladně , což ne\n","Model: <SOS> Musíme třeba <UNK> , , , , , se\n","\n","Source: I agree that the position on delegated acts must be\n","Reference: Souhlasím s tím , že postoj ohledně aktů v\n","Model: <SOS> Souhlasím , že , že je musí být být\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.43, Train Loss: 0.00, Val Loss: 4.46, Train BLEU: 0.00, Val BLEU: 13.64, Minutes Elapsed: 14.98\n","Sampling from val predictions...\n","Source: Agreement between the EC and <UNK> <UNK> and <UNK> on\n","Reference: Dohoda mezi Evropským společenstvím a <UNK> <UNK> <UNK> a\n","Model: <SOS> <UNK> <UNK> <UNK> a a a <UNK> <UNK> <UNK>\n","\n","Source: We are facing the same situation with the topics we\n","Reference: Pokud jde o témata , jimiž se zde zabýváme\n","Model: <SOS> <UNK> se o <UNK> , , jsme s s\n","\n","Source: According to the Commission , requests for data can only\n","Reference: Podle Komise se požadavky na údaje mohou vztahovat pouze\n","Model: <SOS> Podle Komise Komise <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.50, Train Loss: 0.00, Val Loss: 4.36, Train BLEU: 0.00, Val BLEU: 14.90, Minutes Elapsed: 17.27\n","Sampling from val predictions...\n","Source: The developing countries are now suffering a <UNK> blow .\n","Reference: <UNK> země v současnosti trpí v <UNK> ohledu .\n","Model: <SOS> <UNK> země jsou nyní <UNK> <UNK> <UNK> . <EOS>\n","\n","Source: They must match people ' s mentality and expectations .\n","Reference: Tyto instituce musí odpovídat <UNK> a očekávání lidí .\n","Model: <SOS> Musí musí musí <UNK> <UNK> a a . .\n","\n","Source: That is why , ladies and gentlemen , we are\n","Reference: Proto , dámy a pánové , budeme hlasovat proti\n","Model: <SOS> Proto , dámy a pánové , <UNK> jsme <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.57, Train Loss: 0.00, Val Loss: 4.27, Train BLEU: 0.00, Val BLEU: 15.28, Minutes Elapsed: 19.54\n","Sampling from val predictions...\n","Source: We cannot just consider an average situation in the region\n","Reference: Nemůžeme jednoduše vzít v úvahu <UNK> situaci v určitém\n","Model: <SOS> Nemůžeme si <UNK> v v <UNK> kdy , kdy\n","\n","Source: Lastly , it proposes a number of vital measures to\n","Reference: A konečně navrhuje přijetí řady velmi důležitých opatření v\n","Model: <SOS> A konečně , <UNK> opatření opatření opatření , ,\n","\n","Source: As for us , we want decisions . <EOS> <PAD>\n","Reference: Pokud jde o nás , my žádáme rozhodnutí .\n","Model: <SOS> Co jsme o <UNK> , . se . <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.64, Train Loss: 0.00, Val Loss: 4.19, Train BLEU: 0.00, Val BLEU: 15.32, Minutes Elapsed: 21.85\n","Sampling from val predictions...\n","Source: We understand that we do not have a clear framework\n","Reference: <UNK> , že nemáme jasný rámec , pokud jde\n","Model: <SOS> <UNK> , že jsme <UNK> <UNK> <UNK> , <UNK>\n","\n","Source: Thirdly , that all the conditions laid down in No\n","Reference: Za třetí je nutné , aby před tím ,\n","Model: <SOS> Za třetí , všechny , aby <UNK> v <UNK>\n","\n","Source: Mr President , Commissioner , ladies and gentlemen , a\n","Reference: Vážený pane předsedající , vážená paní komisařko , dámy\n","Model: <SOS> Pane předsedající předsedající , pane komisaři komisaři , dámy\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.71, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 15.86, Minutes Elapsed: 24.13\n","Sampling from val predictions...\n","Source: in writing . - ( PT ) I voted against\n","Reference: Hlasoval jsem proti udělení obchodních preferencí Pákistánu prostřednictvím výjimky\n","Model: <SOS> písemně . proti proti zprávě <UNK> <UNK> <UNK> .\n","\n","Source: For this reason , Parliament must fight for human rights\n","Reference: Z tohoto důvodu musí Parlament bojovat za lidská práva\n","Model: <SOS> Z tohoto důvodu musí musí <UNK> práva lidských práva\n","\n","Source: ( Parliament rejected the motion ) <EOS> <PAD> <PAD> <PAD>\n","Reference: ( Parlament návrh <UNK> ) <EOS> <PAD> <PAD> <PAD>\n","Model: <SOS> ( Parlament Parlament návrh ) ) <EOS> <EOS> <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.78, Train Loss: 0.00, Val Loss: 4.06, Train BLEU: 0.00, Val BLEU: 16.45, Minutes Elapsed: 26.42\n","Sampling from val predictions...\n","Source: They call on us to choose growth . <EOS> <PAD>\n","Reference: <UNK> nás , abychom si zvolili růst . <EOS>\n","Model: <SOS> <UNK> na na . se <UNK> . . <EOS>\n","\n","Source: in writing . - Although UKIP makes the point on\n","Reference: písemně . - ( <UNK> ) Přestože se Strana\n","Model: <SOS> písemně . - <UNK> se ) <UNK> o o\n","\n","Source: Fortunately , however , Spain does recognise it . <EOS>\n","Reference: Naštěstí ale Španělsko příkaz uznává . <EOS> <PAD> <PAD>\n","Model: <SOS> <UNK> však však <UNK> <UNK> . <EOS> . <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.85, Train Loss: 0.00, Val Loss: 4.00, Train BLEU: 0.00, Val BLEU: 16.89, Minutes Elapsed: 28.68\n","Sampling from val predictions...\n","Source: In fact , Article 290 refers precisely to this matter\n","Reference: Vlastně se této otázky týká právě článek <UNK> .\n","Model: <SOS> V skutečnosti <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> ,\n","\n","Source: Effective combating of tax evasion and fraud has a significant\n","Reference: <UNK> boj proti daňovým únikům a podvodům má významné\n","Model: <SOS> <UNK> <UNK> a a a a a <UNK> je\n","\n","Source: Lisbon and its <UNK> insist on supporting the Union '\n","Reference: <UNK> a jeho <UNK> <UNK> na podpoře <UNK> EU\n","Model: <SOS> <UNK> a <UNK> <UNK> na na Evropské Evropské unie\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0.93, Train Loss: 0.00, Val Loss: 3.94, Train BLEU: 0.00, Val BLEU: 16.79, Minutes Elapsed: 30.98\n","Sampling from val predictions...\n","Source: Pakistan is a very difficult and crucial foreign - policy\n","Reference: Pákistán je předmětem velmi složité a zásadní zahraniční politiky\n","Model: <SOS> <UNK> je velmi a a a a politiku .\n","\n","Source: I believe that achieving this transatlantic marketplace , for example\n","Reference: Věřím , že například vytvoření tohoto <UNK> trhu je\n","Model: <SOS> Domnívám se že tento <UNK> <UNK> <UNK> , ,\n","\n","Source: Clearly , there cannot be any democratic debate in a\n","Reference: Je jasné , že v atmosféře strachu a zastrašování\n","Model: <SOS> Samozřejmě , , že v existovat případě <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.90, Train BLEU: 0.00, Val BLEU: 17.44, Minutes Elapsed: 33.25\n","Sampling from val predictions...\n","Source: This is logical , but needs greater flexibility . <EOS>\n","Reference: To je logické , potřebuje to ale větší pružnost\n","Model: <SOS> To je , , , potřebuje . . .\n","\n","Source: Here it is important to point out that this directive\n","Reference: Zde je důležité poukázat na to , že tato\n","Model: <SOS> Zde je zdůraznit zdůraznit , to , že tato\n","\n","Source: <UNK> <UNK> <UNK> <UNK> ! <EOS> <PAD> <PAD> <PAD> <PAD>\n","Reference: <UNK> <UNK> <UNK> <UNK> ! <EOS> <PAD> <PAD> <PAD>\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> ! ! <EOS> !\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.89, Train BLEU: 0.00, Val BLEU: 17.19, Minutes Elapsed: 34.52\n","Sampling from val predictions...\n","Source: We also believe that it is very important to improve\n","Reference: Jsme také přesvědčeni , že je velice důležité zlepšit\n","Model: <SOS> Domníváme se také , že je důležité důležité ,\n","\n","Source: According to Article 41 of the Charter of Fundamental Rights\n","Reference: Článek 41 Listiny základních práv Evropské unie stanoví ,\n","Model: <SOS> Podle článku <UNK> <UNK> práv práv <UNK> pro <UNK>\n","\n","Source: ( RO ) Madam President , first of all ,\n","Reference: ( RO ) Paní předsedající , nejprve ze všeho\n","Model: <SOS> ( RO ) Paní předsedající , především bych chtěl\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.07, Train Loss: 0.00, Val Loss: 3.85, Train BLEU: 0.00, Val BLEU: 17.72, Minutes Elapsed: 36.77\n","Sampling from val predictions...\n","Source: 4 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: 4 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> 4 . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n","\n","Source: This must be complemented by exchanges among experts . <EOS>\n","Reference: To musí být <UNK> výměnou informací mezi odborníky .\n","Model: <SOS> To musí být <UNK> <UNK> <UNK> . <EOS> .\n","\n","Source: Let us show our support not with a minute '\n","Reference: <UNK> svou solidaritu nikoli <UNK> <UNK> , ale <UNK>\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <EOS> <EOS> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.14, Train Loss: 0.00, Val Loss: 3.81, Train BLEU: 0.00, Val BLEU: 17.79, Minutes Elapsed: 39.05\n","Sampling from val predictions...\n","Source: So do not have just one <UNK> on your <UNK>\n","Reference: <UNK> tedy jednat <UNK> : <UNK> jednat <UNK> .\n","Model: <SOS> Takže <UNK> jen <UNK> <UNK> <UNK> <UNK> <EOS> <EOS>\n","\n","Source: The rights of workers to information , which they quite\n","Reference: <UNK> <UNK> práva pracovníků na informace nejsou účinná a\n","Model: <SOS> <UNK> <UNK> , , které které , které <UNK>\n","\n","Source: I hope the Irish voters will decide in favour of\n","Reference: Doufám , že <UNK> voliči se rozhodnou podpořit Evropskou\n","Model: <SOS> Doufám , že <UNK> <UNK> bude bude podaří <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.21, Train Loss: 0.00, Val Loss: 3.77, Train BLEU: 0.00, Val BLEU: 18.12, Minutes Elapsed: 41.32\n","Sampling from val predictions...\n","Source: Madam President , many states in other parts of the\n","Reference: Paní předsedající , mnoho států v jiných částech světa\n","Model: <SOS> Paní předsedající , v mnoha v v <UNK> <UNK>\n","\n","Source: For the first time , both parties have also agreed\n","Reference: Poprvé se také obě strany dohodly na zajištění sociálních\n","Model: <SOS> Poprvé , také i , <UNK> <UNK> <UNK> <UNK>\n","\n","Source: The European Union wishes to provide the affected population with\n","Reference: Evropská unie hodlá <UNK> obyvatelstvu poskytnout pomoc . <EOS>\n","Model: <SOS> Evropská unie banka <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.28, Train Loss: 0.00, Val Loss: 3.74, Train BLEU: 0.00, Val BLEU: 18.35, Minutes Elapsed: 43.58\n","Sampling from val predictions...\n","Source: There is no business in any sector that can survive\n","Reference: Neexistuje žádný druh podnikání v žádném odvětví , který\n","Model: <SOS> V žádná v , , které , , ,\n","\n","Source: The monetary instrument in question would serve primarily to help\n","Reference: Takový <UNK> nástroj by <UNK> především na podporu zlepšování\n","Model: <SOS> <UNK> <UNK> <UNK> by by mohlo k , ,\n","\n","Source: For seven years , the Swedish citizen <UNK> <UNK> has\n","Reference: <UNK> občan <UNK> <UNK> je již sedm let <UNK>\n","Model: <SOS> <UNK> let <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.36, Train Loss: 0.00, Val Loss: 3.70, Train BLEU: 0.00, Val BLEU: 18.41, Minutes Elapsed: 45.86\n","Sampling from val predictions...\n","Source: It is a waste in terms of our competitiveness when\n","Reference: Je to <UNK> , které se dotýká naší konkurenceschopnosti\n","Model: <SOS> Je to <UNK> našich našich jde naše našich našich\n","\n","Source: Nevertheless , the overall result is positive , and I\n","Reference: Nicméně všeobecný výsledek je pozitivní a já si myslím\n","Model: <SOS> <UNK> je je pozitivní a a a jsem <UNK>\n","\n","Source: So let us teach our children in schools , churches\n","Reference: <UNK> učit děti ve školách , v <UNK> ,\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> , , a ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.43, Train Loss: 0.00, Val Loss: 3.67, Train BLEU: 0.00, Val BLEU: 18.40, Minutes Elapsed: 48.14\n","Sampling from val predictions...\n","Source: This will allow us to come up with specific answers\n","Reference: To nám umožní veřejnosti konkrétně odpovědět a co nejlépe\n","Model: <SOS> To nám umožní <UNK> <UNK> <UNK> <UNK> , se\n","\n","Source: In the Middle <UNK> , however , they respected Sunday\n","Reference: Ve <UNK> však <UNK> , že se v <UNK>\n","Model: <SOS> V <UNK> <UNK> však <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: We are still prepared to work closely with the United\n","Reference: Stále jsme připraveni na úzkou spolupráci s USA ,\n","Model: <SOS> Jsme jsme připraveni spolupracovat s s s Radou <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.50, Train Loss: 0.00, Val Loss: 3.64, Train BLEU: 0.00, Val BLEU: 18.93, Minutes Elapsed: 50.38\n","Sampling from val predictions...\n","Source: ( FR ) Mr President , I would like to\n","Reference: ( FR ) Pane předsedající , chtěla bych poblahopřát\n","Model: <SOS> ( FR ) Pane předsedající , ráda bych poděkovat\n","\n","Source: Poland is a country in which 96 % of electric\n","Reference: Polsko je zemí , v níž je 96 %\n","Model: <SOS> Polsko je země , která se je <UNK> %\n","\n","Source: If we do not invest in sectors such as energy\n","Reference: <UNK> - li investovat do odvětví , jako je\n","Model: <SOS> Pokud - li v v v , jako jsou\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.57, Train Loss: 0.00, Val Loss: 3.62, Train BLEU: 0.00, Val BLEU: 19.33, Minutes Elapsed: 52.66\n","Sampling from val predictions...\n","Source: Madam President , I have chosen almost the same introduction\n","Reference: jménem skupiny Verts / ALE . - ( DE\n","Model: <SOS> Paní předsedající PSE / ALE . - ( PL\n","\n","Source: Consequently Poland is particularly interested in new technologies for coal\n","Reference: V důsledku toho se Polsko mimořádně zajímá o nové\n","Model: <SOS> V je je je i <UNK> že nových nových\n","\n","Source: The thing is , however , that you then have\n","Reference: V tom případě je však třeba <UNK> , jakým\n","Model: <SOS> Je však případě však však , , , že\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.64, Train Loss: 0.00, Val Loss: 3.60, Train BLEU: 0.00, Val BLEU: 19.34, Minutes Elapsed: 54.94\n","Sampling from val predictions...\n","Source: A strategy is in force in Romania , which dates\n","Reference: V Rumunsku platí strategie , která pochází z doby\n","Model: <SOS> Strategie strategie je v v , je v ,\n","\n","Source: I believe that the EU has an extremely important role\n","Reference: Domnívám se , že zde je velice důležitým úkolem\n","Model: <SOS> Domnívám se , že EU EU EU EU EU\n","\n","Source: - Deprez report <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: - <UNK> : <UNK> <EOS> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> - <UNK> zpráva <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.71, Train Loss: 0.00, Val Loss: 3.57, Train BLEU: 0.00, Val BLEU: 19.52, Minutes Elapsed: 57.22\n","Sampling from val predictions...\n","Source: This sum must be allocated as a matter of priority\n","Reference: Tato částka musí být <UNK> <UNK> těm projektům ,\n","Model: <SOS> Tato této musí být <UNK> na <UNK> <UNK> <EOS>\n","\n","Source: These <UNK> from international and domestic legal norms make transatlantic\n","Reference: Toto <UNK> mezinárodních i domácích právních norem činí projekty\n","Model: <SOS> Tyto <UNK> <UNK> <UNK> a <UNK> <UNK> a <UNK>\n","\n","Source: This morning we held a vote here to justify negotiations\n","Reference: Dnes ráno jsme zde hlasovali o <UNK> vyjednávání ,\n","Model: <SOS> Dnes jsme jsme se rozhodli o o dohodě ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.78, Train Loss: 0.00, Val Loss: 3.56, Train BLEU: 0.00, Val BLEU: 19.37, Minutes Elapsed: 59.47\n","Sampling from val predictions...\n","Source: Even those suspected of committing serious offences have the right\n","Reference: I ti , kteří jsou <UNK> ze <UNK> závažných\n","Model: <SOS> Dokonce když <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: I myself went to Albania to present the first biometric\n","Reference: <UNK> jsem <UNK> do Albánie , abych představil první\n","Model: <SOS> <UNK> jsem se <UNK> aby , <UNK> jsem <UNK>\n","\n","Source: 2 . <UNK> the importance of the euro for the\n","Reference: 2 . poukazuje na význam eura z hlediska evropského\n","Model: <SOS> 2 . <UNK> <UNK> pro <UNK> pro <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.85, Train Loss: 0.00, Val Loss: 3.53, Train BLEU: 0.00, Val BLEU: 19.94, Minutes Elapsed: 61.73\n","Sampling from val predictions...\n","Source: The report will , if appropriate , be accompanied by\n","Reference: Pokud to bude vhodné , zprávu <UNK> návrhy právních\n","Model: <SOS> Zpráva bude bude , , <UNK> <UNK> <UNK> a\n","\n","Source: It should not be inconceivable . <EOS> <PAD> <PAD> <PAD>\n","Reference: To by nemělo být <UNK> . <EOS> <PAD> <PAD>\n","Model: <SOS> Nemělo by nemělo nemělo . . <EOS> . <EOS>\n","\n","Source: As group coordinator on the Lisbon Strategy I would emphasise\n","Reference: Jako <UNK> skupiny pro <UNK> strategii bych ráda zdůraznila\n","Model: <SOS> Jak již <UNK> strategie strategie strategie bych rád zdůraznit\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1.93, Train Loss: 0.00, Val Loss: 3.51, Train BLEU: 0.00, Val BLEU: 19.84, Minutes Elapsed: 64.00\n","Sampling from val predictions...\n","Source: I returned just last Sunday from an official mission to\n","Reference: Právě <UNK> <UNK> jsem se vrátila z oficiální návštěvy\n","Model: <SOS> <UNK> jsem jsem <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: I would also add that I have been surprised by\n","Reference: Také bych chtěl dodat , že jsem byl <UNK>\n","Model: <SOS> Chtěl bych dodal dodal , že jsem <UNK> <UNK>\n","\n","Source: There will be no ' eve of the revolution '\n","Reference: V Londýně dne 2 . dubna nedojde k žádnému\n","Model: <SOS> <UNK> <UNK> unii <UNK> . <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.50, Train BLEU: 0.00, Val BLEU: 20.24, Minutes Elapsed: 66.24\n","Sampling from val predictions...\n","Source: <UNK> and judges learn a great deal in their training\n","Reference: <UNK> a <UNK> se v rámci svého odborného vzdělávání\n","Model: <SOS> <UNK> a <UNK> <UNK> <UNK> v <UNK> <UNK> <UNK>\n","\n","Source: That brings me to the issue of , let us\n","Reference: Tím se dostávám k otázce , řekněme , právního\n","Model: <SOS> Tím se dostávám k otázce otázce , <UNK> <UNK>\n","\n","Source: The latter is rightly excluded from the moratorium , as\n","Reference: Na rozdíl od lovu <UNK> pro vědecké účely se\n","Model: <SOS> Tato je se <UNK> se <UNK> <UNK> , ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.50, Train BLEU: 0.00, Val BLEU: 20.28, Minutes Elapsed: 67.52\n","Sampling from val predictions...\n","Source: We now face a choice between demographic collapse or importing\n","Reference: Nyní máme na výběr mezi <UNK> <UNK> nebo <UNK>\n","Model: <SOS> Nyní jsme <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: Mr President , just as the previous speakers have also\n","Reference: Pane předsedající , stejně jako předchozí řečníci , i\n","Model: <SOS> Pane předsedající , stejně jako i řečníci také také\n","\n","Source: Today ' s debate takes place on the anniversary of\n","Reference: Dnešní rozprava se <UNK> v den výročí <UNK> <UNK>\n","Model: <SOS> Dnešní rozprava se <UNK> 19 výročí 19 výročí výročí\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.07, Train Loss: 0.00, Val Loss: 3.48, Train BLEU: 0.00, Val BLEU: 20.32, Minutes Elapsed: 69.79\n","Sampling from val predictions...\n","Source: Madam President , my congratulations to Mrs Oomen - Ruijten\n","Reference: Paní předsedající , blahopřeji paní Oomen - <UNK> k\n","Model: <SOS> Paní předsedající , blahopřeji bych paní - <UNK> k\n","\n","Source: The comments from these countries - including from people who\n","Reference: <UNK> z těchto zemí , včetně lidí , kteří\n","Model: <SOS> <UNK> z z zemí zemí včetně <UNK> , kteří\n","\n","Source: Rules protecting workers will serve little purpose if there is\n","Reference: Pravidla , která chrání pracující , budou k <UNK>\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> se li\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.14, Train Loss: 0.00, Val Loss: 3.47, Train BLEU: 0.00, Val BLEU: 20.42, Minutes Elapsed: 72.06\n","Sampling from val predictions...\n","Source: Hence , as far as energy is concerned , we\n","Reference: Proto potřebujeme , pokud jde o energii , nalézt\n","Model: <SOS> Proto pokud pokud <UNK> jde o <UNK> , ,\n","\n","Source: These are two sectors which have massive potential in terms\n","Reference: V těchto dvou odvětvích je obrovský potenciál , co\n","Model: <SOS> To jsou oblasti jsou jsou ženy <UNK> , které\n","\n","Source: in writing . - Members of this House will be\n","Reference: písemně . - <UNK> této sněmovny si jistě <UNK>\n","Model: <SOS> písemně . - Poslanci poslanci tohoto bude <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.21, Train Loss: 0.00, Val Loss: 3.45, Train BLEU: 0.00, Val BLEU: 20.85, Minutes Elapsed: 74.31\n","Sampling from val predictions...\n","Source: <UNK> the measures proposed for combating animal diseases or funding\n","Reference: <UNK> opatření <UNK> pro boj s <UNK> zvířat ,\n","Model: <SOS> <UNK> opatření opatření opatření <UNK> proti podvodům <UNK> <UNK>\n","\n","Source: They are exposed to all manner of hardship and acts\n","Reference: Jsou vystaveni <UNK> utrpení a násilí , přičemž ženy\n","Model: <SOS> Jsou <UNK> <UNK> všech všech a <UNK> <UNK> jsou\n","\n","Source: And finally , allow me to congratulate Mr Coelho who\n","Reference: Na závěr mi dovolte , abych poblahopřála panu <UNK>\n","Model: <SOS> A konečně mi dovolte poblahopřát panu poblahopřál panu <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.28, Train Loss: 0.00, Val Loss: 3.44, Train BLEU: 0.00, Val BLEU: 20.75, Minutes Elapsed: 76.58\n","Sampling from val predictions...\n","Source: Mr President , <UNK> of terrorism takes many forms ,\n","Reference: Pane předsedo , <UNK> terorismu může mít mnoho <UNK>\n","Model: <SOS> Pane předsedající , <UNK> <UNK> <UNK> mnoho mnoha mnoha\n","\n","Source: We have to be pragmatic and realistic and pursue a\n","Reference: Musíme být <UNK> a <UNK> a sledovat politiku <UNK>\n","Model: <SOS> Musíme být <UNK> a <UNK> a a <UNK> <UNK>\n","\n","Source: So I think this is an important report on all\n","Reference: Myslím si tedy , že jde ve všech směrech\n","Model: <SOS> Myslím se tedy , že je zpráva důležitou zprávy\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.36, Train Loss: 0.00, Val Loss: 3.43, Train BLEU: 0.00, Val BLEU: 20.70, Minutes Elapsed: 78.84\n","Sampling from val predictions...\n","Source: If the safety of the products placed on the market\n","Reference: Pokud je pro nás pro všechny prioritou bezpečnost výrobků\n","Model: <SOS> Pokud - trh trh trh trh trh trh trh\n","\n","Source: It has now become difficult for food manufacturers and distributors\n","Reference: Pro výrobce a <UNK> potravin je nyní obtížné mít\n","Model: <SOS> <UNK> se je je se je <UNK> <UNK> <UNK>\n","\n","Source: Colleagues , during Question <UNK> with President Barroso , please\n","Reference: Kolegové , <UNK> prosím v průběhu hodiny <UNK> pro\n","Model: <SOS> Kolegové , <UNK> <UNK> <UNK> <UNK> s <UNK> ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.43, Train Loss: 0.00, Val Loss: 3.42, Train BLEU: 0.00, Val BLEU: 20.47, Minutes Elapsed: 81.08\n","Sampling from val predictions...\n","Source: Commissioner , the sector urgently needs this plan if it\n","Reference: Paní komisařko , toto odvětví tento plán naléhavě potřebuje\n","Model: <SOS> Pane komisaři , tento tento potřebuje , potřebuje ,\n","\n","Source: Some of us can be glad that the Internet did\n","Reference: Někteří z nás mohou být rádi , že internet\n","Model: <SOS> Někteří z nás <UNK> <UNK> , , že <UNK>\n","\n","Source: I find it extremely important that high priority is given\n","Reference: Považuji za mimořádně důležité , aby byla otázkám ochrany\n","Model: <SOS> Považuji za nesmírně důležité , aby <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.50, Train Loss: 0.00, Val Loss: 3.41, Train BLEU: 0.00, Val BLEU: 20.93, Minutes Elapsed: 83.34\n","Sampling from val predictions...\n","Source: Given the continuous rise in freight transport , the catastrophic\n","Reference: <UNK> <UNK> <UNK> v <UNK> <UNK> a podobné nehody\n","Model: <SOS> Vzhledem k <UNK> <UNK> dopravy dopravy dopravy <UNK> <UNK>\n","\n","Source: <UNK> could cover everything from visa facilitation , under certain\n","Reference: <UNK> by mohlo zahrnovat vše od usnadnění získávání víz\n","Model: <SOS> <UNK> by mohlo mohlo <UNK> <UNK> co , <UNK>\n","\n","Source: Will the Commission then take them seriously ? <EOS> <PAD>\n","Reference: Bude je Komise brát vážně ? <EOS> <PAD> <PAD>\n","Model: <SOS> <UNK> Komise Komise Komise ? ? <EOS> <EOS> <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.57, Train Loss: 0.00, Val Loss: 3.40, Train BLEU: 0.00, Val BLEU: 21.27, Minutes Elapsed: 85.61\n","Sampling from val predictions...\n","Source: In this respect , in the strategy for equality between\n","Reference: V tomto ohledu Komise uvedla v rámci strategie pro\n","Model: <SOS> V tomto ohledu je zásadní pro mezi mezi mezi\n","\n","Source: It also seems that we need to standardise the different\n","Reference: Zdá se také , že je třeba , abychom\n","Model: <SOS> Zdá se , , že musíme třeba <UNK> abychom\n","\n","Source: Signature of acts adopted under the ordinary legislative procedure :\n","Reference: <UNK> aktů přijatých řádným legislativním postupem : viz zápis\n","Model: <SOS> <UNK> aktů přijatých řádným legislativním postupem : viz zápis\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.64, Train Loss: 0.00, Val Loss: 3.39, Train BLEU: 0.00, Val BLEU: 21.22, Minutes Elapsed: 87.88\n","Sampling from val predictions...\n","Source: I think that we have achieved a great deal .\n","Reference: Domnívám se , že jsme <UNK> dosáhli . <EOS>\n","Model: <SOS> Myslím , , že jsme dosáhli dosáhli . .\n","\n","Source: Madam President , Commissioner , ladies and gentlemen , as\n","Reference: úřadující předseda Rady . - ( FR ) Paní\n","Model: <SOS> Paní předsedající Rady . - ( DE ) Paní\n","\n","Source: It is of course important that there is a clear\n","Reference: Je samozřejmě důležité , aby <UNK> jasné propojení mezi\n","Model: <SOS> Je je důležité , aby v jasná , že\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.71, Train Loss: 0.00, Val Loss: 3.38, Train BLEU: 0.00, Val BLEU: 21.38, Minutes Elapsed: 90.14\n","Sampling from val predictions...\n","Source: President - in - Office of the Council . -\n","Reference: úřadující předsedkyně Rady . - Pane <UNK> , <UNK>\n","Model: <SOS> úřadující předsedkyně Rady . - ( HU , je\n","\n","Source: Mr President , I voted against the Svensson report .\n","Reference: Pane předsedající , hlasovala jsem proti zprávě paní <UNK>\n","Model: <SOS> Pane předsedající , hlasoval jsem proti zprávě paní <UNK>\n","\n","Source: I should also like to reply to one question in\n","Reference: Také bych chtěl odpovědět zejména na jednu otázku .\n","Model: <SOS> Ráda bych rád rád jednu jednu otázku , ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.78, Train Loss: 0.00, Val Loss: 3.38, Train BLEU: 0.00, Val BLEU: 21.00, Minutes Elapsed: 92.42\n","Sampling from val predictions...\n","Source: This important issue is the subject of our discussions today\n","Reference: Tato důležitá záležitost je předmětem naší dnešní rozpravy .\n","Model: <SOS> Tato tématem tématem tématem téma tématem diskusí , ,\n","\n","Source: I should like to emphasise that we have a sound\n","Reference: Rád bych zdůraznil , že zde máme dobrý kompromis\n","Model: <SOS> Rád bych zdůraznil , že máme <UNK> <UNK> <UNK>\n","\n","Source: Does she really , seriously believe that paying out this\n","Reference: Skutečně vážně věří , že <UNK> těchto finančních prostředků\n","Model: <SOS> Opravdu skutečně opravdu , že se <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.85, Train Loss: 0.00, Val Loss: 3.37, Train BLEU: 0.00, Val BLEU: 21.38, Minutes Elapsed: 94.69\n","Sampling from val predictions...\n","Source: I want to particularly mention the sheep and milk sectors\n","Reference: Chci zmínit zejména odvětví chovu ovcí a odvětví mléka\n","Model: <SOS> Chci bych zmínit <UNK> a a a <UNK> <UNK>\n","\n","Source: I think that their idea is an innovative and good\n","Reference: Považuji jejich nápad za inovativní a dobrý . <EOS>\n","Model: <SOS> Myslím se jejich <UNK> <UNK> a a <UNK> ,\n","\n","Source: Members asked for this debate so that they could discuss\n","Reference: Poslanci o tuto rozpravu požádali , aby mohli diskutovat\n","Model: <SOS> Poslanci poslanci tuto <UNK> <UNK> , , by <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2.93, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 21.32, Minutes Elapsed: 96.94\n","Sampling from val predictions...\n","Source: I am pleased that Commissioner Rehn has been <UNK> ,\n","Reference: Těší mě , že pan komisař Rehn byl znovu\n","Model: <SOS> Těší mě , že pan <UNK> byla <UNK> ,\n","\n","Source: On 11 March , at the summit held then ,\n","Reference: Na summitu <UNK> 11 . března hlavy států či\n","Model: <SOS> Dne 11 března března <UNK> března <UNK> <UNK> <UNK>\n","\n","Source: Mr President , I firstly want to thank the rapporteur\n","Reference: Pane předsedající , především chci poděkovat zpravodaji za jeho\n","Model: <SOS> Pane předsedající , chci bych poděkovat panu za <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 21.57, Minutes Elapsed: 99.20\n","Sampling from val predictions...\n","Source: We express our solidarity with the Palestinian people and call\n","Reference: <UNK> svou solidaritu s <UNK> lidmi a požadujeme okamžité\n","Model: <SOS> <UNK> naši solidaritu s lidu a a a ,\n","\n","Source: I should now like to move on to something new\n","Reference: Ráda bych nyní <UNK> k něčemu novému , co\n","Model: <SOS> Nyní bych se nyní k k , nové :\n","\n","Source: Most of the Roma who are legally crossing the borders\n","Reference: Většina Romů , kteří legálně <UNK> hranice v Evropě\n","Model: <SOS> Většina Romů , kteří <UNK> <UNK> , , ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 21.83, Minutes Elapsed: 100.49\n","Sampling from val predictions...\n","Source: New red tape has subsequently created additional difficulties in the\n","Reference: Nová byrokracie v návaznosti na to vytvořila další <UNK>\n","Model: <SOS> Nové další <UNK> další <UNK> další další další další\n","\n","Source: The reason for such behaviour lies with the fact that\n","Reference: Důvodem tohoto chování je , že <UNK> byl neustále\n","Model: <SOS> Důvodem pro <UNK> spočívá skutečnost , se <UNK> <UNK>\n","\n","Source: These few <UNK> of information alone tell us , I\n","Reference: Myslím si , že pouze několik těchto údajů stačí\n","Model: <SOS> Tyto se že že někteří málo málo <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.07, Train Loss: 0.00, Val Loss: 3.35, Train BLEU: 0.00, Val BLEU: 21.67, Minutes Elapsed: 102.75\n","Sampling from val predictions...\n","Source: These are in effect a manifestation of the practice by\n","Reference: Ty jsou v podstatě <UNK> praktik <UNK> a <UNK>\n","Model: <SOS> To jsou v <UNK> <UNK> , , které ,\n","\n","Source: Article 3 of the declaration states : ' Everyone has\n","Reference: Třetí odstavec deklarace zní : \" Každý má právo\n","Model: <SOS> Článek 3 . : : \" <UNK> <UNK> <UNK>\n","\n","Source: The openness of European institutions and the transparency of their\n","Reference: <UNK> evropských orgánů a transparentnost jejich postupů jsou <UNK>\n","Model: <SOS> <UNK> evropských evropských a jejich <UNK> jejich a <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.14, Train Loss: 0.00, Val Loss: 3.35, Train BLEU: 0.00, Val BLEU: 21.76, Minutes Elapsed: 105.02\n","Sampling from val predictions...\n","Source: It is also true that this is more of a\n","Reference: Je také pravda , že se jedná spíše o\n","Model: <SOS> Je také pravda , že je jedná o o\n","\n","Source: At the same time , to make sure that testing\n","Reference: Zároveň zajistit , aby bylo dostupné testování , a\n","Model: <SOS> Zároveň se , aby se <UNK> <UNK> <UNK> <UNK>\n","\n","Source: These territories , which lie within the borders of the\n","Reference: Tato území , jež leží na území dnešních zemí\n","Model: <SOS> Tato , , která je <UNK> rámci hranicích hranic\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.21, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 22.11, Minutes Elapsed: 107.29\n","Sampling from val predictions...\n","Source: For agriculture , this mandate was simply not to force\n","Reference: Pokud jde o zemědělství , tento mandát <UNK> prostě\n","Model: <SOS> Pro zemědělství o tento , , to nebyl <UNK>\n","\n","Source: The multilateral trade system , based on rules and established\n","Reference: <UNK> obchodní systém založený na pravidlech , který byl\n","Model: <SOS> Systém systém systém , který <UNK> , na <UNK>\n","\n","Source: For all these reasons , I voted in favour of\n","Reference: Ze všech těchto důvodů jsem hlasoval pro přijetí zprávy\n","Model: <SOS> Ze všech těchto důvodů jsem hlasoval pro tuto zprávu\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.28, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 21.96, Minutes Elapsed: 109.55\n","Sampling from val predictions...\n","Source: Please study them carefully . <EOS> <PAD> <PAD> <PAD> <PAD>\n","Reference: Prosím Vás , abyste si je pozorně <UNK> .\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> <UNK> . <UNK> . .\n","\n","Source: The international community has taken some action and , it\n","Reference: Mezinárodní společenství <UNK> určité kroky a musím říci ,\n","Model: <SOS> Mezinárodní společenství má určité kroky a je je ,\n","\n","Source: Claude Turmes has finally agreed a compromise that we can\n","Reference: <UNK> <UNK> nakonec <UNK> kompromis , který bezvýhradně podporujeme\n","Model: <SOS> <UNK> <UNK> konečně konečně , , který jsme <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.36, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.00, Minutes Elapsed: 111.82\n","Sampling from val predictions...\n","Source: I also welcome the Member State flexibility there is now\n","Reference: Rovněž vítám flexibilitu , která zde nyní pro členské\n","Model: <SOS> Vítám také , členských států se nyní <UNK> ,\n","\n","Source: The management of this transition has been <UNK> by public\n","Reference: <UNK> tohoto přechodu se <UNK> o veřejný zásah zaměřený\n","Model: <SOS> <UNK> tohoto <UNK> <UNK> <UNK> <UNK> veřejné veřejné <UNK>\n","\n","Source: For this reason , I believe the Neighbourhood Policy should\n","Reference: Domnívám se proto , že politika sousedství by měla\n","Model: <SOS> Proto jsem proto , že politika politika by měla\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.43, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 21.75, Minutes Elapsed: 114.08\n","Sampling from val predictions...\n","Source: I am therefore grateful to Mrs <UNK> , who showed\n","Reference: Proto jsem vděčná paní <UNK> , která měla trochu\n","Model: <SOS> Proto proto paní paní <UNK> <UNK> , nám <UNK>\n","\n","Source: A fall in production and consumption has been accompanied by\n","Reference: <UNK> produkce a spotřeby je <UNK> růstem dovozu a\n","Model: <SOS> <UNK> výroba výroba <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: Tehran already has rockets able to reach almost the whole\n","Reference: <UNK> již má <UNK> schopné dosáhnout téměř do celé\n","Model: <SOS> <UNK> již již již <UNK> téměř téměř než <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.50, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.07, Minutes Elapsed: 116.35\n","Sampling from val predictions...\n","Source: I personally believe that these other activities should be very\n","Reference: Já osobně se domnívám , že tyto ostatní činnosti\n","Model: <SOS> Osobně jsem domnívám domnívám , že by měly by\n","\n","Source: As the honourable Member states , there is currently no\n","Reference: Jak prohlásil <UNK> poslanec , nyní neexistují žádné konkrétní\n","Model: <SOS> Jak poslanec poslanec poslanec , současné současné současné <UNK>\n","\n","Source: I think that more clarity is needed about the terms\n","Reference: Myslím , že je zapotřebí více <UNK> co do\n","Model: <SOS> Myslím , že je třeba <UNK> <UNK> o o\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.57, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.23, Minutes Elapsed: 118.60\n","Sampling from val predictions...\n","Source: 1 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: 1 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> 1 . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n","\n","Source: The wine growers in the south of France went along\n","Reference: <UNK> vína na jihu Francie tak udělali , ale\n","Model: <SOS> <UNK> <UNK> v <UNK> v v Francii že <UNK>\n","\n","Source: The directive strengthens the position of the European monopolies in\n","Reference: Tato směrnice posiluje postavení evropských monopolů ve vztahu s\n","Model: <SOS> Směrnice <UNK> <UNK> <UNK> evropského v v <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.64, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.19, Minutes Elapsed: 120.88\n","Sampling from val predictions...\n","Source: It is obvious , therefore , that efforts should be\n","Reference: Je tedy zřejmé , že bychom měli zajistit trvalý\n","Model: <SOS> Je proto zřejmé zřejmé že by úsilí vyvinout <UNK>\n","\n","Source: The recent fires in Greece had a disastrous impact on\n","Reference: Nedávné požáry v Řecku měly katastrofální dopad na zemědělskou\n","Model: <SOS> <UNK> v v Řecku Řecku <UNK> dopad na na\n","\n","Source: That is not a fair procedure . <EOS> <PAD> <PAD>\n","Reference: To není spravedlivý postup . <EOS> <PAD> <PAD> <PAD>\n","Model: <SOS> To není spravedlivé spravedlivé . <EOS> . <EOS> .\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.71, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.35, Minutes Elapsed: 123.15\n","Sampling from val predictions...\n","Source: In <UNK> , armed individuals <UNK> in , shooting 52\n","Reference: V <UNK> <UNK> <UNK> <UNK> a <UNK> lidí <UNK>\n","Model: <SOS> V <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n","Source: <UNK> , under the Convention on <UNK> Diversity , the\n","Reference: Následně přijaly na základě Úmluvy o biologické rozmanitosti světové\n","Model: <SOS> <UNK> , podle o <UNK> o <UNK> <UNK> <UNK>\n","\n","Source: This learning <UNK> the child ' s intelligence , <UNK>\n","Reference: Toto učení <UNK> <UNK> dítěte , <UNK> jeho <UNK>\n","Model: <SOS> Tento <UNK> <UNK> <UNK> <UNK> , <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.78, Train Loss: 0.00, Val Loss: 3.32, Train BLEU: 0.00, Val BLEU: 21.98, Minutes Elapsed: 125.41\n","Sampling from val predictions...\n","Source: Madam President , I would first of all like to\n","Reference: Paní předsedající , nejdříve bych chtěla poděkovat panu komisaři\n","Model: <SOS> Paní předsedající , nejprve bych chtěl poděkoval všem <UNK>\n","\n","Source: We call on the Council to finally release these funds\n","Reference: Vyzýváme Radu , aby konečně bez <UNK> překážek tyto\n","Model: <SOS> Vyzýváme Radu , aby <UNK> <UNK> prostředky prostředky prostředky\n","\n","Source: Therefore , it is not clear why a complete industry\n","Reference: Proto není jasné , proč by mělo být ze\n","Model: <SOS> Proto není jasné , proč by <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.85, Train Loss: 0.00, Val Loss: 3.32, Train BLEU: 0.00, Val BLEU: 22.14, Minutes Elapsed: 127.68\n","Sampling from val predictions...\n","Source: At the very end it is simple : EU border\n","Reference: V konečném důsledku je to velmi jednoduché : konečnou\n","Model: <SOS> Na je je je <UNK> : : : EU\n","\n","Source: I will now listen with great interest to the speakers\n","Reference: Nyní si s velkým zájmem <UNK> účastníky této rozpravy\n","Model: <SOS> Nyní <UNK> velkým <UNK> zájmem zájmem <UNK> <UNK> <UNK>\n","\n","Source: This vote relates to the second reading of the proposal\n","Reference: Toto hlasování se týká druhého čtení návrhu původně <UNK>\n","Model: <SOS> Toto hlasování se týká hlasování návrhu návrhu návrhu <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3.93, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.01, Minutes Elapsed: 129.94\n","Sampling from val predictions...\n","Source: We have to strive towards this until 2014 . <EOS>\n","Reference: Musíme se to pokusit vyřešit do roku 2014 .\n","Model: <SOS> Musíme se usilovat snažit k k roku . .\n","\n","Source: 18 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: 18 . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> 18 . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n","\n","Source: Ladies and gentlemen , we are not talking about <UNK>\n","Reference: Dámy a pánové , <UNK> zde o <UNK> ,\n","Model: <SOS> Dámy a pánové , hovoříme o o <UNK> ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.25, Minutes Elapsed: 132.19\n","Sampling from val predictions...\n","Source: I would like to explain that I have a lot\n","Reference: Chtěl bych vysvětlit , že mám na seznamu mnoho\n","Model: <SOS> Rád bych vysvětlit , že jsem hodně <UNK> <UNK>\n","\n","Source: This is the most advanced status we can give to\n","Reference: To je nejlepší status , který můžeme určité zemi\n","Model: <SOS> To je <UNK> <UNK> , , můžeme dát <UNK>\n","\n","Source: The fuel quality directive has two objectives : air quality\n","Reference: Směrnice o kvalitě paliv má dva cíle : kvalitu\n","Model: <SOS> <UNK> <UNK> jakosti jakosti má dvě dvě : kvality\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.53, Minutes Elapsed: 133.47\n","Sampling from val predictions...\n","Source: Finally , the Commission wishes to avoid any possible interruption\n","Reference: A konečně , Komise se chce vyvarovat jakéhokoli <UNK>\n","Model: <SOS> A závěr chce Komise Komise chce <UNK> o <UNK>\n","\n","Source: Here it can be shown that the Product Safety Directive\n","Reference: Zde lze prokázat , že směrnice o bezpečnosti hraček\n","Model: <SOS> Můžeme lze říci , že směrnice o bezpečnosti <UNK>\n","\n","Source: What is the reason for this position ? <EOS> <PAD>\n","Reference: Jaký důvod se skrývá za tímto postojem ? <EOS>\n","Model: <SOS> Jaký je postoj postoj ? <EOS> ? <EOS> <EOS>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.07, Train Loss: 0.00, Val Loss: 3.32, Train BLEU: 0.00, Val BLEU: 22.21, Minutes Elapsed: 135.74\n","Sampling from val predictions...\n","Source: At present , a thousand posts must be under threat\n","Reference: V současné době mohou o prostředky z fondu žádat\n","Model: <SOS> V současnosti době musí být <UNK> <UNK> <UNK> <UNK>\n","\n","Source: In this way , the issues that are on the\n","Reference: <UNK> , jimiž se zabýváme , jsou tedy nesmírně\n","Model: <SOS> Tímto způsobem , v otázky na <UNK> které <UNK>\n","\n","Source: I think we can agree on this . <EOS> <PAD>\n","Reference: Domnívám se , že na tom se všichni shodneme\n","Model: <SOS> Myslím , , že můžeme tom můžeme . shodneme\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.14, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.39, Minutes Elapsed: 138.01\n","Sampling from val predictions...\n","Source: Mr President , the Commission ' s proposal focuses on\n","Reference: Pane předsedající , návrh Komise se soustředí na to\n","Model: <SOS> Pane Komise , návrh Komise se zaměřuje na <UNK>\n","\n","Source: This process of strengthening European statistical governance is supplemented by\n","Reference: Tento proces posilování řízení evropské statistiky je <UNK> o\n","Model: <SOS> Tento posílení integrace správy správy evropské je <UNK> <UNK>\n","\n","Source: <UNK> on all political activities and strict censorship of the\n","Reference: 1 . března 2008 byl <UNK> zákaz veškeré politické\n","Model: <SOS> <UNK> všech politických činnosti činnosti a a <UNK> a\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.21, Train Loss: 0.00, Val Loss: 3.32, Train BLEU: 0.00, Val BLEU: 22.71, Minutes Elapsed: 140.26\n","Sampling from val predictions...\n","Source: There is no problem . <EOS> <PAD> <PAD> <PAD> <PAD>\n","Reference: Problém neexistuje . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> Není problém neexistuje <EOS> . <EOS> . . .\n","\n","Source: In particular , we support the amendments which make it\n","Reference: Podporujeme zejména pozměňovací návrhy , které <UNK> , že\n","Model: <SOS> Zejména zejména návrhy návrhy , jejichž cílem , aby\n","\n","Source: As Mr Solana has just said , the international community\n","Reference: Jak pan <UNK> právě řekl , mezinárodní společenství je\n","Model: <SOS> Jak právě pan řekl , , mezinárodní společenství <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.28, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.62, Minutes Elapsed: 142.53\n","Sampling from val predictions...\n","Source: This followed a period of intense pressure from the financial\n","Reference: Toto rozhodnutí <UNK> po období <UNK> tlaku ze strany\n","Model: <SOS> <UNK> <UNK> <UNK> <UNK> na z z na krize\n","\n","Source: These are fundamental rights , and a simple cost -\n","Reference: To jsou základní práva a tam , kde se\n","Model: <SOS> To jsou základní práva , <UNK> <UNK> <UNK> se\n","\n","Source: In our view , farmers must be rewarded for providing\n","Reference: Podle našeho názoru je třeba zemědělce <UNK> za služby\n","Model: <SOS> Podle našeho názoru musí být poskytovat <UNK> za ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.36, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.65, Minutes Elapsed: 144.80\n","Sampling from val predictions...\n","Source: We must make every effort to accelerate the process which\n","Reference: Musíme vynaložit veškeré úsilí k urychlení procesu <UNK> v\n","Model: <SOS> Musíme vynaložit veškeré úsilí , abychom , procesu který\n","\n","Source: Above all , we must reject and refuse to <UNK>\n","Reference: Především musíme odmítnout a <UNK> přesun politiky zpět na\n","Model: <SOS> Především musíme musíme a a <UNK> , <UNK> <EOS>\n","\n","Source: Providing information is our responsibility and our duty , whereas\n","Reference: <UNK> informací je naším úkolem a naší povinností ,\n","Model: <SOS> <UNK> informace je <UNK> povinností a naše naše ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.43, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.50, Minutes Elapsed: 147.04\n","Sampling from val predictions...\n","Source: The internal market will not , however , function properly\n","Reference: Avšak vnitřní trh nebude správně fungovat , pokud nebudou\n","Model: <SOS> <UNK> trh trh nebude fungovat <UNK> a <UNK> by\n","\n","Source: Will they be integrated into existing programmes ? <EOS> <PAD>\n","Reference: Budou začleněny do stávajících programů ? <EOS> <PAD> <PAD>\n","Model: <SOS> Budou se do <UNK> <UNK> ? ? <EOS> <EOS>\n","\n","Source: We are prepared to offer assistance to the Iraqi Council\n","Reference: <UNK> parlamentu jsme připraveni poskytnout <UNK> podporu , učit\n","Model: <SOS> Jsme připraveni Radě Radě Radě Radě a Radě a\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.50, Train Loss: 0.00, Val Loss: 3.33, Train BLEU: 0.00, Val BLEU: 22.63, Minutes Elapsed: 149.31\n","Sampling from val predictions...\n","Source: We are in quite a difficult situation , since ,\n","Reference: Jsme v dosti složité situaci , protože Súdán je\n","Model: <SOS> Jsme jsme obtížné obtížné obtížné , protože v <UNK>\n","\n","Source: The doctor - patient relationship will not be adversely affected\n","Reference: <UNK> mezi <UNK> a <UNK> nebude touto směrnicí negativně\n","Model: <SOS> <UNK> <UNK> <UNK> , <UNK> <UNK> <UNK> . budou\n","\n","Source: This will facilitate their integration into the employment market and\n","Reference: To usnadní jejich integraci do trhu práce a poskytne\n","Model: <SOS> <UNK> <UNK> <UNK> integraci do integraci a a a\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.57, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 22.76, Minutes Elapsed: 151.57\n","Sampling from val predictions...\n","Source: It is therefore essential that there should be a clear\n","Reference: Je proto důležité , aby <UNK> jasný závazek a\n","Model: <SOS> Je proto nezbytné , aby existovala <UNK> jasný ,\n","\n","Source: A final remark on Turkey : when evaluating Turkey ,\n","Reference: <UNK> poznámka k Turecku : chtěl bych vás vyzvat\n","Model: <SOS> Poslední poznámka k Turecku : Turecku Turecko li Turecko\n","\n","Source: ( DE ) Mr President , following the confidence vote\n","Reference: ( DE ) Pane předsedající , po <UNK> hlasování\n","Model: <SOS> ( DE ) Pane předsedající , po <UNK> hlasování\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.64, Train Loss: 0.00, Val Loss: 3.35, Train BLEU: 0.00, Val BLEU: 22.67, Minutes Elapsed: 153.85\n","Sampling from val predictions...\n","Source: Several Members mentioned the need for additional funds for new\n","Reference: Několik poslanců zde <UNK> potřebu vytvoření dodatečných finančních prostředků\n","Model: <SOS> Několik poslanci zmínila o potřebu dodatečné prostředky prostředků prostředky\n","\n","Source: The draft agreement therefore contains a provision stating that there\n","Reference: Návrh dohody tedy obsahuje ustanovení , které uvádí ,\n","Model: <SOS> <UNK> dohoda obsahuje obsahuje ustanovení ustanovení která obsahuje v\n","\n","Source: This is why I believe that agriculture must remain an\n","Reference: A proto jsem přesvědčen , že zemědělství musí zůstat\n","Model: <SOS> Proto se se domnívám názoru že zemědělství zemědělství zůstat\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.71, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 22.72, Minutes Elapsed: 156.09\n","Sampling from val predictions...\n","Source: Thank you very much . <EOS> <PAD> <PAD> <PAD> <PAD>\n","Reference: Velmi vám děkuji . <EOS> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> Děkuji vám děkuji . <EOS> . <EOS> . <EOS>\n","\n","Source: I voted in favour of granting discharge in respect of\n","Reference: Hlasovala jsem pro udělení absolutoria za plnění rozpočtu Evropského\n","Model: <SOS> Hlasovala jsem pro udělení absolutoria za plnění rozpočtu Evropské\n","\n","Source: However , that support should be given to genuine democratic\n","Reference: Podpora by ale měla být poskytnuta skutečným demokratickým <UNK>\n","Model: <SOS> Tato podpora by měla být <UNK> <UNK> a ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.78, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 22.35, Minutes Elapsed: 158.36\n","Sampling from val predictions...\n","Source: We have therefore tried to do some <UNK> up ,\n","Reference: <UNK> jsme se proto udělat \" <UNK> \", objasnit\n","Model: <SOS> <UNK> jsme se proto dělat <UNK> <UNK> <UNK> ,\n","\n","Source: It is quite right for Parliament to take up the\n","Reference: Je velmi správné , že Parlament se znovu zabývá\n","Model: <SOS> Je správné správné , že Parlament Parlament <UNK> přijmout\n","\n","Source: ( IT ) Mr President , ladies and gentlemen ,\n","Reference: ( IT ) Vážený pane předsedající , dámy a\n","Model: <SOS> ( IT ) Pane předsedající předsedající , dámy a\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.85, Train Loss: 0.00, Val Loss: 3.35, Train BLEU: 0.00, Val BLEU: 22.52, Minutes Elapsed: 160.62\n","Sampling from val predictions...\n","Source: ( PL ) Madam President , it is hard for\n","Reference: ( PL ) Vážená paní předsedající , je pro\n","Model: <SOS> ( PL ) Paní předsedající předsedající , je pro\n","\n","Source: It is a solid report that will reflect realities even\n","Reference: Je to dobrá zpráva , která bude ještě lepším\n","Model: <SOS> Je to zpráva zpráva , která se <UNK> velký\n","\n","Source: Her past , and the attitude that she has often\n","Reference: Její minulost a postoj , který často projevila ,\n","Model: <SOS> Její minulost a <UNK> , , <UNK> , ,\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4.93, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 22.32, Minutes Elapsed: 162.88\n","Sampling from val predictions...\n","Source: We have now reached the second stage in the process\n","Reference: <UNK> jsme nyní do druhého <UNK> v procesu snižování\n","Model: <SOS> Nyní jsme nyní nyní fázi fáze procesu , o\n","\n","Source: It is a great shame because there is no political\n","Reference: Je to velká chyba , protože zde nelze vyvodit\n","Model: <SOS> Je to škoda škoda , protože v tomto politická\n","\n","Source: Mr President , the presence of large numbers of alleged\n","Reference: Pane předsedající , na programu zasedání Rady bude příliv\n","Model: <SOS> Pane předsedající , <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 5.00, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 22.55, Minutes Elapsed: 165.16\n","Sampling from val predictions...\n","Source: But we are very mindful of preference erosion and ,\n","Reference: Velmi nás zajímá narušení preferencí , a jakmile <UNK>\n","Model: <SOS> <UNK> však však <UNK> <UNK> , což <UNK> i\n","\n","Source: Naturally all of this will be displayed on your <UNK>\n","Reference: To vše se přirozeně objeví na vašich <UNK> .\n","Model: <SOS> <UNK> to bude bude bude <UNK> <UNK> <UNK> .\n","\n","Source: I consider such practices to be <UNK> violations of the\n","Reference: Mám za to , že takové praktiky jsou <UNK>\n","Model: <SOS> <UNK> tyto mysli praktiky že tyto praktiky <UNK> být\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 5.00, Train Loss: 0.00, Val Loss: 3.37, Train BLEU: 0.00, Val BLEU: 22.82, Minutes Elapsed: 166.42\n","Sampling from val predictions...\n","Source: A total cyanide ban would imply stopping European extraction and\n","Reference: <UNK> zákaz <UNK> by znamenal zastavení evropské těžby a\n","Model: <SOS> <UNK> zákaz <UNK> <UNK> by <UNK> evropské <UNK> <UNK>\n","\n","Source: Five years ago , did Members see the TV pictures\n","Reference: <UNK> poslanci před pěti lety televizní <UNK> stovek <UNK>\n","Model: <SOS> Před pěti , <UNK> dobou <UNK> <UNK> <UNK> <UNK>\n","\n","Source: I - like many colleagues in this Chamber - would\n","Reference: Podobně jako mnoho kolegů v této sněmovně bych byla\n","Model: <SOS> <UNK> , mnoho kolegů kolegů tomto sněmovně bych rád\n","\n","Model training completed in 166 minutes with 3.32 best validation loss and 22.82 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_CHMB1Nbngrz","colab_type":"text"},"source":["## Show dev and test results"]},{"cell_type":"code","metadata":{"id":"DA1Gcfl1rqZ4","colab_type":"code","colab":{}},"source":["def plot_single_learning_curve(results, figsize=(14, 5)): \n","    \"\"\" Plots learning curve of a SINGLE experiment \"\"\"\n","    results_df = pd.DataFrame.from_dict(results)\n","    results_df = results_df.set_index('epoch')\n","    results_df = results_df[['val_bleu', 'val_loss']]\n","\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n","    results_df['val_loss'].plot(ax=axes[0])\n","    axes[0].set_ylabel('Validation Loss')\n","    results_df['val_bleu'].plot(ax=axes[1])\n","    axes[1].set_ylabel('Validation BLEU')\n","    axes[0].set_xlabel('Epoch')\n","    axes[1].set_xlabel('Epoch')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ8ttWthk5dx","colab_type":"code","outputId":"9ee36ccc-3cbd-4fe0-a375-e112df997968","executionInfo":{"status":"ok","timestamp":1589492468152,"user_tz":240,"elapsed":656,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["experiment_results = load_experiment_log(experiment_name=EXPERIMENT_NAME)\n","plot_single_learning_curve(experiment_results[0]['results'])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1008x360 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"s_KLgx5NRljM","colab_type":"code","colab":{}},"source":["model_backup = copy.deepcopy(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGA9kMUZmhEr","colab_type":"code","outputId":"80799928-6e9f-49c2-af93-f73e79b43e97","executionInfo":{"status":"ok","timestamp":1589492480895,"user_tz":240,"elapsed":317,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["summarize_results(experiment_results)[['model_name', 'best_val_loss', 'best_val_bleu', 'runtime', \n","                                       'total_params', 'trainable_params', 'dt_created']]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_name</th>\n","      <th>best_val_loss</th>\n","      <th>best_val_bleu</th>\n","      <th>runtime</th>\n","      <th>total_params</th>\n","      <th>trainable_params</th>\n","      <th>dt_created</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>en-cz-rnn-without-attn-2020-05-14 18:54:16</td>\n","      <td>3.324303</td>\n","      <td>22.819461</td>\n","      <td>166.42937</td>\n","      <td>36992144</td>\n","      <td>36992144</td>\n","      <td>2020-05-14 21:40:45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                   model_name  ...           dt_created\n","0  en-cz-rnn-without-attn-2020-05-14 18:54:16  ...  2020-05-14 21:40:45\n","\n","[1 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"iGtDelPvnvYv","colab_type":"code","outputId":"4af44c10-b1b5-498c-a2ed-99f9fc0b13b3","executionInfo":{"status":"ok","timestamp":1589492722507,"user_tz":240,"elapsed":71858,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# check performance on validation set \n","val_loss, val_bleu, val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens,\\\n","val_attn = evaluate(model=model, loader=loaders_full['dev'], \n","                    src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n","print(\"Validation BLEU: {:.2f} | Validation Loss: {:.2f}\".format(val_bleu, val_loss))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Validation BLEU: 22.82 | Validation Loss: 3.37\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EmgtuBRSnxz6","colab_type":"code","outputId":"b59214fc-4400-4e1d-fe9b-ee5615167f09","executionInfo":{"status":"ok","timestamp":1589492796878,"user_tz":240,"elapsed":72809,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["test_loss, test_bleu, test_hyp_idxs, test_ref_idxs, test_source_idxs, test_hyp_tokens, test_ref_tokens, test_source_tokens,\\\n","test_attn = evaluate(model=model, loader=loaders_full['test'], \n","                     src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n","print(\"Test BLEU: {:.2f} | Test Loss: {:.2f}\".format(test_bleu, test_loss))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:root:That's 100 lines that end in a tokenized period ('.')\n","WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n","WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"],"name":"stderr"},{"output_type":"stream","text":["Test BLEU: 22.89 | Test Loss: 3.36\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vqeovmmsM8Wx","colab_type":"text"},"source":["## Transfer learning on EN-PS"]},{"cell_type":"code","metadata":{"id":"gfIsOEJL-kBd","colab_type":"code","colab":{}},"source":["model = copy.deepcopy(model_backup)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_LGqZE-nuXv","colab_type":"code","outputId":"1604a736-f5fa-47f5-9777-07c09f67c6b7","executionInfo":{"status":"ok","timestamp":1589507634982,"user_tz":240,"elapsed":543,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# reload model\n","MODEL_NAME_TO_RELOAD = 'en-cz-rnn-without-attn-2020-05-14 18:54:16'\n","checkpoint = torch.load('/content/drive/My Drive/ds1012/MT/model_checkpoints/{}.pth.tar'.format(MODEL_NAME_TO_RELOAD), map_location=device)\n","model.load_state_dict(checkpoint)"],"execution_count":361,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":361}]},{"cell_type":"code","metadata":{"id":"Da6IVUaoJbvZ","colab_type":"code","colab":{}},"source":["# reload from pickle for en-ps\n","SRC_LANG = 'en'\n","TARG_LANG = 'ps'\n","SRC_VOCAB_SIZE = 10000\n","TARG_VOCAB_SIZE = 10000\n","\n","vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","vocab = pkl.load(open(vocab_filename, \"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M35cxHE0J7xH","colab_type":"code","colab":{}},"source":["# Load data for en-ps\n","data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False) # 449691\n","data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) #64\n","data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False) #1000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCKbwtZdKPUQ","colab_type":"code","colab":{}},"source":["# create dataloaders \n","## in the form \n","loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORECuRGbK3z3","colab_type":"code","colab":{}},"source":["RESULTS_LOG = '/content/drive/My Drive/ds1012/MT/experiment_results/{}_{}_transfer_experiment_results_log.pkl'.format(SRC_LANG, TARG_LANG)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNki1Qv_LOlU","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'ps'\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000\n","# model architecture params \n","NETWORK_TYPE = 'rnn'\n","RNN_CELL_TYPE = 'gru'\n","NUM_LAYERS = 2 \n","ENC_HIDDEN_DIM = 512\n","DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n","TEACHER_FORCING_RATIO = 1\n","CLIP_GRAD_MAX_NORM = 1\n","ENC_DROPOUT = 0 \n","DEC_DROPOUT = 0  \n","ATTENTION_TYPE = 'without'\n","\n","# training params  \n","NUM_EPOCHS = 10\n","LR = 0.00015 \n","OPTIMIZER = 'Adam'\n","LAZY_TRAIN = False\n","\n","# name the model and experiment \n","if NETWORK_TYPE == 'rnn': \n","    EXPERIMENT_NAME = '{}-{}-rnn-{}-attn'.format(SRC_LANG, TARG_LANG, ATTENTION_TYPE)\n","elif NETWORK_TYPE == 'cnn': \n","    EXPERIMENT_NAME = '{}-cnn'.format(SRC_LANG)\n","MODEL_NAME = '{}-{}'.format(EXPERIMENT_NAME, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hA8v7q9CMPX_","colab_type":"code","colab":{}},"source":["# store as dict to save to results later \n","params = {'experiment_name': EXPERIMENT_NAME,'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n","          'rnn_cell_type': RNN_CELL_TYPE, 'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, \n","          'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, 'src_vocab_size': SRC_VOCAB_SIZE, \n","          'targ_vocab_size': TARG_VOCAB_SIZE, 'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, \n","          'dec_hidden_dim': DEC_HIDDEN_DIM, 'teacher_forcing_ratio': TEACHER_FORCING_RATIO, \n","          'clip_grad_max_norm': CLIP_GRAD_MAX_NORM, 'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n","          'attention_type': ATTENTION_TYPE, 'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, \n","          'learning_rate': LR, 'optimizer': OPTIMIZER, 'lazy_train': LAZY_TRAIN}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-ffE2iAphUd","colab_type":"code","colab":{}},"source":["# freeze encoder\n","for p in model.encoder.parameters():\n","    p.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3O0Xnh37Pgj7","colab_type":"code","colab":{}},"source":["encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVqX-1m1qEfl","colab_type":"code","colab":{}},"source":["model_ps, results_ps = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=paramsm, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ssEH3h8ObUm","colab_type":"code","colab":{}},"source":["# not fix encoder\n","model_ps, results_ps = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmZ2BDQQydsW","colab_type":"code","colab":{}},"source":["# only fix source embedding\n","# freeze encoder\n","for p in model.encoder.parameters():\n","    p.requires_grad = False\n","    break\n","model, results = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCdwZXDOyrbB","colab_type":"code","colab":{}},"source":["# only fix encoder RNN\n","for i, p in enumerate(model.encoder.parameters()):\n","    if i==0:continue\n","    else:\n","      p.requires_grad = False\n","model, results = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wMsvFyB16t0k","colab_type":"text"},"source":["### Transfer on od"]},{"cell_type":"code","metadata":{"id":"xpfcrWT63ByD","colab_type":"code","colab":{}},"source":["# reload from pickle for en-od\n","SRC_LANG = 'en'\n","TARG_LANG = 'od'\n","SRC_VOCAB_SIZE = 10000\n","TARG_VOCAB_SIZE = 10000\n","\n","vocab_filename = \"/content/drive/My Drive/ds1012/MT/vocab/{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n","vocab = pkl.load(open(vocab_filename, \"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyKJr5WW6s5f","colab_type":"code","colab":{}},"source":["# Load data for en-od\n","data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False) # 449691\n","data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) #64\n","data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False) #1000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUJxVZSJ66lq","colab_type":"code","colab":{}},"source":["# create dataloaders \n","## in the form \n","loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n","loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"12c0eCqb69sd","colab_type":"code","colab":{}},"source":["RESULTS_LOG = '/content/drive/My Drive/ds1012/MT/experiment_results/{}_{}_transfer_experiment_results_log.pkl'.format(SRC_LANG, TARG_LANG)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQ3YbQES7CHf","colab_type":"code","colab":{}},"source":["SRC_LANG = 'en'\n","TARG_LANG = 'od'\n","SRC_VOCAB_SIZE = 10000 \n","TARG_VOCAB_SIZE = 10000\n","# model architecture params \n","NETWORK_TYPE = 'rnn'\n","RNN_CELL_TYPE = 'gru'\n","NUM_LAYERS = 2 \n","ENC_HIDDEN_DIM = 512\n","DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n","TEACHER_FORCING_RATIO = 1\n","CLIP_GRAD_MAX_NORM = 1\n","ENC_DROPOUT = 0 \n","DEC_DROPOUT = 0  \n","ATTENTION_TYPE = 'without'\n","\n","# training params  \n","NUM_EPOCHS = 10\n","LR = 0.00015 \n","OPTIMIZER = 'Adam'\n","LAZY_TRAIN = False\n","\n","# name the model and experiment \n","if NETWORK_TYPE == 'rnn': \n","    EXPERIMENT_NAME = '{}-{}-rnn-{}-attn'.format(SRC_LANG, TARG_LANG, ATTENTION_TYPE)\n","elif NETWORK_TYPE == 'cnn': \n","    EXPERIMENT_NAME = '{}-cnn'.format(SRC_LANG)\n","MODEL_NAME = '{}-{}'.format(EXPERIMENT_NAME, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qcyqfR7S7J2o","colab_type":"code","colab":{}},"source":["# store as dict to save to results later \n","params = {'experiment_name': EXPERIMENT_NAME,'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n","          'rnn_cell_type': RNN_CELL_TYPE, 'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, \n","          'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, 'src_vocab_size': SRC_VOCAB_SIZE, \n","          'targ_vocab_size': 6246, 'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, \n","          'dec_hidden_dim': DEC_HIDDEN_DIM, 'teacher_forcing_ratio': TEACHER_FORCING_RATIO, \n","          'clip_grad_max_norm': CLIP_GRAD_MAX_NORM, 'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n","          'attention_type': ATTENTION_TYPE, 'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, \n","          'learning_rate': LR, 'optimizer': OPTIMIZER, 'lazy_train': LAZY_TRAIN}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"paPjGYHd7KlL","colab_type":"code","colab":{}},"source":["# not fix\n","encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzo8Ejob7bJZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b646f42c-4461-466a-8de2-b75c637d81dc","executionInfo":{"status":"ok","timestamp":1589507044605,"user_tz":240,"elapsed":348437,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}}},"source":["model_od, results_od = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":354,"outputs":[{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.66, Train BLEU: 0.00, Val BLEU: 0.02, Minutes Elapsed: 0.01\n","Sampling from val predictions...\n","Source: The wife hath not power of her own body ,\n","Reference: ପତ ୍ ନ ୀ ର ତ ା' ନ ି\n","Model: <SOS> ଚ ବଡଲଲ ବଡଲଲ 50 ମଋତ ସହନଶ ସହନଶ ସହନଶ ବନଠ\n","\n","Source: Thy shepherds slumber , O king of Assyria : thy\n","Reference: ହ େ ଅଶ ୂ ରର ର ା ଜ ା,\n","Model: <SOS> God କନହସଙ କନହସଙ ପସରସସମ 77 ଧକଲସରସସ ଧକଲସରସସ ଧକଲସରସସ ଧକଲସରସସ\n","\n","Source: And the drinking was according to the law ; none\n","Reference: ଦ ୍ ର ା କ ୍ ଷ ା ରସ\n","Model: <SOS> ୃ ୃ ୍ ୍ ୍ ୍ ୍ ୍ ୍\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.47, Train BLEU: 0.00, Val BLEU: 12.01, Minutes Elapsed: 0.60\n","Sampling from val predictions...\n","Source: <UNK> <UNK> <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD>\n","Reference: ମତ ୍ ସ ୍ ୟ ଏବ ଂ ପଶ ୁ\n","Model: <SOS> ଯ ି ର ା ତ ୍ ୍ ତ ା\n","\n","Source: Lo now , his strength is in his loins ,\n","Reference: ବ େ ହମ ୋେ ତର ଶର ୀ ର ର\n","Model: <SOS> ତ େ ଶ ୍ ତ ତ େ େ ର\n","\n","Source: And we declare unto you glad tidings , how that\n","Reference: ଆମ ୍ ଭ ପ ୂ ର ୍ ବ ପ\n","Model: <SOS> ତ େ ଭ େ ତ ର ି ତ ା\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.17, Train BLEU: 0.00, Val BLEU: 16.68, Minutes Elapsed: 1.18\n","Sampling from val predictions...\n","Source: For when they speak great swelling words of vanity ,\n","Reference: ସହ େି ଭଣ ୍ ଡ ଶ ି କ ୍\n","Model: <SOS> ଯ ା ଲ ୋ ତ ା କ ମ ୍\n","\n","Source: Give to him that asketh thee , and from him\n","Reference: ଯଦ ି କହ େି ତ ୁ ମ ୍ ଭକ\n","Model: <SOS> ତ େ ତ ୁ ଲ ୁ ମ ୍ ଭ\n","\n","Source: And they said , What need we any further witness\n","Reference: ସମ ା ନ େେ କହ ି ଲ େ, \"\n","Model: <SOS> ସମ ା ନ େେ କହ ା ଲ େ, \"\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.06, Train BLEU: 0.00, Val BLEU: 19.05, Minutes Elapsed: 1.76\n","Sampling from val predictions...\n","Source: And on the morrow when he departed , he took\n","Reference: ତ ା' ପରଦ ି ନ ଶମ ି ର ୋ\n","Model: <SOS> ତ େ ପର େ ନ ତ ୁ ତ ୍\n","\n","Source: The son of Mahli , the son of Mushi ,\n","Reference: ଶମର େ ମହଲ ି ଙ ୍ କ ପ ୁ\n","Model: <SOS> ତ ା ବ ୁ ବ ା କ ପ ୁ\n","\n","Source: The old lion perisheth for lack of prey , and\n","Reference: ହ ଁ, ସହ େି ଦ ୁ ଷ ୍ ଟଲ\n","Model: <SOS> ତ ୍ ସ ା ସ ା ର ୍ ଟ\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.03, Train BLEU: 0.00, Val BLEU: 20.28, Minutes Elapsed: 2.34\n","Sampling from val predictions...\n","Source: Thus saith the LORD ; <UNK> thy voice from weeping\n","Reference: ସଦ ା ପ ୍ ରଭ ୁ ଏହ ି କଥ\n","Model: <SOS> ସଦ ା ପ ୍ ରଭ ୁ ଏହ ୁ କଥ\n","\n","Source: And the LORD stirred up an adversary unto Solomon ,\n","Reference: ଅନନ ୍ ତର ସଦ ା ପ ୍ ରଭ ୁ\n","Model: <SOS> ତ ା ତର ସଦ ା ପ ୍ ରଭ ୁ\n","\n","Source: And unto the families of the children of Merari ,\n","Reference: ଏହ ା ପର େ ସମ ା ନ େେ ମର\n","Model: <SOS> ତ ା ପର େ ବ ୍ ନ େେ ପରମ\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 3.10, Train BLEU: 0.00, Val BLEU: 20.70, Minutes Elapsed: 2.92\n","Sampling from val predictions...\n","Source: And Chaldea shall be a spoil : all that spoil\n","Reference: ସମ ା ନ େେ କଲଦ ୀ ଯମ ା ନଙ\n","Model: <SOS> ପ ି ନ େେ ବ ୁ ୁ ୁ ନ\n","\n","Source: If they obey and serve him , they shall spend\n","Reference: ଯଦ ି ସହ େି ଲ ୋ କମ ା ନ\n","Model: <SOS> ସମ ା ତ ା ଲ ା କମ ା ନ\n","\n","Source: <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: <UNK> ି ଶ ା ପର ୍ ଯ ୍ <UNK>\n","Model: <SOS> ଲ ି କ ୍ ବ ୍ ବ ୍ ପର\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 3.27, Train BLEU: 0.00, Val BLEU: 20.58, Minutes Elapsed: 3.50\n","Sampling from val predictions...\n","Source: And the messenger that was gone to call Micaiah spake\n","Reference: ଏହ ି ସମୟର େ ଆହ ା ବ ୍ ଙ\n","Model: <SOS> ତ ୁ ସ ୍ ବ ୁ ବ ୍ ତ\n","\n","Source: But when Jacob heard that there was corn in Egypt\n","Reference: ମ ି ଶର ର େ ଶସ ୍ ଯଥ ି\n","Model: <SOS> ଯ ି ଯ ା ଯ ଜ ା ଯ ା\n","\n","Source: And I heard the number of them which were sealed\n","Reference: ଏହ ି ପର ି ମ ୁ ଦ ୍ ର\n","Model: <SOS> ତ ା' ପର ା ଭ ା ନ ା ସମ\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 3.49, Train BLEU: 0.00, Val BLEU: 20.31, Minutes Elapsed: 4.08\n","Sampling from val predictions...\n","Source: And they shall build the old wastes , they shall\n","Reference: \" ସମ ା ନ େେ ପ ୁ ର ା\n","Model: <SOS> ସମ ା ା ନ େେ ସ ୁ ର ୁ\n","\n","Source: There is one come out of thee , that <UNK>\n","Reference: ଜଣ େ ୟ ି ଏ କ ି ସଦ ା\n","Model: <SOS> ତ ୁ ବ ୁ ଏ ୁ ୁ ତ ୁ\n","\n","Source: Run now , I pray thee , to meet her\n","Reference: ମ ୁଁ ବ ି ନଯ କର ୁ ଛ ି,\n","Model: <SOS> ତ ୁ ତ ୁ ତ ୁ ୁ ତ ୁ\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.61, Train BLEU: 0.00, Val BLEU: 20.98, Minutes Elapsed: 4.65\n","Sampling from val predictions...\n","Source: And <UNK> shall be led away captive , she shall\n","Reference: ର ା ଣ ୀ ଶତ ୃ ମ ା ନଙ\n","Model: <SOS> ଲ ୋ ଜ ା ଲ ୋ ର ି ନ\n","\n","Source: The Lord knoweth how to deliver the godly out of\n","Reference: ପରମ େ ଶ ୍ ବର ଏହ ି ସମସ ୍\n","Model: <SOS> ମ ା ଶ ୍ ବର ୍ ମ କଥ ା\n","\n","Source: The families of the sons of Kohath shall pitch on\n","Reference: କହ ା ତ ୀ ଯ ସନ ୍ ତ ା\n","Model: <SOS> ୟ ା ବ ି ି ି ି ଧ ୍\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.76, Train BLEU: 0.00, Val BLEU: 19.64, Minutes Elapsed: 5.23\n","Sampling from val predictions...\n","Source: But the judgment shall sit , and they shall take\n","Reference: \" ମ ା ତ ୍ ର ବ ି ଗ\n","Model: <SOS> କ ି ି ତ ୍ ର ସ ି ଶ\n","\n","Source: But whereunto shall I liken this generation ? It is\n","Reference: \" ଏହ ି ଲ ୋ କମ ା ନଙ ୍\n","Model: <SOS> କ ି ି ବ ୍ କମ ା ନଙ ୍\n","\n","Source: And there shall dwell in Judah itself , and in\n","Reference: \" ପ ୁ ଣ ି ଯ ି ହ ୁ\n","Model: <SOS> ସହ େି ା ର ି ସ େ ଉ ୂ\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 3.92, Train BLEU: 0.00, Val BLEU: 19.63, Minutes Elapsed: 5.80\n","Sampling from val predictions...\n","Source: The eyes of your understanding being enlightened ; that ye\n","Reference: ମ ୁଁ ପ ୍ ର ା ର ୍ ଥନ\n","Model: <SOS> ମ ୍ ନ ୀ ର େ ନ ୀ ଥନ\n","\n","Source: For Ahaz took away a portion out of the house\n","Reference: ଆହସ ୍ ସଦ ା ପ ୍ ରଭ ୁ ଙ\n","Model: <SOS> ଯ ି ଯ ି ପ ୍ େ ି ି\n","\n","Source: The families of the sons of Kohath shall pitch on\n","Reference: କହ ା ତ ୀ ଯ ସନ ୍ ତ ା\n","Model: <SOS> କହ ି ନ ି ି ି ି ଧ ୍\n","\n","Model training completed in 5 minutes with 3.03 best validation loss and 20.98 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRGA3FEAAobP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e062b704-6049-430a-c700-2f72c32e650a","executionInfo":{"status":"ok","timestamp":1589507529253,"user_tz":240,"elapsed":313826,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}}},"source":["# freeze encoder\n","for p in model.encoder.parameters():\n","    p.requires_grad = False\n","encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n","model_od, results_od = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":358,"outputs":[{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.66, Train BLEU: 0.00, Val BLEU: 0.03, Minutes Elapsed: 0.01\n","Sampling from val predictions...\n","Source: And the LORD spake unto Moses , saying , <EOS>\n","Reference: ଅନନ ୍ ତର ସଦ ା ପ ୍ ରଭ ୁ\n","Model: <SOS> ଶଗ େ େ େ େ ୍ େ େ େ\n","\n","Source: <UNK> , <UNK> <UNK> , <UNK> , <UNK> - <UNK>\n","Reference: ବଙ ୍ <UNK> ା <UNK> , ବ ା ଣପ\n","Model: <SOS> ମତଇ ଆକ ଆକ ଟଆମ ଭଧ ଭଧ ଭଧ ଭଧ ଭଧ\n","\n","Source: <UNK> <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ଇଲ େ କ ୍ ଟ ୍ ର ୋ ନ\n","Model: <SOS> ଥଲବ ଥଲବ ଲମକକ ଲମକକ ବବକ ବବକ ବବକ ବବକ ବବକ\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.50, Train BLEU: 0.00, Val BLEU: 10.75, Minutes Elapsed: 0.53\n","Sampling from val predictions...\n","Source: And Ephraim their father mourned many days , and his\n","Reference: ଇଫ ୍ ରଯ ି ମ , ଏତସର ଓ ଇଲ\n","Model: <SOS> ତ େ ଶ ୍ ତ ା ନ େ ବ\n","\n","Source: Seeing that Abraham shall surely become a great and mighty\n","Reference: ଅବ ୍ ରହ ା ମଠ ା ର ୁ ଏକ\n","Model: <SOS> ତ େ ର ା ତ ୍ ତ େ େ\n","\n","Source: They answered him , We be Abraham ' s seed\n","Reference: ଯ ି ହ ୂ ଦ ୀ ମ ା ନ\n","Model: <SOS> ତ ି ଉ ୂ ଦ ା ମ ା ନ\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.22, Train BLEU: 0.00, Val BLEU: 15.24, Minutes Elapsed: 1.05\n","Sampling from val predictions...\n","Source: But he that lacketh these things is blind , and\n","Reference: ଯଦ ି କ ୌ ଣସ ି ଲ ୋ କଠ\n","Model: <SOS> କ ି ତ ୍ ନ ି ତ ୍ କମ\n","\n","Source: He poureth contempt upon princes , and <UNK> the strength\n","Reference: ପରମ େ ଶ ୍ ବର ନ େ ତ ା\n","Model: <SOS> ପରମ େ ଶ ୍ ବର ୍ ୍ ଜ ୍\n","\n","Source: I went down to the <UNK> of the mountains ;\n","Reference: ମ ୁଁ ସମ ୁ ଦ ୍ ରର ତଳ ଦ\n","Model: <SOS> ମ ୁଁ ତ ୁ ନଙ ୍ ର ା ା\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.10, Train BLEU: 0.00, Val BLEU: 17.26, Minutes Elapsed: 1.57\n","Sampling from val predictions...\n","Source: Which maketh <UNK> , <UNK> , and <UNK> , and\n","Reference: ପରମ େ ଶ ୍ ବର ନକ ୍ ଷତ ୍\n","Model: <SOS> ତ େ ଶ ୍ ବର ତ ୍ କ ୍\n","\n","Source: And there was no passover like to that kept in\n","Reference: ଭବ ି ଷ ୍ ଯତ ୍ ବକ ୍ ତ\n","Model: <SOS> ତ ି ଷ ୍ ଟ ା େ ୍ ତ\n","\n","Source: Seeing that Abraham shall surely become a great and mighty\n","Reference: ଅବ ୍ ରହ ା ମଠ ା ର ୁ ଏକ\n","Model: <SOS> ତ େ ରହ ା ମ ମ ତ େ ୍\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.04, Train BLEU: 0.00, Val BLEU: 18.23, Minutes Elapsed: 2.09\n","Sampling from val predictions...\n","Source: Give to him that asketh thee , and from him\n","Reference: ଯଦ ି କହ େି ତ ୁ ମ ୍ ଭକ\n","Model: <SOS> ତ େ ଜଣ େ ବ ା ମ ୍ ଭ\n","\n","Source: Give to him that asketh thee , and from him\n","Reference: ଯଦ ି କହ େି ତ ୁ ମ ୍ ଭକ\n","Model: <SOS> ତ େ ଜଣ େ ବ ା ମ ୍ ଭ\n","\n","Source: <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ଭ ୌ ଗ ୋ ଳ ି କ ଚ ି\n","Model: <SOS> ପ ି ଇ ି ର ି ପ ୍ ର\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 3.02, Train BLEU: 0.00, Val BLEU: 18.86, Minutes Elapsed: 2.61\n","Sampling from val predictions...\n","Source: Then said I , Woe is me ! for I\n","Reference: ସ େ ତବ େେ ଳ େ ମ ୁଁ ଭୟଭ\n","Model: <SOS> ତ ା' ତ ି ଳ େ ମ ୁଁ ତ\n","\n","Source: But unto the Son he saith , Thy throne ,\n","Reference: କ ି ନ ୍ ତ ୁ ପରମ େ ଶ\n","Model: <SOS> କ ି ନ ୍ ତ ୁ ତ ୁ ଶ\n","\n","Source: For in that he died , he died unto sin\n","Reference: ଯ େ ତବ େେ ଳ େ ଖ ୍ ର\n","Model: <SOS> ଯ େ ଶ ଁ ଳ େ ତ ୁ ର\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 3.03, Train BLEU: 0.00, Val BLEU: 19.67, Minutes Elapsed: 3.14\n","Sampling from val predictions...\n","Source: <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ଜଳ ସମ ୍ ପଦ <EOS> <PAD> <PAD> <PAD> <PAD>\n","Model: <SOS> ପ ି ପ ନ ୍ ର ି ବ ୍\n","\n","Source: For the LORD ' s portion is his people ;\n","Reference: ସଦ ା ପ ୍ ରଭ ୁ ଙ ୍ କ\n","Model: <SOS> କ ା ପ ୍ ରଭ ୁ ଙ ି କ\n","\n","Source: Looking for and <UNK> unto the coming of the day\n","Reference: ପ ୍ ରଭ ୁ ଙ ୍ କ ଦ ି\n","Model: <SOS> ତ ୀ ର ୁ ଙ ୀ କ ପ ି\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 3.07, Train BLEU: 0.00, Val BLEU: 20.10, Minutes Elapsed: 3.66\n","Sampling from val predictions...\n","Source: Thus saith the LORD ; <UNK> thy voice from weeping\n","Reference: ସଦ ା ପ ୍ ରଭ ୁ ଏହ ି କଥ\n","Model: <SOS> ସଦ ା ପ ୍ ରଭ ୁ ଏହ ି କଥ\n","\n","Source: Give to him that asketh thee , and from him\n","Reference: ଯଦ ି କହ େି ତ ୁ ମ ୍ ଭକ\n","Model: <SOS> ସ େ କ େ ବ ୁ ମ ୍ ଭ\n","\n","Source: Hattush , Shebaniah , Malluch , <EOS> <PAD> <PAD> <PAD>\n","Reference: ହଟ ୂ ଶ ୍, ଶବନ ି ଯ , ମଲ\n","Model: <SOS> ପ ା ଲ ୍ କ ି ବ ୍ ର\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.14, Train BLEU: 0.00, Val BLEU: 20.15, Minutes Elapsed: 4.18\n","Sampling from val predictions...\n","Source: Blessed are they which are persecuted for righteousness ' sake\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କ ଇଚ ୍\n","Model: <SOS> ତ ୍ ଶ ୍ ବର ୍ କ ବ ି\n","\n","Source: <UNK> <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ବ ି ଦ ୍ ୟ ା ଳୟ ଏବ ଂ\n","Model: <SOS> ତ ି ଯବସ ୍ ବ ା ର ା କ\n","\n","Source: But the manifestation of the Spirit is given to every\n","Reference: ପ ୍ ର େ ତ ୍ ୟକକ ଲ ୋ\n","Model: <SOS> କ ି ର ି ତ ୍ ୟକକ ବ ୍\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.24, Train BLEU: 0.00, Val BLEU: 20.21, Minutes Elapsed: 4.70\n","Sampling from val predictions...\n","Source: And she said , Let thine handmaid find grace in\n","Reference: ତ ା' ପର େ ସ େ ଉତ ୍ ତର\n","Model: <SOS> ତ େ ପର େ ତ ୁ ତ ୍ ତର\n","\n","Source: And he brake in pieces the images , and cut\n","Reference: ନବ ା ଟଙ ୍ କ ପ ୁ ତ ୍\n","Model: <SOS> ତ େି ଖଦ ୍ କ ପ ୁ ତ ୍\n","\n","Source: For every high priest is ordained to offer gifts and\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କ ୁ ଦ\n","Model: <SOS> ତ େ ଶ ୍ ବର ନ କ ବ ୍\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 3.34, Train BLEU: 0.00, Val BLEU: 20.33, Minutes Elapsed: 5.22\n","Sampling from val predictions...\n","Source: And when the day of Pentecost was fully come ,\n","Reference: ଯ େ ତବ େେ ଳ େ ପ େ ଣ\n","Model: <SOS> ତ ି ତବ େେ ଳ େ ବ ୍ ର\n","\n","Source: Yea , every pot in Jerusalem and in Judah shall\n","Reference: ସମସ ୍ ତ ଜଳପ ା ତ ୍ ର ୟ\n","Model: <SOS> ପରମ ି ତ ୍ ୍ କ ଓ ମ ୍\n","\n","Source: Woe unto you , scribes and Pharisees , hypocrites !\n","Reference: \" ର େ କପଟ ୀ ଯ ି ହ ୂ\n","Model: <SOS> ହ ା େ କପଟ ୍ ଧର ୍ ହ ା\n","\n","Model training completed in 5 minutes with 3.02 best validation loss and 20.33 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mjECWcaZA0_u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f45e702f-148f-44e3-a41b-8d71dfb71e67","executionInfo":{"status":"ok","timestamp":1589508037589,"user_tz":240,"elapsed":345971,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}}},"source":["# freeze embeddings\n","for i,p in enumerate(model.encoder.parameters()):\n","    p.requires_grad = False\n","    break\n","encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n","model_od, results_od = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":362,"outputs":[{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.67, Train BLEU: 0.00, Val BLEU: 0.02, Minutes Elapsed: 0.01\n","Sampling from val predictions...\n","Source: Draw thee waters for the siege , fortify thy strong\n","Reference: ଅବର ୋ ଧ ସମୟ ନ ି ମନ ୍ ତ\n","Model: <SOS> ଓନନ । । । ଉଥଲ ଉଥଲ ମଫର ମଫର ମଫର\n","\n","Source: Blessed are they which are persecuted for righteousness ' sake\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କ ଇଚ ୍\n","Model: <SOS> ନଆଣ ବହତ ବହତ ଲୟଲରସଗ ଦହ ଦହ ଦହ ଶକଟ ଶକଟ\n","\n","Source: And the four and twenty elders , which sat before\n","Reference: ତ ା' ପର େ ଚବ ି ଶ ଜଣ ପ\n","Model: <SOS> ମତର େ େ େ େ ୍ ଚପକ େ ବନପଶକ\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.46, Train BLEU: 0.00, Val BLEU: 12.92, Minutes Elapsed: 0.58\n","Sampling from val predictions...\n","Source: He that heareth you heareth me ; and he that\n","Reference: \" ଯ େ ତବ େେ ଳ େ କ ୌ\n","Model: <SOS> ତ େ େ ଉ ଁ ଳ େ ମ ୁ\n","\n","Source: O LORD , correct me , but with judgment ;\n","Reference: ହ େ ସଦ ା ପ ୍ ରଭ ୁ, ଆମ\n","Model: <SOS> ତ େ ଦ ା ପ ୍ ରଭ ୁ ତ\n","\n","Source: The LORD of hosts hath sworn by himself , saying\n","Reference: ସ ୈ ନ ୍ ଯ ା ଧ ି ପତ\n","Model: <SOS> ତ ା ତ ୍ ତ ୁ ୁ ୁ ନ\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.16, Train BLEU: 0.00, Val BLEU: 16.83, Minutes Elapsed: 1.15\n","Sampling from val predictions...\n","Source: In <UNK> , <UNK> <UNK> become a <UNK> <UNK> ,\n","Reference: ବସ ୍ ତ ୁ ତ ଃ <UNK> ଼ି ଶ\n","Model: <SOS> ସହ ା ତ ା ର ୍ ମ ା ି\n","\n","Source: There is no healing of thy bruise ; thy wound\n","Reference: ହ େ ନ ୀ ନ ି ବ ୀ, ତ\n","Model: <SOS> ତ ୁ ଲ ୁ ଜ ୁ ତ ତ ଶ\n","\n","Source: And in that day it shall come to pass ,\n","Reference: ସହ େି ସମୟର େ ଯ ା କ ୁ ବର\n","Model: <SOS> ସହ େି ସମୟର ି ତ ି ଉ ା ବ\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.05, Train BLEU: 0.00, Val BLEU: 19.00, Minutes Elapsed: 1.72\n","Sampling from val predictions...\n","Source: <UNK> in <UNK> <UNK> <UNK> <UNK> , the <UNK> of\n","Reference: ପର େ ପର େ <UNK> <UNK> େ ଆସ ି\n","Model: <SOS> ସମ ା ବ ା ତ ା ତ ତ ି\n","\n","Source: Then hear thou in heaven , and forgive the sin\n","Reference: ତବ େେ ତ ୁ ମ ୍ ଭ େ ସ\n","Model: <SOS> ତ ୁ ତ ୁ ମ ୍ ଭ େ ତ\n","\n","Source: <UNK> the <UNK> King of <UNK> , invaded <UNK> in\n","Reference: ଖ ୍ ର ୀ ଷ ୍ ଟପ ୂ ର\n","Model: <SOS> ତ ୁ ର ୀ ଷ ୍ ଟ ୍ ୍\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.02, Train BLEU: 0.00, Val BLEU: 20.51, Minutes Elapsed: 2.30\n","Sampling from val predictions...\n","Source: <UNK> is a <UNK> language of before Christ . <UNK>\n","Reference: <UNK> ି ଆ ଭ ା ଷ ା ଖ ୍\n","Model: <SOS> ତ ା ତ ୍ େ ଇ େ ର େ\n","\n","Source: And he made the middle bar to shoot through the\n","Reference: ମଧ ୍ ଯସ ୍ ଥ ି ତ ଅର ୍\n","Model: <SOS> ସ ା' ଯ ପ ୁ ପ େ ା େ\n","\n","Source: He that <UNK> in pieces is come up before thy\n","Reference: କହ େି ଜଣ େ ତ ୁ ମ ୍ ଭମ\n","Model: <SOS> ଯ େ ବ ୁ ବ ୁ ମ ୍ ଭ\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 3.10, Train BLEU: 0.00, Val BLEU: 20.93, Minutes Elapsed: 2.87\n","Sampling from val predictions...\n","Source: And she said , Let thine handmaid find grace in\n","Reference: ତ ା' ପର େ ସ େ ଉତ ୍ ତର\n","Model: <SOS> ସ ା' ପର େ ସ ୁ ତ ୁ ତର\n","\n","Source: Which were cut down out of time , whose foundation\n","Reference: ସହ େି ଦ ୁ ଷ ୍ ଟମ ା ନ\n","Model: <SOS> ସମ ା ସ ୁ ନ ୍ ଟ ଲ ୁ\n","\n","Source: To whom also Abraham gave a tenth part of all\n","Reference: ୟ ୁ ଦ ୍ ଧ ର େ ଜ ି\n","Model: <SOS> ଏହ ି ହ ା ଧ ା ା ଜ ା\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 3.27, Train BLEU: 0.00, Val BLEU: 20.38, Minutes Elapsed: 3.44\n","Sampling from val predictions...\n","Source: For which cause both thou and all thy company are\n","Reference: ତ ୁ ମ ୍ ଭ େ ଓ ତ ୁ\n","Model: <SOS> ତ ୁ ମ ୍ ଭ େ ତ ୁ ୁ\n","\n","Source: He is green before the sun , and his branch\n","Reference: ସହ େି ବ ୍ ଯକ ୍ ତ ି ଏକ\n","Model: <SOS> ସ େ ପ ା ଶ ୍ ତ ି ହ\n","\n","Source: And Ephraim their father mourned many days , and his\n","Reference: ଇଫ ୍ ରଯ ି ମ , ଏତସର ଓ ଇଲ\n","Model: <SOS> ସହ ି ରଯ ି ମ ତ ି ି ତ\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 3.50, Train BLEU: 0.00, Val BLEU: 19.79, Minutes Elapsed: 4.01\n","Sampling from val predictions...\n","Source: Keep yourselves in the love of God , looking for\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କର ପ ୍\n","Model: <SOS> ପରମ େ ଶ ୍ ବର ହ କ ହ ା\n","\n","Source: <UNK> with girdles upon their loins , exceeding in dyed\n","Reference: ସମ ା ନଙ ୍ କ େ କଟ ୀ ର\n","Model: <SOS> ଯ ି ନ େେ କ େ ଭ ଭ ି\n","\n","Source: <UNK> <UNK> <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ବ ି ଦ ୍ ୟ ା ଳୟ ଏବ ଂ\n","Model: <SOS> ନ ି ଶ ୍ ର ା ର ା ଦ\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.59, Train BLEU: 0.00, Val BLEU: 20.47, Minutes Elapsed: 4.58\n","Sampling from val predictions...\n","Source: It <UNK> also <UNK> its <UNK> strength and <UNK> <UNK>\n","Reference: କଳ ି ଙ ୍ ଗ ( <UNK> ଼ି ଶ\n","Model: <SOS> ନ ି ର ି କ ବ ି ି ି\n","\n","Source: Simon Peter , a servant and an apostle of Jesus\n","Reference: ଯ ୀ ଶ ୁ ଖ ୍ ର ୀ ଷ\n","Model: <SOS> ପ ି ତବ ୁ ପ ା ର ା ଷ\n","\n","Source: <UNK> <UNK> <UNK> <UNK> , <UNK> <UNK> <UNK> <UNK> ,\n","Reference: କବ ି ସମ ୍ ର ା ଟ ଉପ େ\n","Model: <SOS> ନ ା ର ୍ ନ ା ର ା ଦ\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.76, Train BLEU: 0.00, Val BLEU: 20.11, Minutes Elapsed: 5.17\n","Sampling from val predictions...\n","Source: Then David said unto the messenger , Thus shalt thou\n","Reference: ଦ ା ଉଦ ଦ ୂ ତକକ ୍ ସ ୍\n","Model: <SOS> ଦ ା ଉଦ ତ ୍ ର ୍ ନ ୍\n","\n","Source: And Joseph saw his brethren , and he knew them\n","Reference: ଯ ୋ ଷଫ େ ସମ ା ନଙ ୍ କ\n","Model: <SOS> ଯ ୋ ଷଫ େ ତ ା ନଙ ୍ କ\n","\n","Source: And I beheld , and I heard the voice of\n","Reference: ତ ା' ପର େ ମ ୁଁ ଦ େ ଖ\n","Model: <SOS> ମ ୁଁ ପର େ ମ ୁଁ ମ ୁଁ ଖ\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 4.02, Train BLEU: 0.00, Val BLEU: 18.90, Minutes Elapsed: 5.76\n","Sampling from val predictions...\n","Source: And a letter unto Asaph the keeper of the king\n","Reference: ର ା ଜ ା ଆସଫ ୍ ଙ ୍ କ\n","Model: <SOS> ଆଉ ି ଜ ି ହର ି ନ ନ ି\n","\n","Source: <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ସ ଂ ସଦ ୀ ୟ କ ା ର ୍\n","Model: <SOS> ଭବ ି ଥ ି ପ ୍ ୍ ବ ୍\n","\n","Source: Verily , verily , I say unto you , The\n","Reference: ମ ୁଁ ତ ୁ ମ ୍ ଭକ ୁ ସତ\n","Model: <SOS> ମ ୁଁ ପ ା ମ ୍ ଭକ ୁ ସତ\n","\n","Model training completed in 5 minutes with 3.02 best validation loss and 20.93 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FtDlobl2CpQJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"729a4ca4-8f9d-4d63-a942-1384b5866850","executionInfo":{"status":"ok","timestamp":1589508689871,"user_tz":240,"elapsed":344781,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}}},"source":["# freeze rnn\n","for i,p in enumerate(model.encoder.parameters()):\n","    if i==0: continue\n","    else:p.requires_grad = False\n","encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n","model_od, results_od = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":363,"outputs":[{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.67, Train BLEU: 0.00, Val BLEU: 0.03, Minutes Elapsed: 0.01\n","Sampling from val predictions...\n","Source: The pride of thine heart hath deceived thee , thou\n","Reference: ତ ୁ ମ ୍ ଭର ଗର ୍ ବ ତ\n","Model: <SOS> ଟନର ହରଣକ ୍ ୍ ଶ ରଣର ରଣର ଳୟର ଭଷ\n","\n","Source: The LORD will not spare him , but then the\n","Reference: ସଦ ା ପ ୍ ରଭ ୁ ତ ା ହ\n","Model: <SOS> େ େ ୍ ୍ ଥରପ ପରମ ପରମ ପରମ ୍?\n","\n","Source: <UNK> , <UNK> <UNK> ( <UNK> ) <EOS> <PAD> <PAD>\n","Reference: <UNK> . <UNK> କ ି. ମ ି. ( <UNK>\n","Model: <SOS> ନତକ ଅଦର ଅଦର ନବର ୋ- ୋ- ୋ- ୋ- ୋ-\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.56, Train BLEU: 0.00, Val BLEU: 10.30, Minutes Elapsed: 0.58\n","Sampling from val predictions...\n","Source: And a letter unto Asaph the keeper of the king\n","Reference: ର ା ଜ ା ଆସଫ ୍ ଙ ୍ କ\n","Model: <SOS> ତ େ ଜ ା ବ େ େ ବ କ\n","\n","Source: Nevertheless we made our prayer unto our God , and\n","Reference: ମ ା ତ ୍ ର ଆମ ୍ ଭମ ା\n","Model: <SOS> ତ ି ତ େ ମ େ ୍ ଭ େ\n","\n","Source: Thus shall he do in the most strong holds with\n","Reference: ସ େ ବ ି ଦ େ ଶ ୀ ଯ\n","Model: <SOS> ତ େ ତ ି ଶ ୍ ର େ ବର\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.22, Train BLEU: 0.00, Val BLEU: 15.76, Minutes Elapsed: 1.15\n","Sampling from val predictions...\n","Source: This is the inheritance of the tribe of the children\n","Reference: ଏହ ି ଦ େ ଶ ୟ ି ହକ ୍\n","Model: <SOS> ତ ି ପର ୍ ବ ି ବ ୍ ା\n","\n","Source: Yet was she carried away , she went into captivity\n","Reference: କ ି ନ ୍ ତ ୁ ନ ୋ- ଆମ\n","Model: <SOS> ତ ି ନ ୍ ତ ୁ ତ ୁ ଜ\n","\n","Source: To whom also Abraham gave a tenth part of all\n","Reference: ୟ ୁ ଦ ୍ ଧ ର େ ଜ ି\n","Model: <SOS> ଯ େ ହ ୍ ବ ା ର ଜ ୍\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.07, Train BLEU: 0.00, Val BLEU: 18.35, Minutes Elapsed: 1.72\n","Sampling from val predictions...\n","Source: And there appeared in the cherubims the form of a\n","Reference: ମନ ୁ ଷ ୍ ଯର ହ ା ତପର ି\n","Model: <SOS> ସହ େି ଦ ୍ ଟ ା ୍ ଲ ୁ\n","\n","Source: How is the gold become dim ! how is the\n","Reference: ଦ େ ଖ , ସ ୁ ବର ୍ ଣ\n","Model: <SOS> ତ ି ବ ି ର ୀ ତ ୍ ତ\n","\n","Source: And it shall come to pass , that when they\n","Reference: ସମସ ୍ ତ ଯ ା ଜକମ ା ନ େ\n","Model: <SOS> ତ ି ତ ଲ ୋ ତବ ା ନ େ\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 2.99, Train BLEU: 0.00, Val BLEU: 20.02, Minutes Elapsed: 2.30\n","Sampling from val predictions...\n","Source: And the LORD stirred up an adversary unto Solomon ,\n","Reference: ଅନନ ୍ ତର ସଦ ା ପ ୍ ରଭ ୁ\n","Model: <SOS> ପ ା ତର ସଦ ା ପ ୍ ରଭ ୁ\n","\n","Source: <UNK> of <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ମନ ୍ ତ ୍ ର ୀ ପର ି ଷଦ\n","Model: <SOS> ସ ି ଷ ି ର ୀ ୁ ୁ କ\n","\n","Source: And the land be subdued before the LORD : then\n","Reference: ଯ େ ତବ େେ ଳ େ ସହ େି ଦ\n","Model: <SOS> ପ ୍ ଶ ଁ ଳ େ ପ ୍ ସ\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 2.96, Train BLEU: 0.00, Val BLEU: 21.13, Minutes Elapsed: 2.87\n","Sampling from val predictions...\n","Source: Now after many years I came to bring alms to\n","Reference: \" ମ ୁଁ ବହ ୁ ତ ବର ୍ ଷ\n","Model: <SOS> ମ ୍ େ ତ ୍ ତ ି ି ତ\n","\n","Source: And I knew that thou hearest me always : but\n","Reference: ମ ୁଁ ଜ ା ଣ େ ଯ େ, ତ\n","Model: <SOS> ମ ୁ ତ ୁ ଣ େ ତ ୁ ଉ\n","\n","Source: In <UNK> , <UNK> an <UNK> state <UNK> was <UNK>\n","Reference: ସର ୍ ବଶ େ ଷର େ <UNK> େ ତତ\n","Model: <SOS> ସହ ା ବଦ ା କ ା ହ ା କ\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 2.96, Train BLEU: 0.00, Val BLEU: 21.70, Minutes Elapsed: 3.45\n","Sampling from val predictions...\n","Source: And Elijah said unto her , Fear not ; go\n","Reference: ଏଲ ି ଯ ସହ େି ବ ି ଧବ ା\n","Model: <SOS> ତ ି ଯ ତ ା ସ ୍ ଶ ୍\n","\n","Source: And there was again a battle in <UNK> with the\n","Reference: ଏହ ା ପର େ ପକ ୍ ସ ୍ ଟନର\n","Model: <SOS> ସହ େି ପର ି ବ େ ସ ୍ ଥ\n","\n","Source: <UNK> is the one of the <UNK> <UNK> languages of\n","Reference: <UNK> ଼ି ଆ ଭ ା ରତର ଅନ ୍ ୟତମ\n","Model: <SOS> ନ ା କ େ ା ବ େ େ ୟ\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 2.99, Train BLEU: 0.00, Val BLEU: 22.34, Minutes Elapsed: 4.03\n","Sampling from val predictions...\n","Source: Again , Jesse made seven of his sons to pass\n","Reference: ଏହ ି ର ୂ ପ େ ୟ ି ଶ\n","Model: <SOS> ତ ା ପର ି ପ େ ତ େ ର\n","\n","Source: Then Balak the son of Zippor , king of Moab\n","Reference: ଏହ ା ପର େ ସ ି ପ ୍ ପ\n","Model: <SOS> ତ ା ପର େ ବ ା ନ ା ର\n","\n","Source: Thou shalt make them as a fiery oven in the\n","Reference: ତ ୁ ମ ୍ ଭ େ ଆପଣ ା ର\n","Model: <SOS> ତ ୁ ମ ୍ ଭ େ ସମ ା ର\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.07, Train BLEU: 0.00, Val BLEU: 22.65, Minutes Elapsed: 4.60\n","Sampling from val predictions...\n","Source: And I have oxen , and asses , flocks ,\n","Reference: ମ ା ର େ ଗ ା ଈଗ ୁ ଡ\n","Model: <SOS> ମ ୁ ପ େ ପ ୍ ଟ ୁ ୍\n","\n","Source: Where is the dwelling of the lions , and the\n","Reference: ସହ େି ସ ିଂ ହଗ ୁ ମ ୍ ଫ\n","Model: <SOS> ସ ା ସ ୍ ତ ା ନ ୍ ଭ\n","\n","Source: Again , Jesse made seven of his sons to pass\n","Reference: ଏହ ି ର ୂ ପ େ ୟ ି ଶ\n","Model: <SOS> ତ େ ପର ୂ ପ େ ର େ ର\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.20, Train BLEU: 0.00, Val BLEU: 22.17, Minutes Elapsed: 5.17\n","Sampling from val predictions...\n","Source: And the coast of Og king of Bashan , which\n","Reference: ସମ ା ନ େେ ମଧ ୍ ଯ ବ ା\n","Model: <SOS> ର ା ନଙ ୍ ର ା ଯ ଯ ା\n","\n","Source: For if after they have escaped the <UNK> of the\n","Reference: ସହ େି ଲ ୋ କମ ା ନଙ ୍ କ\n","Model: <SOS> ଯଦ ି ଲ ୁ କମ ା ନ େ କ\n","\n","Source: That the waters which came down from above stood and\n","Reference: ତ ା' ପର େ ଉପରକ ୍ ସ ୍ ଟ\n","Model: <SOS> ଏହ ି ପର େ ଦ ି ବ ି ି\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 3.35, Train BLEU: 0.00, Val BLEU: 21.71, Minutes Elapsed: 5.74\n","Sampling from val predictions...\n","Source: The horseman lifteth up both the bright sword and the\n","Reference: ସ ୈ ନ ୍ ଯମ ା ନ େ ଅଶ\n","Model: <SOS> ପ ୍ ବ ୍ ଯମ ା ନ େ ନ\n","\n","Source: For all people will walk every one in the name\n","Reference: ଅନ ୍ ୟ ଗ ୋ ଷ ୍ ଠ ୀ\n","Model: <SOS> ସମସ ୍ ୟ ୀ ୋ ଟ ୍ ଠ ୀ\n","\n","Source: The sons of Reuel ; Nahath , Zerah , Shammah\n","Reference: ର ୁ ଯଲଙ ୍ କ େ ର ପ ୁ\n","Model: <SOS> ଏହ ା ଜ ୍ କ େ ପ ୍ ୁ\n","\n","Model training completed in 5 minutes with 2.96 best validation loss and 22.65 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XN6tWxfnG8OI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"aae35961-d8d7-42ec-a313-43d34d1245ef","executionInfo":{"status":"ok","timestamp":1589509442377,"user_tz":240,"elapsed":355058,"user":{"displayName":"Zihao Guo","photoUrl":"","userId":"12502228106172909245"}}},"source":["# not freeze\n","encoder = model.encoder\n","\n","# without attention \n","decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n","                        targ_vocab_size=6246, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN)\n","\n","model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n","model_od, results_od = train_and_eval(\n","    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n","    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=False, save_to_log=False, \n","    lazy_eval=True, print_attn=False, inspect_samples=3)"],"execution_count":371,"outputs":[{"output_type":"stream","text":["Epoch: 0.00, Train Loss: 0.00, Val Loss: 8.68, Train BLEU: 0.00, Val BLEU: 0.10, Minutes Elapsed: 0.01\n","Sampling from val predictions...\n","Source: And turning the cities of Sodom and Gomorrha into ashes\n","Reference: ପରମ େ ଶ ୍ ବର ଦଣ ୍ ଡ ସ\n","Model: <SOS> ଣଯଠ ଣଯଠ ୍ ୍ ବର ୍ ୍ ଡମ ଡମ\n","\n","Source: There are also <UNK> bodies , and bodies <UNK> :\n","Reference: ସ ୍ ବର ୍ ଗ ୀ ୟ ଶର ୀ\n","Model: <SOS> ଯସବ ପରମ େ, ୍ ୍ ୍ ଲମକକ ଗ ଗ\n","\n","Source: <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ପ ୍ ରସ ି ଦ ୍ ଧ ବ ୍\n","Model: <SOS> ନଉଥ ମକଙ ମକଙ ରହର ଇବନ ଇବନ ଇବନ ଇବନ ଇବନ\n","\n","Epoch: 1.00, Train Loss: 0.00, Val Loss: 3.57, Train BLEU: 0.00, Val BLEU: 10.58, Minutes Elapsed: 0.60\n","Sampling from val predictions...\n","Source: Then hear thou from heaven thy dwelling place , and\n","Reference: ତବ େେ ତ ୁ ମ ୍ ଭ େ ସ\n","Model: <SOS> ତ େ ପର େ ମ ୍ ଭ େ ତ\n","\n","Source: The most <UNK> <UNK> of this <UNK> can be seen\n","Reference: ଏହ ି ସମୟର େ ଗଢ ି ଉଠ ି ଥ\n","Model: <SOS> ତ େ ପର ୍ ତ େ ର ା େ\n","\n","Source: And if any man think that he knoweth any thing\n","Reference: କ ି ନ ୍ ତ ୁ ପ ୍ ରମ\n","Model: <SOS> ତ େ ନ ୍ ତ ୁ ତ େ ର\n","\n","Epoch: 2.00, Train Loss: 0.00, Val Loss: 3.23, Train BLEU: 0.00, Val BLEU: 15.48, Minutes Elapsed: 1.19\n","Sampling from val predictions...\n","Source: And it came to pass , that when they had\n","Reference: ପଙ ୍ ଗପ ା ଳ ଦଳ ର ା ଜ\n","Model: <SOS> ଯ େ ପର ା ର େ ି ର ଜ\n","\n","Source: It <UNK> also <UNK> its <UNK> strength and <UNK> <UNK>\n","Reference: କଳ ି ଙ ୍ ଗ ( <UNK> ଼ି ଶ\n","Model: <SOS> ତ ି ତ ୍ କ ୁ ି ତ ି\n","\n","Source: And Naomi had a kinsman of her husband ' s\n","Reference: ବ ୈ ଥ ି ଲହମ େ ର େ ଜଣ\n","Model: <SOS> ତ ି ଶ ୍ ବ ା ବ େ ଜ\n","\n","Epoch: 3.00, Train Loss: 0.00, Val Loss: 3.08, Train BLEU: 0.00, Val BLEU: 18.03, Minutes Elapsed: 1.78\n","Sampling from val predictions...\n","Source: But if they say thus , Come up unto us\n","Reference: ଯଦ ି ପଲ େ ଷ ୍ ଟ ୀ ୟମ\n","Model: <SOS> କ ି ତ ୁ ନ ି ଟ ା ତ\n","\n","Source: But grow in grace , and in the knowledge of\n","Reference: କ ି ନ ୍ ତ ୁ ଆମ ୍ ଭ\n","Model: <SOS> କ ି ନ ୍ ତ ୁ ତ ି ଭ\n","\n","Source: All the words of my mouth are in righteousness ;\n","Reference: ମ ୁଁ ଯ ା ହ ା କ ହ େ,\n","Model: <SOS> ମ ୍ ତ ା ଉ ା ଦ ୁ ବ\n","\n","Epoch: 4.00, Train Loss: 0.00, Val Loss: 3.00, Train BLEU: 0.00, Val BLEU: 19.76, Minutes Elapsed: 2.37\n","Sampling from val predictions...\n","Source: And he put forth the form of an hand ,\n","Reference: ତ ା' ପ ର େ ଆମ ୍ ଭ େ\n","Model: <SOS> ତ ା' ପର େ େ ସ େ ଭ େ\n","\n","Source: And he made the middle bar to shoot through the\n","Reference: ମଧ ୍ ଯସ ୍ ଥ ି ତ ଅର ୍\n","Model: <SOS> ତ ା' ଯ ସହ େ ୍ ପ ା େ\n","\n","Source: And he will destroy in this mountain the face of\n","Reference: ସମସ ୍ ତ ଗ ୋ ଷ ୍ ଠ ୀ\n","Model: <SOS> ତ ି ତ େ ି ଟ ି ଟ ୍\n","\n","Epoch: 5.00, Train Loss: 0.00, Val Loss: 2.96, Train BLEU: 0.00, Val BLEU: 21.35, Minutes Elapsed: 2.96\n","Sampling from val predictions...\n","Source: <UNK> , Meshullam , <UNK> , <EOS> <PAD> <PAD> <PAD>\n","Reference: ମଗ ୍ ପ ୀ ଯସ , ମଶ ୁ ଲ\n","Model: <SOS> ପ ା ର ୀ ର ା ର ା ର\n","\n","Source: No man that hath a blemish of the seed of\n","Reference: ହ ା ର ୋ ଣ ଯ ା ଜକର ବ\n","Model: <SOS> ଯ େ ଲ ୋ ା କ ା ଉ ା\n","\n","Source: And when they had fasted and prayed , and laid\n","Reference: ତ େ ଣ ୁ ସମ ା ନ େେ ଉପବ\n","Model: <SOS> ସମ ା ପର ୁ ସମ ା ନ େେ କ\n","\n","Epoch: 6.00, Train Loss: 0.00, Val Loss: 2.97, Train BLEU: 0.00, Val BLEU: 22.02, Minutes Elapsed: 3.55\n","Sampling from val predictions...\n","Source: He shall <UNK> his <UNK> : they shall stumble in\n","Reference: ସ େ ତ ା ଙ ୍ କର ଅଧ ି\n","Model: <SOS> ସ େ ଲ ୋ ହ ା କ ୁ ୋ\n","\n","Source: Sixteen years old was Uzziah when he began to reign\n","Reference: ଉଷ ି ୟ ର ା ଜ ା ହବ ୋ\n","Model: <SOS> ଯ ି ହ ବ ି ଶ ା ହ ି\n","\n","Source: <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n","Reference: ମ ୂ <UNK> ୍ ସ <EOS> <PAD> <PAD> <PAD>\n","Model: <SOS> ପ ି ପ ୍ କ ପ ର ମ ର\n","\n","Epoch: 7.00, Train Loss: 0.00, Val Loss: 3.00, Train BLEU: 0.00, Val BLEU: 22.26, Minutes Elapsed: 4.14\n","Sampling from val predictions...\n","Source: And if thy right hand offend thee , cut it\n","Reference: ଯଦ ି ତ ୁ ମ ୍ ଭର ଡ ା\n","Model: <SOS> ଯଦ ି ତ ୁ ମ ୍ ଭର ପ ା\n","\n","Source: For his sins which he sinned in doing evil in\n","Reference: ସ ି ମ ୍ ର ି ତ ା' ର\n","Model: <SOS> ପରମ େ ବର ୍ ନ ି ୋ ର ି\n","\n","Source: And said to his servant , Go up now ,\n","Reference: ତ ା' ପର େ ଏଲ ି ଯ ତ ା\n","Model: <SOS> ତ ା' ପର େ ସ େ ଯ ତ ା\n","\n","Epoch: 8.00, Train Loss: 0.00, Val Loss: 3.07, Train BLEU: 0.00, Val BLEU: 22.67, Minutes Elapsed: 4.73\n","Sampling from val predictions...\n","Source: And the man that will do presumptuously , and will\n","Reference: ଯ େ ଉ ଁ ବ ୍ ଯକ ୍ ତ\n","Model: <SOS> ଯ େ ଉ ଁ ଲ ୋ ଯକ ୍ ତ\n","\n","Source: And he shall lay his hand upon the head of\n","Reference: ପ ୁ ଣ ି ସ େ ସହ େି ପ\n","Model: <SOS> ପ ା' ଉଲ ି ତ େ ତ ୁ ପ\n","\n","Source: And the man that will do presumptuously , and will\n","Reference: ଯ େ ଉ ଁ ବ ୍ ଯକ ୍ ତ\n","Model: <SOS> ଯ େ ଉ ଁ ଲ ୋ ଯକ ୍ ତ\n","\n","Epoch: 9.00, Train Loss: 0.00, Val Loss: 3.19, Train BLEU: 0.00, Val BLEU: 22.87, Minutes Elapsed: 5.32\n","Sampling from val predictions...\n","Source: For every high priest is ordained to offer gifts and\n","Reference: ପରମ େ ଶ ୍ ବରଙ ୍ କ ୁ ଦ\n","Model: <SOS> ଯ େ ଶ ୍ ବର ଯ କ ର ି\n","\n","Source: And Pilate wrote a title , and put it on\n","Reference: ପ ୀ ଲ ା ତ ଗ ୋ ଟ ି\n","Model: <SOS> ପ ା ଲ ା ତ ପ ପ ଟ ି\n","\n","Source: And the hanging for the gate of the court was\n","Reference: ପ ୍ ର ା ଙ ୍ ଗଣ ଦ ୍\n","Model: <SOS> ପ ୍ ର େି ତ ୍ କ ସହ ା\n","\n","Epoch: 10.00, Train Loss: 0.00, Val Loss: 3.36, Train BLEU: 0.00, Val BLEU: 22.51, Minutes Elapsed: 5.91\n","Sampling from val predictions...\n","Source: And they drew Alexander out of the multitude , the\n","Reference: ସ େ ତବ େେ ଳ େ ଯ ି ହ\n","Model: <SOS> ଲ ା ସମ ା ଳ େ ସମ ା ହ\n","\n","Source: For first of all , when ye come together in\n","Reference: ପ ୍ ରଥମ େ ମ ୁଁ ଶ ୁ ଣ\n","Model: <SOS> ତ ୍ ର େ ୀ ୀ ତ ୁ ନ\n","\n","Source: And I knew that thou hearest me always : but\n","Reference: ମ ୁଁ ଜ ା ଣ େ ଯ େ, ତ\n","Model: <SOS> ମ ୁଁ ଜ ୁ ଣ େ ଯ େ, ତ\n","\n","Model training completed in 5 minutes with 2.96 best validation loss and 22.87 best validation BLEU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QdKNe2cnHzxK","colab_type":"code","colab":{}},"source":[" "],"execution_count":0,"outputs":[]}]}